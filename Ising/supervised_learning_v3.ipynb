{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "data = pd.read_csv('dataframe.csv')\n",
    "X = data.iloc[:, :-1].values  # 入力データ (スピン配位)\n",
    "y = data.iloc[:, -1].values   # 教師データ (温度)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 100), (25000,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データのサイズを確認\n",
    "X.shape , y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01, 0.01, 0.01, ..., 6.  , 6.  , 6.  ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy配列からPyTorchのテンソルに変換\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)  # (25000,) -> (25000, 1)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)    # (6250,) -> (6250, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.0000],\n",
       "        [0.5000],\n",
       "        [2.2500],\n",
       "        ...,\n",
       "        [0.0100],\n",
       "        [3.7500],\n",
       "        [5.7500]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正解データはone-hot表現にする必要がある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# y_trainテンソルを新しいテンソルに変換する関数を定義\n",
    "def to_one_hot(y_train, num_classes=25):\n",
    "    # one-hotベクトルの初期化\n",
    "    one_hot = torch.zeros(len(y_train), num_classes)\n",
    "    \n",
    "    # 各要素を25次元のone-hotベクトルに変換\n",
    "    for i, val in enumerate(y_train):\n",
    "        index = int((val - 0.01) / 0.24)  # 正しいインデックスの計算\n",
    "        one_hot[i, index] = 1.0\n",
    "    \n",
    "    return one_hot\n",
    "\n",
    "# y_train,y_testをone-hotベクトルに変換\n",
    "one_hot_y_train = to_one_hot(y_train, num_classes=25)\n",
    "one_hot_y_test = to_one_hot(y_test, num_classes=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.5000])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_y_train[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの作成\n",
    "train_dataset = TensorDataset(X_train, one_hot_y_train)\n",
    "test_dataset = TensorDataset(X_test, one_hot_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.,  1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "          1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1.,  1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1.,  1.,  1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1.,  1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1.,  1., -1., -1., -1.,  1.,  1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1.,\n",
       "          1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像を回転させるような前処理を実行したいができていない，\n",
    "\n",
    "原因：各データが1次元に形を変形させてしまっているため，画像回転の前処理がエラーになってしまう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理を定義\n",
    "#transform = transforms.Compose([\n",
    "#    transforms.ToTensor(),\n",
    "#    transforms.RandomHorizontalFlip(p=0.5),\n",
    "#    transforms.RandomVerticalFlip(p=0.5),\n",
    "#])\n",
    "#\n",
    "#train_dataset = transform(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaderの設定（バッチサイズ1250）\n",
    "train_loader = DataLoader(train_dataset, batch_size=1250, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データの参照"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1250, 100]), torch.Size([1250, 25]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, t = next(iter(train_loader))\n",
    "x.shape, t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([1250, 25])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([1250, 25])\n",
      "tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([1250, 25])\n",
      "tensor([[0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([1250, 25])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.]])\n",
      "torch.Size([1250, 25])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([1250, 25])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n",
      "torch.Size([1250, 25])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([1250, 25])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([1250, 25])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([1250, 25])\n"
     ]
    }
   ],
   "source": [
    "for x, t in train_loader:\n",
    "    print(t)\n",
    "    print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ニューラルネットワークモデルの定義\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = F.softmax(self.fc2(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの初期化\n",
    "input_size = 100\n",
    "hidden_size = 64\n",
    "output_size = 25\n",
    "model = NeuralNetwork(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (fc1): Linear(in_features=100, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=25, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# モデルの中身を確認\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失関数と最適化アルゴリズムの設定\n",
    "criterion = nn.CrossEntropyLoss()   # クロスエントロピー誤差を採用\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)     # Adamという最適化手法を採用,L2正則化を設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sugay\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 3.2109736442565917, acc: 0.042479999363422394, test loss: 3.208908224105835, test acc: 0.04871999844908714\n",
      "epoch: 1, loss: 3.202813673019409, acc: 0.07055999338626862, test loss: 3.205059766769409, test acc: 0.06047999858856201\n",
      "epoch: 2, loss: 3.1951112270355226, acc: 0.08903999626636505, test loss: 3.2021817922592164, test acc: 0.06431999802589417\n",
      "epoch: 3, loss: 3.1883126974105833, acc: 0.09040000289678574, test loss: 3.198360323905945, test acc: 0.06815999746322632\n",
      "epoch: 4, loss: 3.1787576913833617, acc: 0.09736000001430511, test loss: 3.197310376167297, test acc: 0.06976000219583511\n",
      "epoch: 5, loss: 3.172018837928772, acc: 0.10839998722076416, test loss: 3.1986115694046022, test acc: 0.07128000259399414\n",
      "epoch: 6, loss: 3.1645182609558105, acc: 0.11903999745845795, test loss: 3.1992177724838258, test acc: 0.06824000179767609\n",
      "epoch: 7, loss: 3.1582841157913206, acc: 0.12783999741077423, test loss: 3.1977906703948973, test acc: 0.07448000460863113\n",
      "epoch: 8, loss: 3.1524796724319457, acc: 0.13471999764442444, test loss: 3.1978870153427126, test acc: 0.07239999622106552\n",
      "epoch: 9, loss: 3.1474971055984495, acc: 0.14151999354362488, test loss: 3.1989586353302, test acc: 0.07264000177383423\n",
      "epoch: 10, loss: 3.14309446811676, acc: 0.14824000000953674, test loss: 3.1979225873947144, test acc: 0.0735199972987175\n",
      "epoch: 11, loss: 3.1406234741210937, acc: 0.15223999321460724, test loss: 3.198873257637024, test acc: 0.07447999715805054\n",
      "epoch: 12, loss: 3.1372473001480103, acc: 0.1565599888563156, test loss: 3.1992406129837034, test acc: 0.07311999797821045\n",
      "epoch: 13, loss: 3.1340867042541505, acc: 0.1603199988603592, test loss: 3.2000872135162353, test acc: 0.07248000800609589\n",
      "epoch: 14, loss: 3.131809186935425, acc: 0.16360001266002655, test loss: 3.1978627920150755, test acc: 0.07503999769687653\n",
      "epoch: 15, loss: 3.1291744470596314, acc: 0.16767999529838562, test loss: 3.1982400178909303, test acc: 0.07576000690460205\n",
      "epoch: 16, loss: 3.1263240575790405, acc: 0.17096000909805298, test loss: 3.197983741760254, test acc: 0.07488000392913818\n",
      "epoch: 17, loss: 3.124244523048401, acc: 0.17191998660564423, test loss: 3.1976146697998047, test acc: 0.07400000095367432\n",
      "epoch: 18, loss: 3.1209534645080566, acc: 0.1783200055360794, test loss: 3.1985472202301026, test acc: 0.07472000271081924\n",
      "epoch: 19, loss: 3.120228719711304, acc: 0.17896001040935516, test loss: 3.1976468324661256, test acc: 0.07623999565839767\n",
      "epoch: 20, loss: 3.1186668634414674, acc: 0.1791199892759323, test loss: 3.198011016845703, test acc: 0.07608000934123993\n",
      "epoch: 21, loss: 3.1174230575561523, acc: 0.17999999225139618, test loss: 3.19812433719635, test acc: 0.07216000556945801\n",
      "epoch: 22, loss: 3.1151294469833375, acc: 0.18464002013206482, test loss: 3.1983910322189333, test acc: 0.07575999200344086\n",
      "epoch: 23, loss: 3.113368034362793, acc: 0.18591998517513275, test loss: 3.1974050045013427, test acc: 0.07599999755620956\n",
      "epoch: 24, loss: 3.1119813203811644, acc: 0.18648001551628113, test loss: 3.1975977659225463, test acc: 0.07584001123905182\n",
      "epoch: 25, loss: 3.1108365774154665, acc: 0.1881599873304367, test loss: 3.197188663482666, test acc: 0.07751999795436859\n",
      "epoch: 26, loss: 3.1094684839248656, acc: 0.18935999274253845, test loss: 3.197236251831055, test acc: 0.0761599987745285\n",
      "epoch: 27, loss: 3.1095494270324706, acc: 0.19167998433113098, test loss: 3.1978437423706056, test acc: 0.07711999118328094\n",
      "epoch: 28, loss: 3.1091251611709594, acc: 0.1907999962568283, test loss: 3.1976749181747435, test acc: 0.07679999619722366\n",
      "epoch: 29, loss: 3.107305884361267, acc: 0.19391998648643494, test loss: 3.1973805665969848, test acc: 0.07624000310897827\n",
      "epoch: 30, loss: 3.1058558940887453, acc: 0.1966399997472763, test loss: 3.1973493576049803, test acc: 0.07560000568628311\n",
      "epoch: 31, loss: 3.1046268224716185, acc: 0.1961599886417389, test loss: 3.1964619636535643, test acc: 0.07799999415874481\n",
      "epoch: 32, loss: 3.1047512531280517, acc: 0.19832000136375427, test loss: 3.1973498344421385, test acc: 0.07720000296831131\n",
      "epoch: 33, loss: 3.103681945800781, acc: 0.19784000515937805, test loss: 3.1968705654144287, test acc: 0.07656000554561615\n",
      "epoch: 34, loss: 3.100945782661438, acc: 0.20272000133991241, test loss: 3.19680438041687, test acc: 0.0761599987745285\n",
      "epoch: 35, loss: 3.101498913764954, acc: 0.20071999728679657, test loss: 3.197398805618286, test acc: 0.07656000554561615\n",
      "epoch: 36, loss: 3.100476694107056, acc: 0.20216000080108643, test loss: 3.196635031700134, test acc: 0.07999999821186066\n",
      "epoch: 37, loss: 3.100689721107483, acc: 0.20256002247333527, test loss: 3.1975635528564452, test acc: 0.07463999837636948\n",
      "epoch: 38, loss: 3.0994822502136232, acc: 0.201679989695549, test loss: 3.197058391571045, test acc: 0.07727999985218048\n",
      "epoch: 39, loss: 3.097943735122681, acc: 0.20495998859405518, test loss: 3.1969054460525514, test acc: 0.07815999537706375\n",
      "epoch: 40, loss: 3.09861798286438, acc: 0.20416000485420227, test loss: 3.1973634481430055, test acc: 0.07600000500679016\n",
      "epoch: 41, loss: 3.099431538581848, acc: 0.20255999267101288, test loss: 3.1963104009628296, test acc: 0.0785600021481514\n",
      "epoch: 42, loss: 3.097761297225952, acc: 0.2032800018787384, test loss: 3.196574592590332, test acc: 0.07904000580310822\n",
      "epoch: 43, loss: 3.0982340574264526, acc: 0.2051999866962433, test loss: 3.1971320629119875, test acc: 0.07551999390125275\n",
      "epoch: 44, loss: 3.097454476356506, acc: 0.20375999808311462, test loss: 3.1966785907745363, test acc: 0.07768000662326813\n",
      "epoch: 45, loss: 3.097067952156067, acc: 0.2064799964427948, test loss: 3.1983744144439696, test acc: 0.07656000554561615\n",
      "epoch: 46, loss: 3.0965535402297975, acc: 0.2048799991607666, test loss: 3.196586799621582, test acc: 0.07712000608444214\n",
      "epoch: 47, loss: 3.0956268310546875, acc: 0.2083199918270111, test loss: 3.1974677085876464, test acc: 0.07631999999284744\n",
      "epoch: 48, loss: 3.095304274559021, acc: 0.20696000754833221, test loss: 3.1978775024414063, test acc: 0.07503999769687653\n",
      "epoch: 49, loss: 3.0945735692977907, acc: 0.21000000834465027, test loss: 3.1984684467315674, test acc: 0.07736000418663025\n",
      "epoch: 50, loss: 3.0942849636077883, acc: 0.20855998992919922, test loss: 3.1980016946792604, test acc: 0.07383999973535538\n",
      "epoch: 51, loss: 3.095454978942871, acc: 0.20696000754833221, test loss: 3.196908402442932, test acc: 0.07903999090194702\n",
      "epoch: 52, loss: 3.0941901206970215, acc: 0.20960000157356262, test loss: 3.1981199979782104, test acc: 0.07503999769687653\n",
      "epoch: 53, loss: 3.0940257787704466, acc: 0.20999999344348907, test loss: 3.1972113370895388, test acc: 0.07744000107049942\n",
      "epoch: 54, loss: 3.093730068206787, acc: 0.21087999641895294, test loss: 3.196127414703369, test acc: 0.07895999401807785\n",
      "epoch: 55, loss: 3.0932255029678344, acc: 0.20952001214027405, test loss: 3.1971217155456544, test acc: 0.07943999767303467\n",
      "epoch: 56, loss: 3.091849446296692, acc: 0.21111997961997986, test loss: 3.1961431741714477, test acc: 0.07816000282764435\n",
      "epoch: 57, loss: 3.09146044254303, acc: 0.2120000123977661, test loss: 3.196975827217102, test acc: 0.07632000744342804\n",
      "epoch: 58, loss: 3.0905424118041993, acc: 0.21264000236988068, test loss: 3.196191358566284, test acc: 0.0785600021481514\n",
      "epoch: 59, loss: 3.089795231819153, acc: 0.21344001591205597, test loss: 3.196858859062195, test acc: 0.07727999985218048\n",
      "epoch: 60, loss: 3.089945912361145, acc: 0.21383997797966003, test loss: 3.1957278728485106, test acc: 0.07847999781370163\n",
      "epoch: 61, loss: 3.0885989665985107, acc: 0.21616001427173615, test loss: 3.196544718742371, test acc: 0.07823999226093292\n",
      "epoch: 62, loss: 3.088985562324524, acc: 0.2157600224018097, test loss: 3.195984411239624, test acc: 0.07871999591588974\n",
      "epoch: 63, loss: 3.0878511905670165, acc: 0.2163199931383133, test loss: 3.196021008491516, test acc: 0.07783999294042587\n",
      "epoch: 64, loss: 3.0881570100784304, acc: 0.21775999665260315, test loss: 3.196012496948242, test acc: 0.07840000092983246\n",
      "epoch: 65, loss: 3.087465763092041, acc: 0.21768000721931458, test loss: 3.196144723892212, test acc: 0.07711999863386154\n",
      "epoch: 66, loss: 3.086330771446228, acc: 0.21928000450134277, test loss: 3.1960803031921388, test acc: 0.0777599960565567\n",
      "epoch: 67, loss: 3.0867143630981446, acc: 0.21872000396251678, test loss: 3.196323275566101, test acc: 0.07872000336647034\n",
      "epoch: 68, loss: 3.0863452434539793, acc: 0.22047999501228333, test loss: 3.195974850654602, test acc: 0.07920000702142715\n",
      "epoch: 69, loss: 3.0860568284988403, acc: 0.2199999988079071, test loss: 3.1957932472229005, test acc: 0.07848000526428223\n",
      "epoch: 70, loss: 3.086499238014221, acc: 0.21935999393463135, test loss: 3.195997714996338, test acc: 0.07872000336647034\n",
      "epoch: 71, loss: 3.0862956762313845, acc: 0.2199999839067459, test loss: 3.1967396259307863, test acc: 0.07968000322580338\n",
      "epoch: 72, loss: 3.0859184503555297, acc: 0.22032001614570618, test loss: 3.197045183181763, test acc: 0.07735998928546906\n",
      "epoch: 73, loss: 3.0862303972244263, acc: 0.21848002076148987, test loss: 3.1956377267837524, test acc: 0.07887999713420868\n",
      "epoch: 74, loss: 3.085342860221863, acc: 0.22007998824119568, test loss: 3.195964288711548, test acc: 0.08032000064849854\n",
      "epoch: 75, loss: 3.0858747720718385, acc: 0.22040000557899475, test loss: 3.196637988090515, test acc: 0.07816000282764435\n",
      "epoch: 76, loss: 3.0854042291641237, acc: 0.22095999121665955, test loss: 3.196200466156006, test acc: 0.07800000160932541\n",
      "epoch: 77, loss: 3.0849069118499757, acc: 0.22119998931884766, test loss: 3.1960543394088745, test acc: 0.0793599933385849\n",
      "epoch: 78, loss: 3.084667372703552, acc: 0.22304002940654755, test loss: 3.1955294370651246, test acc: 0.07944000512361526\n",
      "epoch: 79, loss: 3.0840081691741945, acc: 0.2226400077342987, test loss: 3.196011710166931, test acc: 0.07943999767303467\n",
      "epoch: 80, loss: 3.0838316679000854, acc: 0.22183997929096222, test loss: 3.195937395095825, test acc: 0.07920000702142715\n",
      "epoch: 81, loss: 3.083071494102478, acc: 0.22312000393867493, test loss: 3.19580614566803, test acc: 0.07848000526428223\n",
      "epoch: 82, loss: 3.0829548120498655, acc: 0.2247999906539917, test loss: 3.195626974105835, test acc: 0.07919999212026596\n",
      "epoch: 83, loss: 3.0824740648269655, acc: 0.22511999309062958, test loss: 3.1968550443649293, test acc: 0.07784000039100647\n",
      "epoch: 84, loss: 3.083480978012085, acc: 0.22288000583648682, test loss: 3.1956756114959717, test acc: 0.08023999631404877\n",
      "epoch: 85, loss: 3.0829252004623413, acc: 0.22288000583648682, test loss: 3.195817494392395, test acc: 0.07912000268697739\n",
      "epoch: 86, loss: 3.083386254310608, acc: 0.2218399941921234, test loss: 3.1959279775619507, test acc: 0.08032000064849854\n",
      "epoch: 87, loss: 3.083982300758362, acc: 0.22151999175548553, test loss: 3.195397734642029, test acc: 0.07983999699354172\n",
      "epoch: 88, loss: 3.082963728904724, acc: 0.22544002532958984, test loss: 3.195789337158203, test acc: 0.07928000390529633\n",
      "epoch: 89, loss: 3.082321286201477, acc: 0.22487998008728027, test loss: 3.195882487297058, test acc: 0.07896000146865845\n",
      "epoch: 90, loss: 3.0821168422698975, acc: 0.22511999309062958, test loss: 3.1975740432739257, test acc: 0.07880000025033951\n",
      "epoch: 91, loss: 3.0834009885787963, acc: 0.22327999770641327, test loss: 3.1961756229400633, test acc: 0.07896000146865845\n",
      "epoch: 92, loss: 3.0814924478530883, acc: 0.22551998496055603, test loss: 3.1970855474472044, test acc: 0.0753600001335144\n",
      "epoch: 93, loss: 3.0814565896987913, acc: 0.22488000988960266, test loss: 3.1957569122314453, test acc: 0.07951999455690384\n",
      "epoch: 94, loss: 3.0813528537750243, acc: 0.22648000717163086, test loss: 3.1953628778457643, test acc: 0.07919999957084656\n",
      "epoch: 95, loss: 3.081222724914551, acc: 0.22624000906944275, test loss: 3.1964229345321655, test acc: 0.07903999090194702\n",
      "epoch: 96, loss: 3.0809513568878173, acc: 0.2268799990415573, test loss: 3.195480465888977, test acc: 0.07847999781370163\n",
      "epoch: 97, loss: 3.080556845664978, acc: 0.22599999606609344, test loss: 3.1950735807418824, test acc: 0.08000000566244125\n",
      "epoch: 98, loss: 3.0800335884094237, acc: 0.22991999983787537, test loss: 3.1963323593139648, test acc: 0.07783998548984528\n",
      "epoch: 99, loss: 3.0800934791564942, acc: 0.22752001881599426, test loss: 3.1955668449401857, test acc: 0.07792000472545624\n",
      "epoch: 100, loss: 3.080481839179993, acc: 0.2276799976825714, test loss: 3.195624041557312, test acc: 0.07944000512361526\n",
      "epoch: 101, loss: 3.0791238069534304, acc: 0.22856000065803528, test loss: 3.1955761194229124, test acc: 0.07983999699354172\n",
      "epoch: 102, loss: 3.079268383979797, acc: 0.22839999198913574, test loss: 3.195462465286255, test acc: 0.0785600021481514\n",
      "epoch: 103, loss: 3.0798166036605834, acc: 0.22847998142242432, test loss: 3.1956568241119383, test acc: 0.07872000336647034\n",
      "epoch: 104, loss: 3.080200934410095, acc: 0.2272000014781952, test loss: 3.1966288566589354, test acc: 0.0788000077009201\n",
      "epoch: 105, loss: 3.081368350982666, acc: 0.22519998252391815, test loss: 3.196034479141235, test acc: 0.07984000444412231\n",
      "epoch: 106, loss: 3.080798101425171, acc: 0.22592000663280487, test loss: 3.1951220750808718, test acc: 0.08071999251842499\n",
      "epoch: 107, loss: 3.0808435678482056, acc: 0.22592000663280487, test loss: 3.196454334259033, test acc: 0.0769599974155426\n",
      "epoch: 108, loss: 3.079685401916504, acc: 0.22807998955249786, test loss: 3.1955926418304443, test acc: 0.07952000200748444\n",
      "epoch: 109, loss: 3.079784965515137, acc: 0.22696001827716827, test loss: 3.1959543228149414, test acc: 0.07840000092983246\n",
      "epoch: 110, loss: 3.079174780845642, acc: 0.22751998901367188, test loss: 3.1954272508621218, test acc: 0.07999999821186066\n",
      "epoch: 111, loss: 3.079310989379883, acc: 0.22847998142242432, test loss: 3.196300745010376, test acc: 0.07807999849319458\n",
      "epoch: 112, loss: 3.0789431810379027, acc: 0.22880001366138458, test loss: 3.1952619314193726, test acc: 0.08024000376462936\n",
      "epoch: 113, loss: 3.0774866580963134, acc: 0.2298400104045868, test loss: 3.195576620101929, test acc: 0.07887999713420868\n",
      "epoch: 114, loss: 3.078470969200134, acc: 0.23007997870445251, test loss: 3.1956044912338255, test acc: 0.07896000146865845\n",
      "epoch: 115, loss: 3.0783281087875367, acc: 0.22999998927116394, test loss: 3.195197868347168, test acc: 0.07984000444412231\n",
      "epoch: 116, loss: 3.077220582962036, acc: 0.23080000281333923, test loss: 3.1957551002502442, test acc: 0.07912000268697739\n",
      "epoch: 117, loss: 3.0780210733413695, acc: 0.23007997870445251, test loss: 3.195821833610535, test acc: 0.07944000512361526\n",
      "epoch: 118, loss: 3.077813911437988, acc: 0.23120000958442688, test loss: 3.1947948932647705, test acc: 0.0811999961733818\n",
      "epoch: 119, loss: 3.077347469329834, acc: 0.23048000037670135, test loss: 3.196079468727112, test acc: 0.07919999957084656\n",
      "epoch: 120, loss: 3.077681827545166, acc: 0.23023998737335205, test loss: 3.1958737134933473, test acc: 0.08072000741958618\n",
      "epoch: 121, loss: 3.078248882293701, acc: 0.22991998493671417, test loss: 3.1962037801742555, test acc: 0.07968000322580338\n",
      "epoch: 122, loss: 3.076890206336975, acc: 0.23240001499652863, test loss: 3.195428895950317, test acc: 0.08047999441623688\n",
      "epoch: 123, loss: 3.0770536184310915, acc: 0.2303999960422516, test loss: 3.195127820968628, test acc: 0.08055999875068665\n",
      "epoch: 124, loss: 3.07736394405365, acc: 0.2308799922466278, test loss: 3.1965118408203126, test acc: 0.07784000039100647\n",
      "epoch: 125, loss: 3.078402209281921, acc: 0.2282399833202362, test loss: 3.1958025455474854, test acc: 0.07887999713420868\n",
      "epoch: 126, loss: 3.0766395330429077, acc: 0.23136000335216522, test loss: 3.1956551313400268, test acc: 0.07871999591588974\n",
      "epoch: 127, loss: 3.0754831075668334, acc: 0.23199999332427979, test loss: 3.1950040578842165, test acc: 0.08024000376462936\n",
      "epoch: 128, loss: 3.0763355016708376, acc: 0.23312000930309296, test loss: 3.195120596885681, test acc: 0.0803999975323677\n",
      "epoch: 129, loss: 3.077873182296753, acc: 0.2295200079679489, test loss: 3.1952867031097414, test acc: 0.08007999509572983\n",
      "epoch: 130, loss: 3.0767518281936646, acc: 0.2316799908876419, test loss: 3.1952431440353393, test acc: 0.08016000688076019\n",
      "epoch: 131, loss: 3.076101803779602, acc: 0.23231999576091766, test loss: 3.1950389623641966, test acc: 0.07999999821186066\n",
      "epoch: 132, loss: 3.075317406654358, acc: 0.23400001227855682, test loss: 3.1953450441360474, test acc: 0.07911999523639679\n",
      "epoch: 133, loss: 3.0753216981887816, acc: 0.2343199998140335, test loss: 3.1954922437667848, test acc: 0.07943999767303467\n",
      "epoch: 134, loss: 3.0746792554855347, acc: 0.23319999873638153, test loss: 3.1945077657699583, test acc: 0.08088000118732452\n",
      "epoch: 135, loss: 3.075424313545227, acc: 0.23359999060630798, test loss: 3.195935010910034, test acc: 0.07880000025033951\n",
      "epoch: 136, loss: 3.074228525161743, acc: 0.23544001579284668, test loss: 3.195433187484741, test acc: 0.08023999631404877\n",
      "epoch: 137, loss: 3.0741032123565675, acc: 0.23503999412059784, test loss: 3.1953895568847654, test acc: 0.07823999971151352\n",
      "epoch: 138, loss: 3.0745933294296264, acc: 0.23439998924732208, test loss: 3.1954777240753174, test acc: 0.08080000430345535\n",
      "epoch: 139, loss: 3.073784351348877, acc: 0.23608000576496124, test loss: 3.1950957775115967, test acc: 0.07999999821186066\n",
      "epoch: 140, loss: 3.0739808082580566, acc: 0.2356800138950348, test loss: 3.196439266204834, test acc: 0.07823999971151352\n",
      "epoch: 141, loss: 3.0748843431472777, acc: 0.23367998003959656, test loss: 3.1957187175750734, test acc: 0.07840000092983246\n",
      "epoch: 142, loss: 3.0754125833511354, acc: 0.23288002610206604, test loss: 3.1948321580886843, test acc: 0.08144000172615051\n",
      "epoch: 143, loss: 3.0743241786956785, acc: 0.23343999683856964, test loss: 3.1953323125839233, test acc: 0.07863999903202057\n",
      "epoch: 144, loss: 3.0734979152679442, acc: 0.23535998165607452, test loss: 3.195321774482727, test acc: 0.07976000010967255\n",
      "epoch: 145, loss: 3.072797727584839, acc: 0.23664000630378723, test loss: 3.1946878910064695, test acc: 0.08103999495506287\n",
      "epoch: 146, loss: 3.0734884262084963, acc: 0.2354399859905243, test loss: 3.1953258991241453, test acc: 0.07976000010967255\n",
      "epoch: 147, loss: 3.0736871480941774, acc: 0.23584000766277313, test loss: 3.195681834220886, test acc: 0.07832000404596329\n",
      "epoch: 148, loss: 3.0729023456573485, acc: 0.23704001307487488, test loss: 3.1949030637741087, test acc: 0.07928000390529633\n",
      "epoch: 149, loss: 3.074867606163025, acc: 0.23319998383522034, test loss: 3.1960320234298707, test acc: 0.07792000472545624\n",
      "epoch: 150, loss: 3.073831582069397, acc: 0.2348800152540207, test loss: 3.1955235481262205, test acc: 0.07880000025033951\n",
      "epoch: 151, loss: 3.0731303453445435, acc: 0.23656001687049866, test loss: 3.195099878311157, test acc: 0.07976000010967255\n",
      "epoch: 152, loss: 3.0748194456100464, acc: 0.23288002610206604, test loss: 3.196060585975647, test acc: 0.0804000049829483\n",
      "epoch: 153, loss: 3.0748148202896117, acc: 0.2327999770641327, test loss: 3.195267581939697, test acc: 0.08007999509572983\n",
      "epoch: 154, loss: 3.0748549699783325, acc: 0.23415999114513397, test loss: 3.195374298095703, test acc: 0.07880000025033951\n",
      "epoch: 155, loss: 3.0744166135787965, acc: 0.23424001038074493, test loss: 3.196861410140991, test acc: 0.07767999917268753\n",
      "epoch: 156, loss: 3.0745035886764525, acc: 0.23392000794410706, test loss: 3.195034217834473, test acc: 0.08047999441623688\n",
      "epoch: 157, loss: 3.072252869606018, acc: 0.23680000007152557, test loss: 3.1953094720840456, test acc: 0.07984000444412231\n",
      "epoch: 158, loss: 3.072926950454712, acc: 0.23551997542381287, test loss: 3.194826912879944, test acc: 0.08023999631404877\n",
      "epoch: 159, loss: 3.0735302686691286, acc: 0.23440000414848328, test loss: 3.1956156492233276, test acc: 0.07879999279975891\n",
      "epoch: 160, loss: 3.0731244564056395, acc: 0.23623999953269958, test loss: 3.19598183631897, test acc: 0.0788000077009201\n",
      "epoch: 161, loss: 3.0726383686065675, acc: 0.2356799840927124, test loss: 3.1955151081085207, test acc: 0.07944000512361526\n",
      "epoch: 162, loss: 3.0732555627822875, acc: 0.2348800152540207, test loss: 3.195018744468689, test acc: 0.0785599946975708\n",
      "epoch: 163, loss: 3.071807932853699, acc: 0.23736000061035156, test loss: 3.1956709384918214, test acc: 0.07896000146865845\n",
      "epoch: 164, loss: 3.0721959829330445, acc: 0.23759999871253967, test loss: 3.1965135812759398, test acc: 0.07599999755620956\n",
      "epoch: 165, loss: 3.072037935256958, acc: 0.23792000114917755, test loss: 3.1951049089431764, test acc: 0.07976000010967255\n",
      "epoch: 166, loss: 3.071692132949829, acc: 0.238319993019104, test loss: 3.194510984420776, test acc: 0.08031999319791794\n",
      "epoch: 167, loss: 3.0714002370834352, acc: 0.23791997134685516, test loss: 3.1956107139587404, test acc: 0.07767999917268753\n",
      "epoch: 168, loss: 3.073096513748169, acc: 0.23656001687049866, test loss: 3.1954132318496704, test acc: 0.07839999347925186\n",
      "epoch: 169, loss: 3.0732593059539797, acc: 0.23560002446174622, test loss: 3.195297431945801, test acc: 0.07896000146865845\n",
      "epoch: 170, loss: 3.073479413986206, acc: 0.2345600128173828, test loss: 3.1954796075820924, test acc: 0.07792000472545624\n",
      "epoch: 171, loss: 3.0726008892059324, acc: 0.23680000007152557, test loss: 3.195085644721985, test acc: 0.08064000308513641\n",
      "epoch: 172, loss: 3.0718448638916014, acc: 0.23768000304698944, test loss: 3.1949246168136596, test acc: 0.0801599994301796\n",
      "epoch: 173, loss: 3.070911979675293, acc: 0.23824000358581543, test loss: 3.195104646682739, test acc: 0.07888000458478928\n",
      "epoch: 174, loss: 3.0719173431396483, acc: 0.23735997080802917, test loss: 3.1952059507369994, test acc: 0.07840000092983246\n",
      "epoch: 175, loss: 3.0713311672210692, acc: 0.23792001605033875, test loss: 3.195201563835144, test acc: 0.07760000228881836\n",
      "epoch: 176, loss: 3.071211552619934, acc: 0.23816001415252686, test loss: 3.1952919721603394, test acc: 0.0801599994301796\n",
      "epoch: 177, loss: 3.07236008644104, acc: 0.2354399859905243, test loss: 3.197142767906189, test acc: 0.0785600021481514\n",
      "epoch: 178, loss: 3.0727627277374268, acc: 0.23695997893810272, test loss: 3.196325397491455, test acc: 0.07664000988006592\n",
      "epoch: 179, loss: 3.072379970550537, acc: 0.23503999412059784, test loss: 3.1957879304885863, test acc: 0.07863999903202057\n",
      "epoch: 180, loss: 3.071383476257324, acc: 0.2369600087404251, test loss: 3.195398044586182, test acc: 0.0793599933385849\n",
      "epoch: 181, loss: 3.0721202850341798, acc: 0.23679998517036438, test loss: 3.1958942890167235, test acc: 0.07808000594377518\n",
      "epoch: 182, loss: 3.072780203819275, acc: 0.23584000766277313, test loss: 3.195526123046875, test acc: 0.07896000146865845\n",
      "epoch: 183, loss: 3.072211170196533, acc: 0.23631998896598816, test loss: 3.1953914642333983, test acc: 0.08000000566244125\n",
      "epoch: 184, loss: 3.07135648727417, acc: 0.2375200092792511, test loss: 3.1949981451034546, test acc: 0.07999999821186066\n",
      "epoch: 185, loss: 3.072455048561096, acc: 0.23631998896598816, test loss: 3.1956122398376463, test acc: 0.07896000146865845\n",
      "epoch: 186, loss: 3.073910093307495, acc: 0.23343999683856964, test loss: 3.195252275466919, test acc: 0.07920000702142715\n",
      "epoch: 187, loss: 3.0716551780700683, acc: 0.23608000576496124, test loss: 3.1954614400863646, test acc: 0.07863999903202057\n",
      "epoch: 188, loss: 3.0718376636505127, acc: 0.23919999599456787, test loss: 3.195777177810669, test acc: 0.07704000174999237\n",
      "epoch: 189, loss: 3.0717407941818236, acc: 0.23615999519824982, test loss: 3.1953306198120117, test acc: 0.07863999903202057\n",
      "epoch: 190, loss: 3.0713327884674073, acc: 0.23775999248027802, test loss: 3.1956705808639527, test acc: 0.0777599960565567\n",
      "epoch: 191, loss: 3.0710405826568605, acc: 0.23775999248027802, test loss: 3.195155310630798, test acc: 0.07895999401807785\n",
      "epoch: 192, loss: 3.0706812143325806, acc: 0.23880000412464142, test loss: 3.194825029373169, test acc: 0.0801599994301796\n",
      "epoch: 193, loss: 3.070841836929321, acc: 0.23887999355793, test loss: 3.1958327770233153, test acc: 0.0788000077009201\n",
      "epoch: 194, loss: 3.0710641622543333, acc: 0.23895999789237976, test loss: 3.19509379863739, test acc: 0.07952000200748444\n",
      "epoch: 195, loss: 3.0708317279815676, acc: 0.23792000114917755, test loss: 3.1952147245407105, test acc: 0.07895999401807785\n",
      "epoch: 196, loss: 3.0721393823623657, acc: 0.23680000007152557, test loss: 3.196960520744324, test acc: 0.07648000866174698\n",
      "epoch: 197, loss: 3.074990725517273, acc: 0.23160000145435333, test loss: 3.195283818244934, test acc: 0.07991999387741089\n",
      "epoch: 198, loss: 3.071407508850098, acc: 0.23880000412464142, test loss: 3.194792103767395, test acc: 0.08079999685287476\n",
      "epoch: 199, loss: 3.070422625541687, acc: 0.23895999789237976, test loss: 3.1955039739608764, test acc: 0.07872001081705093\n",
      "epoch: 200, loss: 3.070689582824707, acc: 0.2391199767589569, test loss: 3.194848561286926, test acc: 0.07871999591588974\n",
      "epoch: 201, loss: 3.071445631980896, acc: 0.23680000007152557, test loss: 3.1958374261856077, test acc: 0.078560009598732\n",
      "epoch: 202, loss: 3.0708252429962157, acc: 0.23759999871253967, test loss: 3.1944895029067992, test acc: 0.08103999495506287\n",
      "epoch: 203, loss: 3.0699801445007324, acc: 0.2399199903011322, test loss: 3.194619393348694, test acc: 0.08032000064849854\n",
      "epoch: 204, loss: 3.0687316179275514, acc: 0.24272000789642334, test loss: 3.1950893640518188, test acc: 0.07872000336647034\n",
      "epoch: 205, loss: 3.06965651512146, acc: 0.24063999950885773, test loss: 3.196062755584717, test acc: 0.07608000189065933\n",
      "epoch: 206, loss: 3.070404815673828, acc: 0.23775999248027802, test loss: 3.1947560548782348, test acc: 0.07903999835252762\n",
      "epoch: 207, loss: 3.0682586193084718, acc: 0.24032001197338104, test loss: 3.194871187210083, test acc: 0.07952000200748444\n",
      "epoch: 208, loss: 3.0686991691589354, acc: 0.24199998378753662, test loss: 3.1953071117401124, test acc: 0.07919999212026596\n",
      "epoch: 209, loss: 3.0690741539001465, acc: 0.24143998324871063, test loss: 3.1945125102996825, test acc: 0.07896000146865845\n",
      "epoch: 210, loss: 3.0688396215438845, acc: 0.2415199726819992, test loss: 3.194968032836914, test acc: 0.07927999645471573\n",
      "epoch: 211, loss: 3.069499373435974, acc: 0.24128000438213348, test loss: 3.194728946685791, test acc: 0.07928000390529633\n",
      "epoch: 212, loss: 3.0686091423034667, acc: 0.24087998270988464, test loss: 3.194970989227295, test acc: 0.07832000404596329\n",
      "epoch: 213, loss: 3.0679357767105104, acc: 0.2407200038433075, test loss: 3.1951307535171507, test acc: 0.07984000444412231\n",
      "epoch: 214, loss: 3.0690550565719605, acc: 0.24128000438213348, test loss: 3.19591429233551, test acc: 0.07784000784158707\n",
      "epoch: 215, loss: 3.0690437078475954, acc: 0.2412000149488449, test loss: 3.1961583614349367, test acc: 0.07744000107049942\n",
      "epoch: 216, loss: 3.0707399606704713, acc: 0.2375200092792511, test loss: 3.194810175895691, test acc: 0.07871999591588974\n",
      "epoch: 217, loss: 3.068804883956909, acc: 0.24031999707221985, test loss: 3.195124864578247, test acc: 0.07880000025033951\n",
      "epoch: 218, loss: 3.068535327911377, acc: 0.24192002415657043, test loss: 3.1944440841674804, test acc: 0.07911999523639679\n",
      "epoch: 219, loss: 3.068298816680908, acc: 0.24247999489307404, test loss: 3.1943637132644653, test acc: 0.0803999975323677\n",
      "epoch: 220, loss: 3.06831750869751, acc: 0.2415200024843216, test loss: 3.1949015617370606, test acc: 0.08023999631404877\n",
      "epoch: 221, loss: 3.067990207672119, acc: 0.24167999625205994, test loss: 3.194961094856262, test acc: 0.07999999821186066\n",
      "epoch: 222, loss: 3.068173718452454, acc: 0.2431199997663498, test loss: 3.194780874252319, test acc: 0.07816000282764435\n",
      "epoch: 223, loss: 3.0673654556274412, acc: 0.24304001033306122, test loss: 3.1950534105300905, test acc: 0.07912000268697739\n",
      "epoch: 224, loss: 3.0674643516540527, acc: 0.24263998866081238, test loss: 3.1943318128585814, test acc: 0.08023999631404877\n",
      "epoch: 225, loss: 3.0673073053359987, acc: 0.24288001656532288, test loss: 3.194936466217041, test acc: 0.07880000025033951\n",
      "epoch: 226, loss: 3.0687729358673095, acc: 0.24120000004768372, test loss: 3.194830083847046, test acc: 0.0785600021481514\n",
      "epoch: 227, loss: 3.0689061164855955, acc: 0.2404799908399582, test loss: 3.194950723648071, test acc: 0.07976000010967255\n",
      "epoch: 228, loss: 3.0677382946014404, acc: 0.2423200160264969, test loss: 3.1949702978134153, test acc: 0.08056000620126724\n",
      "epoch: 229, loss: 3.0674308061599733, acc: 0.24304001033306122, test loss: 3.194537901878357, test acc: 0.07927999645471573\n",
      "epoch: 230, loss: 3.0670594215393066, acc: 0.24344000220298767, test loss: 3.1957509517669678, test acc: 0.07823999226093292\n",
      "epoch: 231, loss: 3.0673089265823363, acc: 0.24248000979423523, test loss: 3.1943010807037355, test acc: 0.08048000186681747\n",
      "epoch: 232, loss: 3.0662756681442263, acc: 0.24488000571727753, test loss: 3.194784688949585, test acc: 0.07887999713420868\n",
      "epoch: 233, loss: 3.0663225412368775, acc: 0.24399998784065247, test loss: 3.1947306871414183, test acc: 0.08055999875068665\n",
      "epoch: 234, loss: 3.068237781524658, acc: 0.24216000735759735, test loss: 3.1947850227355956, test acc: 0.08111999928951263\n",
      "epoch: 235, loss: 3.0666399955749513, acc: 0.24384000897407532, test loss: 3.195155310630798, test acc: 0.07911999523639679\n",
      "epoch: 236, loss: 3.066681456565857, acc: 0.24351999163627625, test loss: 3.1948200702667235, test acc: 0.07864000648260117\n",
      "epoch: 237, loss: 3.0662338972091674, acc: 0.24632000923156738, test loss: 3.1944935083389283, test acc: 0.0809599980711937\n",
      "epoch: 238, loss: 3.0662782192230225, acc: 0.24456000328063965, test loss: 3.1948315382003782, test acc: 0.07863999903202057\n",
      "epoch: 239, loss: 3.0675373554229735, acc: 0.2436000406742096, test loss: 3.1949486255645754, test acc: 0.08063999563455582\n",
      "epoch: 240, loss: 3.0679575920104982, acc: 0.2417600154876709, test loss: 3.1946407079696657, test acc: 0.07840000092983246\n",
      "epoch: 241, loss: 3.066055941581726, acc: 0.24552002549171448, test loss: 3.1955576181411742, test acc: 0.07711999863386154\n",
      "epoch: 242, loss: 3.0663833379745484, acc: 0.2457600086927414, test loss: 3.1944198608398438, test acc: 0.07967999577522278\n",
      "epoch: 243, loss: 3.0661880731582642, acc: 0.24607999622821808, test loss: 3.1950060606002806, test acc: 0.07984000444412231\n",
      "epoch: 244, loss: 3.0671245098114013, acc: 0.24408002197742462, test loss: 3.1949925661087035, test acc: 0.07984000444412231\n",
      "epoch: 245, loss: 3.067980694770813, acc: 0.24295997619628906, test loss: 3.1957559823989867, test acc: 0.07904000580310822\n",
      "epoch: 246, loss: 3.066042995452881, acc: 0.2455199956893921, test loss: 3.194053840637207, test acc: 0.07911999523639679\n",
      "epoch: 247, loss: 3.0661943674087526, acc: 0.24615998566150665, test loss: 3.1946190357208253, test acc: 0.08023999631404877\n",
      "epoch: 248, loss: 3.067094588279724, acc: 0.24319998919963837, test loss: 3.1965446949005125, test acc: 0.07928000390529633\n",
      "epoch: 249, loss: 3.0676462650299072, acc: 0.24263998866081238, test loss: 3.1949878692626954, test acc: 0.07927999645471573\n",
      "epoch: 250, loss: 3.0658168315887453, acc: 0.24528002738952637, test loss: 3.1954431533813477, test acc: 0.07871998846530914\n",
      "epoch: 251, loss: 3.066379737854004, acc: 0.24423997104167938, test loss: 3.19548761844635, test acc: 0.07927999645471573\n",
      "epoch: 252, loss: 3.0681085348129273, acc: 0.24247999489307404, test loss: 3.1946890115737916, test acc: 0.07976000010967255\n",
      "epoch: 253, loss: 3.0657326698303224, acc: 0.24463999271392822, test loss: 3.1942816734313966, test acc: 0.07992000132799149\n",
      "epoch: 254, loss: 3.0646283626556396, acc: 0.2486400157213211, test loss: 3.194638419151306, test acc: 0.08032000064849854\n",
      "epoch: 255, loss: 3.0646801471710203, acc: 0.24767999351024628, test loss: 3.1948017835617066, test acc: 0.07968000322580338\n",
      "epoch: 256, loss: 3.0640749454498293, acc: 0.24743998050689697, test loss: 3.194566559791565, test acc: 0.08008000254631042\n",
      "epoch: 257, loss: 3.064214301109314, acc: 0.24727997183799744, test loss: 3.1950453996658323, test acc: 0.08047999441623688\n",
      "epoch: 258, loss: 3.064389228820801, acc: 0.24664001166820526, test loss: 3.1947123289108275, test acc: 0.0803999975323677\n",
      "epoch: 259, loss: 3.06399986743927, acc: 0.24823996424674988, test loss: 3.194753861427307, test acc: 0.07919999957084656\n",
      "epoch: 260, loss: 3.0639847040176393, acc: 0.24688000977039337, test loss: 3.1948216915130616, test acc: 0.08032000064849854\n",
      "epoch: 261, loss: 3.065464901924133, acc: 0.24615998566150665, test loss: 3.1943658351898194, test acc: 0.08159999549388885\n",
      "epoch: 262, loss: 3.065829372406006, acc: 0.24463999271392822, test loss: 3.1952847957611086, test acc: 0.07872000336647034\n",
      "epoch: 263, loss: 3.0644849300384522, acc: 0.24647998809814453, test loss: 3.195494365692139, test acc: 0.07976000756025314\n",
      "epoch: 264, loss: 3.0656905651092528, acc: 0.24480000138282776, test loss: 3.195308804512024, test acc: 0.08080000430345535\n",
      "epoch: 265, loss: 3.0659291744232178, acc: 0.2444000244140625, test loss: 3.194110298156738, test acc: 0.08152000606060028\n",
      "epoch: 266, loss: 3.0639343738555906, acc: 0.24823999404907227, test loss: 3.1948035955429077, test acc: 0.07904000580310822\n",
      "epoch: 267, loss: 3.06449236869812, acc: 0.24679997563362122, test loss: 3.1948216438293455, test acc: 0.08176000416278839\n",
      "epoch: 268, loss: 3.064337420463562, acc: 0.24767999351024628, test loss: 3.1942781686782835, test acc: 0.08088000118732452\n",
      "epoch: 269, loss: 3.063298463821411, acc: 0.24992001056671143, test loss: 3.1946982622146605, test acc: 0.0793600082397461\n",
      "epoch: 270, loss: 3.0622174978256225, acc: 0.25008001923561096, test loss: 3.1946298360824583, test acc: 0.07984000444412231\n",
      "epoch: 271, loss: 3.0622816562652586, acc: 0.24967996776103973, test loss: 3.1944334745407104, test acc: 0.0803999975323677\n",
      "epoch: 272, loss: 3.06226532459259, acc: 0.2507999837398529, test loss: 3.19466712474823, test acc: 0.08079999685287476\n",
      "epoch: 273, loss: 3.062355947494507, acc: 0.25, test loss: 3.194686698913574, test acc: 0.08104000240564346\n",
      "epoch: 274, loss: 3.0627913951873778, acc: 0.25016000866889954, test loss: 3.1943138360977175, test acc: 0.08104000240564346\n",
      "epoch: 275, loss: 3.062486672401428, acc: 0.24936001002788544, test loss: 3.1948394060134886, test acc: 0.08007999509572983\n",
      "epoch: 276, loss: 3.0620356798171997, acc: 0.2502400279045105, test loss: 3.1948972940444946, test acc: 0.0804000049829483\n",
      "epoch: 277, loss: 3.063124918937683, acc: 0.24783997237682343, test loss: 3.1946982860565187, test acc: 0.07983999699354172\n",
      "epoch: 278, loss: 3.0626922130584715, acc: 0.24928000569343567, test loss: 3.194471025466919, test acc: 0.08008000254631042\n",
      "epoch: 279, loss: 3.0636286973953246, acc: 0.24776001274585724, test loss: 3.194706130027771, test acc: 0.08023999631404877\n",
      "epoch: 280, loss: 3.0627198696136473, acc: 0.2503199875354767, test loss: 3.194650959968567, test acc: 0.08152000606060028\n",
      "epoch: 281, loss: 3.062100052833557, acc: 0.25063997507095337, test loss: 3.194798541069031, test acc: 0.07968001067638397\n",
      "epoch: 282, loss: 3.061859917640686, acc: 0.2515999972820282, test loss: 3.194369411468506, test acc: 0.0801599994301796\n",
      "epoch: 283, loss: 3.062097430229187, acc: 0.24887998402118683, test loss: 3.1935681819915773, test acc: 0.08296000212430954\n",
      "epoch: 284, loss: 3.0610632419586183, acc: 0.25224000215530396, test loss: 3.1947160005569457, test acc: 0.08184000849723816\n",
      "epoch: 285, loss: 3.0607621669769287, acc: 0.25336000323295593, test loss: 3.1944757223129274, test acc: 0.0812000036239624\n",
      "epoch: 286, loss: 3.062094783782959, acc: 0.2504799962043762, test loss: 3.193911147117615, test acc: 0.08104000240564346\n",
      "epoch: 287, loss: 3.0624744415283205, acc: 0.24927997589111328, test loss: 3.1944241523742676, test acc: 0.08135999739170074\n",
      "epoch: 288, loss: 3.062916398048401, acc: 0.24824002385139465, test loss: 3.194573473930359, test acc: 0.08152000606060028\n",
      "epoch: 289, loss: 3.0609692573547362, acc: 0.2510400414466858, test loss: 3.1939968824386598, test acc: 0.08031999319791794\n",
      "epoch: 290, loss: 3.0613982677459717, acc: 0.25151997804641724, test loss: 3.1945075511932375, test acc: 0.08128000795841217\n",
      "epoch: 291, loss: 3.0612240076065063, acc: 0.25280001759529114, test loss: 3.193734884262085, test acc: 0.08080000430345535\n",
      "epoch: 292, loss: 3.0626006841659548, acc: 0.24847999215126038, test loss: 3.1951660394668577, test acc: 0.08063999563455582\n",
      "epoch: 293, loss: 3.0622525215148926, acc: 0.24872000515460968, test loss: 3.193323254585266, test acc: 0.08159999549388885\n",
      "epoch: 294, loss: 3.062773656845093, acc: 0.24832001328468323, test loss: 3.1940231800079344, test acc: 0.08264000713825226\n",
      "epoch: 295, loss: 3.0612789154052735, acc: 0.2513599991798401, test loss: 3.194856786727905, test acc: 0.08032000809907913\n",
      "epoch: 296, loss: 3.061238431930542, acc: 0.2519199848175049, test loss: 3.1942772388458254, test acc: 0.08032000064849854\n",
      "epoch: 297, loss: 3.0606721162796022, acc: 0.2536799907684326, test loss: 3.194003176689148, test acc: 0.08104000985622406\n",
      "epoch: 298, loss: 3.0607990264892577, acc: 0.25248000025749207, test loss: 3.194393444061279, test acc: 0.08048000186681747\n",
      "epoch: 299, loss: 3.061052942276001, acc: 0.25143998861312866, test loss: 3.1939974546432497, test acc: 0.0793599933385849\n",
      "epoch: 300, loss: 3.060546565055847, acc: 0.2524799704551697, test loss: 3.1942782640457152, test acc: 0.08151999861001968\n",
      "epoch: 301, loss: 3.0611262798309324, acc: 0.2518400251865387, test loss: 3.1940887451171873, test acc: 0.08111999928951263\n",
      "epoch: 302, loss: 3.060272979736328, acc: 0.252560019493103, test loss: 3.194026303291321, test acc: 0.08079999685287476\n",
      "epoch: 303, loss: 3.0598058462142945, acc: 0.2520800232887268, test loss: 3.1947787046432494, test acc: 0.08032000064849854\n",
      "epoch: 304, loss: 3.0608533143997194, acc: 0.25231999158859253, test loss: 3.19441020488739, test acc: 0.08151999861001968\n",
      "epoch: 305, loss: 3.0613462209701536, acc: 0.25120002031326294, test loss: 3.193859505653381, test acc: 0.08055999130010605\n",
      "epoch: 306, loss: 3.060768699645996, acc: 0.25120002031326294, test loss: 3.19451642036438, test acc: 0.08167999982833862\n",
      "epoch: 307, loss: 3.060069274902344, acc: 0.2539200186729431, test loss: 3.1933894634246824, test acc: 0.0825599879026413\n",
      "epoch: 308, loss: 3.059841847419739, acc: 0.2539199888706207, test loss: 3.1937724590301513, test acc: 0.07999999821186066\n",
      "epoch: 309, loss: 3.059885549545288, acc: 0.25359997153282166, test loss: 3.1942459106445313, test acc: 0.08111999928951263\n",
      "epoch: 310, loss: 3.060238575935364, acc: 0.25280001759529114, test loss: 3.1936913251876833, test acc: 0.08088000118732452\n",
      "epoch: 311, loss: 3.0595425844192503, acc: 0.2528800070285797, test loss: 3.1939341545104982, test acc: 0.08128000795841217\n",
      "epoch: 312, loss: 3.059712362289429, acc: 0.2539199888706207, test loss: 3.1939444303512574, test acc: 0.08071999251842499\n",
      "epoch: 313, loss: 3.061347770690918, acc: 0.2505599856376648, test loss: 3.194836401939392, test acc: 0.0811999961733818\n",
      "epoch: 314, loss: 3.0615644454956055, acc: 0.2504799962043762, test loss: 3.193851089477539, test acc: 0.08112000674009323\n",
      "epoch: 315, loss: 3.0616458654403687, acc: 0.2513599991798401, test loss: 3.1939377784729004, test acc: 0.08144000917673111\n",
      "epoch: 316, loss: 3.060743880271912, acc: 0.25151997804641724, test loss: 3.195316767692566, test acc: 0.07800000160932541\n",
      "epoch: 317, loss: 3.0616616010665894, acc: 0.2499999701976776, test loss: 3.194456911087036, test acc: 0.08151999115943909\n",
      "epoch: 318, loss: 3.062099647521973, acc: 0.2500799894332886, test loss: 3.194068765640259, test acc: 0.07992000132799149\n",
      "epoch: 319, loss: 3.0604999542236326, acc: 0.25088000297546387, test loss: 3.194087338447571, test acc: 0.08047999441623688\n",
      "epoch: 320, loss: 3.059817981719971, acc: 0.2518399953842163, test loss: 3.193627667427063, test acc: 0.08143999427556992\n",
      "epoch: 321, loss: 3.0595153093338014, acc: 0.25248000025749207, test loss: 3.193686318397522, test acc: 0.08216000348329544\n",
      "epoch: 322, loss: 3.06032395362854, acc: 0.25280001759529114, test loss: 3.1939970016479493, test acc: 0.08135999739170074\n",
      "epoch: 323, loss: 3.061650013923645, acc: 0.24887999892234802, test loss: 3.193861699104309, test acc: 0.08007999509572983\n",
      "epoch: 324, loss: 3.0597681283950804, acc: 0.25328001379966736, test loss: 3.194519543647766, test acc: 0.07959999889135361\n",
      "epoch: 325, loss: 3.059311270713806, acc: 0.25287994742393494, test loss: 3.1940868854522706, test acc: 0.08071999251842499\n",
      "epoch: 326, loss: 3.0603072166442873, acc: 0.2516799867153168, test loss: 3.19433856010437, test acc: 0.07919999957084656\n",
      "epoch: 327, loss: 3.0619056701660154, acc: 0.2492000162601471, test loss: 3.1947628259658813, test acc: 0.08216000348329544\n",
      "epoch: 328, loss: 3.0601277589797973, acc: 0.25151997804641724, test loss: 3.1934753894805907, test acc: 0.08160000294446945\n",
      "epoch: 329, loss: 3.060283637046814, acc: 0.2520799934864044, test loss: 3.194314742088318, test acc: 0.08144000917673111\n",
      "epoch: 330, loss: 3.059850311279297, acc: 0.2515999972820282, test loss: 3.193804478645325, test acc: 0.08256000280380249\n",
      "epoch: 331, loss: 3.0613935708999636, acc: 0.24872000515460968, test loss: 3.194128942489624, test acc: 0.08151999861001968\n",
      "epoch: 332, loss: 3.059569525718689, acc: 0.25224000215530396, test loss: 3.193578362464905, test acc: 0.08207999914884567\n",
      "epoch: 333, loss: 3.060060477256775, acc: 0.25248000025749207, test loss: 3.1949622869491576, test acc: 0.0804000049829483\n",
      "epoch: 334, loss: 3.060084414482117, acc: 0.2527199983596802, test loss: 3.193509578704834, test acc: 0.08135999739170074\n",
      "epoch: 335, loss: 3.061094331741333, acc: 0.25040000677108765, test loss: 3.1937764167785643, test acc: 0.08184000104665756\n",
      "epoch: 336, loss: 3.0606993675231933, acc: 0.2518399953842163, test loss: 3.1940863847732546, test acc: 0.08143999427556992\n",
      "epoch: 337, loss: 3.059846353530884, acc: 0.25352001190185547, test loss: 3.1937146186828613, test acc: 0.08240000903606415\n",
      "epoch: 338, loss: 3.0596598625183105, acc: 0.2513599991798401, test loss: 3.1937772750854494, test acc: 0.08208000659942627\n",
      "epoch: 339, loss: 3.061742162704468, acc: 0.24872000515460968, test loss: 3.1949447870254515, test acc: 0.07976000010967255\n",
      "epoch: 340, loss: 3.0604594230651854, acc: 0.2515999972820282, test loss: 3.1931102752685545, test acc: 0.08288000524044037\n",
      "epoch: 341, loss: 3.0610403299331663, acc: 0.2516799867153168, test loss: 3.193581986427307, test acc: 0.08272001147270203\n",
      "epoch: 342, loss: 3.0597776651382445, acc: 0.2531999945640564, test loss: 3.194266414642334, test acc: 0.0812000036239624\n",
      "epoch: 343, loss: 3.0592355728149414, acc: 0.25224000215530396, test loss: 3.193800520896912, test acc: 0.0825599953532219\n",
      "epoch: 344, loss: 3.0604085683822633, acc: 0.25336000323295593, test loss: 3.1943445920944216, test acc: 0.08079999685287476\n",
      "epoch: 345, loss: 3.0604667901992797, acc: 0.2531200051307678, test loss: 3.195472502708435, test acc: 0.07752000540494919\n",
      "epoch: 346, loss: 3.060485601425171, acc: 0.25200000405311584, test loss: 3.193583607673645, test acc: 0.08215999603271484\n",
      "epoch: 347, loss: 3.059891629219055, acc: 0.2523999810218811, test loss: 3.1939241886138916, test acc: 0.08135999739170074\n",
      "epoch: 348, loss: 3.0594013929367065, acc: 0.2526399791240692, test loss: 3.1937289953231813, test acc: 0.08239999413490295\n",
      "epoch: 349, loss: 3.0597226142883303, acc: 0.25359997153282166, test loss: 3.194190192222595, test acc: 0.08183999359607697\n",
      "epoch: 350, loss: 3.061313343048096, acc: 0.2515999972820282, test loss: 3.195129084587097, test acc: 0.07999999821186066\n",
      "epoch: 351, loss: 3.061663842201233, acc: 0.24863998591899872, test loss: 3.1937270402908324, test acc: 0.0828000009059906\n",
      "epoch: 352, loss: 3.0590227842330933, acc: 0.25536003708839417, test loss: 3.19374418258667, test acc: 0.08055999875068665\n",
      "epoch: 353, loss: 3.060097670555115, acc: 0.2524000108242035, test loss: 3.1939951181411743, test acc: 0.08207999914884567\n",
      "epoch: 354, loss: 3.060397434234619, acc: 0.2526400089263916, test loss: 3.1937146902084352, test acc: 0.0820000022649765\n",
      "epoch: 355, loss: 3.0604036331176756, acc: 0.2539200186729431, test loss: 3.1936103820800783, test acc: 0.08112000674009323\n",
      "epoch: 356, loss: 3.0596181631088255, acc: 0.25279998779296875, test loss: 3.1937104940414427, test acc: 0.08168000727891922\n",
      "epoch: 357, loss: 3.059418058395386, acc: 0.2520800232887268, test loss: 3.1938201665878294, test acc: 0.08135999739170074\n",
      "epoch: 358, loss: 3.0596724271774294, acc: 0.25384002923965454, test loss: 3.1942039728164673, test acc: 0.08031999319791794\n",
      "epoch: 359, loss: 3.058890461921692, acc: 0.254720002412796, test loss: 3.1934486865997314, test acc: 0.08256000280380249\n",
      "epoch: 360, loss: 3.0590759038925173, acc: 0.2534399926662445, test loss: 3.1934030532836912, test acc: 0.08408000320196152\n",
      "epoch: 361, loss: 3.0588997840881347, acc: 0.25464001297950745, test loss: 3.193826460838318, test acc: 0.08088000118732452\n",
      "epoch: 362, loss: 3.05961217880249, acc: 0.25384002923965454, test loss: 3.193938207626343, test acc: 0.08151999861001968\n",
      "epoch: 363, loss: 3.0588005781173706, acc: 0.2539999783039093, test loss: 3.1942384243011475, test acc: 0.08159999549388885\n",
      "epoch: 364, loss: 3.058526086807251, acc: 0.25543999671936035, test loss: 3.1946820497512816, test acc: 0.08111999928951263\n",
      "epoch: 365, loss: 3.0597534656524656, acc: 0.25168001651763916, test loss: 3.1936301946640016, test acc: 0.08143998682498932\n",
      "epoch: 366, loss: 3.060337519645691, acc: 0.251120001077652, test loss: 3.194433641433716, test acc: 0.08071999251842499\n",
      "epoch: 367, loss: 3.0594512224197388, acc: 0.25231999158859253, test loss: 3.1935177087783813, test acc: 0.0828000009059906\n",
      "epoch: 368, loss: 3.05890429019928, acc: 0.2537600100040436, test loss: 3.1943498611450196, test acc: 0.07999999821186066\n",
      "epoch: 369, loss: 3.0596272230148314, acc: 0.2536799907684326, test loss: 3.193435549736023, test acc: 0.08151999861001968\n",
      "epoch: 370, loss: 3.059646463394165, acc: 0.2526399791240692, test loss: 3.1945359230041506, test acc: 0.08007999509572983\n",
      "epoch: 371, loss: 3.06025493144989, acc: 0.2512800097465515, test loss: 3.1944253921508787, test acc: 0.0809599906206131\n",
      "epoch: 372, loss: 3.058605170249939, acc: 0.25519999861717224, test loss: 3.193684220314026, test acc: 0.08231999725103378\n",
      "epoch: 373, loss: 3.059165024757385, acc: 0.25383999943733215, test loss: 3.195430588722229, test acc: 0.08135999739170074\n",
      "epoch: 374, loss: 3.0603147745132446, acc: 0.25200000405311584, test loss: 3.1936370134353638, test acc: 0.08055999875068665\n",
      "epoch: 375, loss: 3.058816981315613, acc: 0.25543999671936035, test loss: 3.1941329717636107, test acc: 0.08167999237775803\n",
      "epoch: 376, loss: 3.058491063117981, acc: 0.2550399899482727, test loss: 3.193504786491394, test acc: 0.08224000036716461\n",
      "epoch: 377, loss: 3.0582464933395386, acc: 0.25599998235702515, test loss: 3.193554902076721, test acc: 0.08232000470161438\n",
      "epoch: 378, loss: 3.0585540771484374, acc: 0.25439998507499695, test loss: 3.1937888145446776, test acc: 0.08288000524044037\n",
      "epoch: 379, loss: 3.0589869022369385, acc: 0.2543199956417084, test loss: 3.1939400911331175, test acc: 0.08183999359607697\n",
      "epoch: 380, loss: 3.058544898033142, acc: 0.25512000918388367, test loss: 3.1935914039611815, test acc: 0.08176000416278839\n",
      "epoch: 381, loss: 3.058119225502014, acc: 0.25647997856140137, test loss: 3.1943044662475586, test acc: 0.08056000620126724\n",
      "epoch: 382, loss: 3.0597893238067626, acc: 0.2516799867153168, test loss: 3.1933772563934326, test acc: 0.08232001215219498\n",
      "epoch: 383, loss: 3.0584792613983156, acc: 0.2542400062084198, test loss: 3.1936065435409544, test acc: 0.0828000009059906\n",
      "epoch: 384, loss: 3.0587466239929197, acc: 0.2540000081062317, test loss: 3.194322443008423, test acc: 0.08088000118732452\n",
      "epoch: 385, loss: 3.059684467315674, acc: 0.25303998589515686, test loss: 3.193846249580383, test acc: 0.08207999914884567\n",
      "epoch: 386, loss: 3.058577227592468, acc: 0.2542399764060974, test loss: 3.193988084793091, test acc: 0.08032000809907913\n",
      "epoch: 387, loss: 3.057452440261841, acc: 0.2567199766635895, test loss: 3.1933987617492674, test acc: 0.08215999603271484\n",
      "epoch: 388, loss: 3.058067560195923, acc: 0.25488001108169556, test loss: 3.1933018922805787, test acc: 0.08215999603271484\n",
      "epoch: 389, loss: 3.057598924636841, acc: 0.2574400305747986, test loss: 3.1938108921051027, test acc: 0.0817599967122078\n",
      "epoch: 390, loss: 3.057067704200745, acc: 0.25655999779701233, test loss: 3.193805694580078, test acc: 0.0825599879026413\n",
      "epoch: 391, loss: 3.058213400840759, acc: 0.25624001026153564, test loss: 3.194100832939148, test acc: 0.08080000430345535\n",
      "epoch: 392, loss: 3.0591861248016357, acc: 0.2539999783039093, test loss: 3.193580174446106, test acc: 0.08207999914884567\n",
      "epoch: 393, loss: 3.0573970556259153, acc: 0.25624001026153564, test loss: 3.194008946418762, test acc: 0.0801599994301796\n",
      "epoch: 394, loss: 3.0574548721313475, acc: 0.2552800178527832, test loss: 3.1946419954299925, test acc: 0.08159999549388885\n",
      "epoch: 395, loss: 3.058272194862366, acc: 0.25568002462387085, test loss: 3.1931141138076784, test acc: 0.08184000104665756\n",
      "epoch: 396, loss: 3.0588428020477294, acc: 0.2553599774837494, test loss: 3.193615198135376, test acc: 0.08111999928951263\n",
      "epoch: 397, loss: 3.0579580783843996, acc: 0.2555200159549713, test loss: 3.19420440196991, test acc: 0.08080000430345535\n",
      "epoch: 398, loss: 3.0582775831222535, acc: 0.2542399764060974, test loss: 3.194325661659241, test acc: 0.08111999928951263\n",
      "epoch: 399, loss: 3.0595642805099486, acc: 0.25383999943733215, test loss: 3.19381844997406, test acc: 0.08151999861001968\n",
      "epoch: 400, loss: 3.058196783065796, acc: 0.2551199793815613, test loss: 3.1933441877365114, test acc: 0.0820000022649765\n",
      "epoch: 401, loss: 3.0575996160507204, acc: 0.25599998235702515, test loss: 3.194864821434021, test acc: 0.07952000200748444\n",
      "epoch: 402, loss: 3.0575175523757934, acc: 0.2555200159549713, test loss: 3.1935801267623902, test acc: 0.08183999359607697\n",
      "epoch: 403, loss: 3.0568336725234984, acc: 0.2580000162124634, test loss: 3.194032597541809, test acc: 0.0828000083565712\n",
      "epoch: 404, loss: 3.0576128005981444, acc: 0.2553599774837494, test loss: 3.1937403202056887, test acc: 0.08191999793052673\n",
      "epoch: 405, loss: 3.0577235221862793, acc: 0.2560800015926361, test loss: 3.193856692314148, test acc: 0.08192000538110733\n",
      "epoch: 406, loss: 3.0587514638900757, acc: 0.2536799907684326, test loss: 3.194388222694397, test acc: 0.08079999685287476\n",
      "epoch: 407, loss: 3.0580262184143066, acc: 0.25543999671936035, test loss: 3.193987250328064, test acc: 0.08192000538110733\n",
      "epoch: 408, loss: 3.0587997674942016, acc: 0.25496000051498413, test loss: 3.194149684906006, test acc: 0.08104000240564346\n",
      "epoch: 409, loss: 3.058324861526489, acc: 0.25487998127937317, test loss: 3.1943423986434936, test acc: 0.08208000659942627\n",
      "epoch: 410, loss: 3.058317995071411, acc: 0.25567999482154846, test loss: 3.1934250354766847, test acc: 0.08144000917673111\n",
      "epoch: 411, loss: 3.057721424102783, acc: 0.2556000053882599, test loss: 3.193813943862915, test acc: 0.0819999948143959\n",
      "epoch: 412, loss: 3.0578009843826295, acc: 0.2555200159549713, test loss: 3.1938409328460695, test acc: 0.08168000727891922\n",
      "epoch: 413, loss: 3.058897066116333, acc: 0.2534399926662445, test loss: 3.193917989730835, test acc: 0.08247999846935272\n",
      "epoch: 414, loss: 3.05782527923584, acc: 0.254720002412796, test loss: 3.193681168556213, test acc: 0.08264000713825226\n",
      "epoch: 415, loss: 3.0579262495040895, acc: 0.25496000051498413, test loss: 3.1934695482254027, test acc: 0.08184000104665756\n",
      "epoch: 416, loss: 3.056879925727844, acc: 0.2555199861526489, test loss: 3.1935471296310425, test acc: 0.0820000022649765\n",
      "epoch: 417, loss: 3.0573946952819826, acc: 0.2555199861526489, test loss: 3.1939157485961913, test acc: 0.08055999875068665\n",
      "epoch: 418, loss: 3.0578541994094848, acc: 0.2556000053882599, test loss: 3.193654942512512, test acc: 0.08143999427556992\n",
      "epoch: 419, loss: 3.0573434114456175, acc: 0.2555999755859375, test loss: 3.1933820724487303, test acc: 0.08207999914884567\n",
      "epoch: 420, loss: 3.0571094274520876, acc: 0.25519996881484985, test loss: 3.193598008155823, test acc: 0.08152000606060028\n",
      "epoch: 421, loss: 3.058121180534363, acc: 0.2564000189304352, test loss: 3.1945497512817385, test acc: 0.08176000416278839\n",
      "epoch: 422, loss: 3.057137894630432, acc: 0.25679999589920044, test loss: 3.1936344623565676, test acc: 0.08288000524044037\n",
      "epoch: 423, loss: 3.056898856163025, acc: 0.2566399872303009, test loss: 3.194140839576721, test acc: 0.08128000795841217\n",
      "epoch: 424, loss: 3.0573979377746583, acc: 0.2571199834346771, test loss: 3.1938555002212525, test acc: 0.08336000144481659\n",
      "epoch: 425, loss: 3.0581651449203493, acc: 0.2551199793815613, test loss: 3.19365394115448, test acc: 0.08191999793052673\n",
      "epoch: 426, loss: 3.0567514657974244, acc: 0.2572799623012543, test loss: 3.193832755088806, test acc: 0.0825599953532219\n",
      "epoch: 427, loss: 3.0565786361694336, acc: 0.2579199969768524, test loss: 3.1944813251495363, test acc: 0.08128000795841217\n",
      "epoch: 428, loss: 3.057314658164978, acc: 0.2553599774837494, test loss: 3.193638324737549, test acc: 0.08256000280380249\n",
      "epoch: 429, loss: 3.0567459583282472, acc: 0.25672000646591187, test loss: 3.193466591835022, test acc: 0.08192000538110733\n",
      "epoch: 430, loss: 3.0572530031204224, acc: 0.25440001487731934, test loss: 3.1941089391708375, test acc: 0.08271999657154083\n",
      "epoch: 431, loss: 3.0579636335372924, acc: 0.2564000189304352, test loss: 3.194088673591614, test acc: 0.08320000022649765\n",
      "epoch: 432, loss: 3.0580962896347046, acc: 0.2547200322151184, test loss: 3.1938257455825805, test acc: 0.08111999928951263\n",
      "epoch: 433, loss: 3.0571826219558718, acc: 0.2566399872303009, test loss: 3.194351553916931, test acc: 0.08088000118732452\n",
      "epoch: 434, loss: 3.0577277183532714, acc: 0.25543999671936035, test loss: 3.1935165882110597, test acc: 0.08216000348329544\n",
      "epoch: 435, loss: 3.05708429813385, acc: 0.2577599883079529, test loss: 3.1935893058776856, test acc: 0.08328000456094742\n",
      "epoch: 436, loss: 3.057236576080322, acc: 0.2568000257015228, test loss: 3.1938967227935793, test acc: 0.08247999846935272\n",
      "epoch: 437, loss: 3.056656765937805, acc: 0.2574400007724762, test loss: 3.1942843198776245, test acc: 0.08111999928951263\n",
      "epoch: 438, loss: 3.056997847557068, acc: 0.25672000646591187, test loss: 3.1934205293655396, test acc: 0.0820000022649765\n",
      "epoch: 439, loss: 3.058118534088135, acc: 0.2560800015926361, test loss: 3.1941211462020873, test acc: 0.08183999359607697\n",
      "epoch: 440, loss: 3.058435082435608, acc: 0.2555200159549713, test loss: 3.1933816194534304, test acc: 0.08144000172615051\n",
      "epoch: 441, loss: 3.056713175773621, acc: 0.25703996419906616, test loss: 3.19403555393219, test acc: 0.08128000050783157\n",
      "epoch: 442, loss: 3.057053065299988, acc: 0.25704002380371094, test loss: 3.193488073348999, test acc: 0.08192000538110733\n",
      "epoch: 443, loss: 3.0566675901412963, acc: 0.2587999999523163, test loss: 3.193629741668701, test acc: 0.08287999778985977\n",
      "epoch: 444, loss: 3.0563674211502074, acc: 0.2587200105190277, test loss: 3.1940215587615968, test acc: 0.08088000118732452\n",
      "epoch: 445, loss: 3.0568418502807617, acc: 0.25760000944137573, test loss: 3.1934307336807253, test acc: 0.08184000104665756\n",
      "epoch: 446, loss: 3.0564232587814333, acc: 0.2580000162124634, test loss: 3.193963050842285, test acc: 0.08240000903606415\n",
      "epoch: 447, loss: 3.05700044631958, acc: 0.25752002000808716, test loss: 3.193414497375488, test acc: 0.08343999832868576\n",
      "epoch: 448, loss: 3.0561450719833374, acc: 0.2566400170326233, test loss: 3.1941352605819704, test acc: 0.08256000280380249\n",
      "epoch: 449, loss: 3.0568027019500734, acc: 0.25655999779701233, test loss: 3.1935394287109373, test acc: 0.08135999739170074\n",
      "epoch: 450, loss: 3.0571266412734985, acc: 0.25616002082824707, test loss: 3.1936572074890135, test acc: 0.08183999359607697\n",
      "epoch: 451, loss: 3.0566631317138673, acc: 0.257999986410141, test loss: 3.193586826324463, test acc: 0.08224000036716461\n",
      "epoch: 452, loss: 3.0566720247268675, acc: 0.2580000162124634, test loss: 3.193592357635498, test acc: 0.08336000144481659\n",
      "epoch: 453, loss: 3.0580652475357057, acc: 0.2563199996948242, test loss: 3.1933392524719237, test acc: 0.08351999521255493\n",
      "epoch: 454, loss: 3.0574397087097167, acc: 0.2563999891281128, test loss: 3.193544888496399, test acc: 0.08271999657154083\n",
      "epoch: 455, loss: 3.057075309753418, acc: 0.256879985332489, test loss: 3.194228744506836, test acc: 0.08207999914884567\n",
      "epoch: 456, loss: 3.0562014102935793, acc: 0.25728002190589905, test loss: 3.19323468208313, test acc: 0.0804000049829483\n",
      "epoch: 457, loss: 3.056815028190613, acc: 0.2572000026702881, test loss: 3.194270944595337, test acc: 0.08192000538110733\n",
      "epoch: 458, loss: 3.056347632408142, acc: 0.2584800124168396, test loss: 3.193598508834839, test acc: 0.08256000280380249\n",
      "epoch: 459, loss: 3.058030128479004, acc: 0.2549600303173065, test loss: 3.1939586400985718, test acc: 0.0811999961733818\n",
      "epoch: 460, loss: 3.058751654624939, acc: 0.25248000025749207, test loss: 3.1940114498138428, test acc: 0.0828000009059906\n",
      "epoch: 461, loss: 3.057156300544739, acc: 0.2577599883079529, test loss: 3.193547582626343, test acc: 0.08256000280380249\n",
      "epoch: 462, loss: 3.056778144836426, acc: 0.25624001026153564, test loss: 3.1934170007705687, test acc: 0.08343999832868576\n",
      "epoch: 463, loss: 3.0561458110809325, acc: 0.258400022983551, test loss: 3.1938730239868165, test acc: 0.08055999875068665\n",
      "epoch: 464, loss: 3.0561688423156737, acc: 0.2582399845123291, test loss: 3.1937021255493163, test acc: 0.08207999914884567\n",
      "epoch: 465, loss: 3.0563878059387206, acc: 0.2579200267791748, test loss: 3.1949270963668823, test acc: 0.07944000512361526\n",
      "epoch: 466, loss: 3.056075644493103, acc: 0.257999986410141, test loss: 3.1944088459014894, test acc: 0.0825599953532219\n",
      "epoch: 467, loss: 3.0560608386993406, acc: 0.25735998153686523, test loss: 3.1933948278427122, test acc: 0.08247999846935272\n",
      "epoch: 468, loss: 3.056576633453369, acc: 0.25727999210357666, test loss: 3.194655752182007, test acc: 0.08064000308513641\n",
      "epoch: 469, loss: 3.05689857006073, acc: 0.25648000836372375, test loss: 3.193758010864258, test acc: 0.08151999861001968\n",
      "epoch: 470, loss: 3.055679678916931, acc: 0.25887998938560486, test loss: 3.1935617923736572, test acc: 0.08263999223709106\n",
      "epoch: 471, loss: 3.0557409286499024, acc: 0.2584799826145172, test loss: 3.193954825401306, test acc: 0.0828000083565712\n",
      "epoch: 472, loss: 3.0548895359039308, acc: 0.25920000672340393, test loss: 3.193123149871826, test acc: 0.08271999657154083\n",
      "epoch: 473, loss: 3.055341029167175, acc: 0.25968003273010254, test loss: 3.193683314323425, test acc: 0.08335999399423599\n",
      "epoch: 474, loss: 3.0557742357254027, acc: 0.2584799826145172, test loss: 3.1935163736343384, test acc: 0.08192000538110733\n",
      "epoch: 475, loss: 3.0551696538925173, acc: 0.2584800124168396, test loss: 3.1934683322906494, test acc: 0.08176000416278839\n",
      "epoch: 476, loss: 3.056118965148926, acc: 0.2571999728679657, test loss: 3.1934646129608155, test acc: 0.08216000348329544\n",
      "epoch: 477, loss: 3.0567260503768923, acc: 0.25655999779701233, test loss: 3.193910551071167, test acc: 0.08231999725103378\n",
      "epoch: 478, loss: 3.056837010383606, acc: 0.25672000646591187, test loss: 3.1936443567276003, test acc: 0.08256000280380249\n",
      "epoch: 479, loss: 3.0560508012771606, acc: 0.25808000564575195, test loss: 3.1935587882995606, test acc: 0.08279999345541\n",
      "epoch: 480, loss: 3.056412148475647, acc: 0.25672000646591187, test loss: 3.1939562797546386, test acc: 0.08144000172615051\n",
      "epoch: 481, loss: 3.0569488763809205, acc: 0.2571200132369995, test loss: 3.19500527381897, test acc: 0.07983999699354172\n",
      "epoch: 482, loss: 3.0560996532440186, acc: 0.25679999589920044, test loss: 3.194269061088562, test acc: 0.08295999467372894\n",
      "epoch: 483, loss: 3.05735559463501, acc: 0.2552799880504608, test loss: 3.1941244125366213, test acc: 0.08207999169826508\n",
      "epoch: 484, loss: 3.0563448905944823, acc: 0.25655999779701233, test loss: 3.1940195322036744, test acc: 0.08263999968767166\n",
      "epoch: 485, loss: 3.056556725502014, acc: 0.25464001297950745, test loss: 3.193704438209534, test acc: 0.08264000713825226\n",
      "epoch: 486, loss: 3.057024097442627, acc: 0.25760000944137573, test loss: 3.194178581237793, test acc: 0.08088000118732452\n",
      "epoch: 487, loss: 3.0563990116119384, acc: 0.25839999318122864, test loss: 3.1940759897232054, test acc: 0.08176000416278839\n",
      "epoch: 488, loss: 3.056617021560669, acc: 0.2566400170326233, test loss: 3.1937191486358643, test acc: 0.08312000334262848\n",
      "epoch: 489, loss: 3.0569481372833254, acc: 0.2571200132369995, test loss: 3.1945287466049193, test acc: 0.08007999509572983\n",
      "epoch: 490, loss: 3.055955100059509, acc: 0.2577599883079529, test loss: 3.193702745437622, test acc: 0.08303999155759811\n",
      "epoch: 491, loss: 3.0565168857574463, acc: 0.2565600275993347, test loss: 3.1937517642974855, test acc: 0.08279999345541\n",
      "epoch: 492, loss: 3.0573699951171873, acc: 0.254800021648407, test loss: 3.1933871030807497, test acc: 0.08256000280380249\n",
      "epoch: 493, loss: 3.056921195983887, acc: 0.2568800151348114, test loss: 3.193350005149841, test acc: 0.0820000022649765\n",
      "epoch: 494, loss: 3.0561712741851808, acc: 0.25736004114151, test loss: 3.1938786268234254, test acc: 0.08064000308513641\n",
      "epoch: 495, loss: 3.0559792041778566, acc: 0.2580000162124634, test loss: 3.1933024644851686, test acc: 0.08271999657154083\n",
      "epoch: 496, loss: 3.0556900262832642, acc: 0.25759997963905334, test loss: 3.1936049938201903, test acc: 0.08183999359607697\n",
      "epoch: 497, loss: 3.0565507888793944, acc: 0.2559199929237366, test loss: 3.193655848503113, test acc: 0.08279999345541\n",
      "epoch: 498, loss: 3.057435989379883, acc: 0.2537600100040436, test loss: 3.1930951118469237, test acc: 0.08271999657154083\n",
      "epoch: 499, loss: 3.0568137168884277, acc: 0.2571199834346771, test loss: 3.1944674015045167, test acc: 0.08312000334262848\n",
      "epoch: 500, loss: 3.0567028284072877, acc: 0.25703999400138855, test loss: 3.193933367729187, test acc: 0.08056000620126724\n",
      "epoch: 501, loss: 3.0558735847473146, acc: 0.2579200267791748, test loss: 3.1934914112091066, test acc: 0.08343999832868576\n",
      "epoch: 502, loss: 3.0564517736434937, acc: 0.257999986410141, test loss: 3.1943445920944216, test acc: 0.08103999495506287\n",
      "epoch: 503, loss: 3.055865454673767, acc: 0.2572000026702881, test loss: 3.19291832447052, test acc: 0.08336000144481659\n",
      "epoch: 504, loss: 3.055629324913025, acc: 0.2596000134944916, test loss: 3.193835639953613, test acc: 0.08263999968767166\n",
      "epoch: 505, loss: 3.0552746057510376, acc: 0.25888001918792725, test loss: 3.1941189765930176, test acc: 0.08047999441623688\n",
      "epoch: 506, loss: 3.0556702852249145, acc: 0.25760000944137573, test loss: 3.1933236837387087, test acc: 0.08399999886751175\n",
      "epoch: 507, loss: 3.0555647134780886, acc: 0.2592799961566925, test loss: 3.1931000709533692, test acc: 0.08168000727891922\n",
      "epoch: 508, loss: 3.0569875240325928, acc: 0.2568000257015228, test loss: 3.193959927558899, test acc: 0.08232001215219498\n",
      "epoch: 509, loss: 3.05679931640625, acc: 0.25648000836372375, test loss: 3.1931556701660155, test acc: 0.08224000036716461\n",
      "epoch: 510, loss: 3.056092619895935, acc: 0.2576799988746643, test loss: 3.194166398048401, test acc: 0.08376000076532364\n",
      "epoch: 511, loss: 3.0553110361099245, acc: 0.2581599950790405, test loss: 3.1928770780563354, test acc: 0.08303999900817871\n",
      "epoch: 512, loss: 3.055394768714905, acc: 0.2582399845123291, test loss: 3.1940444707870483, test acc: 0.08224000036716461\n",
      "epoch: 513, loss: 3.056538724899292, acc: 0.2566400170326233, test loss: 3.1940643072128294, test acc: 0.08296000212430954\n",
      "epoch: 514, loss: 3.0556147575378416, acc: 0.2577599883079529, test loss: 3.1939881324768065, test acc: 0.08152000606060028\n",
      "epoch: 515, loss: 3.0553756952285767, acc: 0.2580000162124634, test loss: 3.1936389207839966, test acc: 0.08191999793052673\n",
      "epoch: 516, loss: 3.055000567436218, acc: 0.2600800395011902, test loss: 3.194039011001587, test acc: 0.08135999739170074\n",
      "epoch: 517, loss: 3.0556129693984984, acc: 0.2589600384235382, test loss: 3.1935110330581664, test acc: 0.0835999995470047\n",
      "epoch: 518, loss: 3.054988431930542, acc: 0.25751999020576477, test loss: 3.19424455165863, test acc: 0.08128000795841217\n",
      "epoch: 519, loss: 3.0559269189834595, acc: 0.25832000374794006, test loss: 3.1940059423446656, test acc: 0.08184000104665756\n",
      "epoch: 520, loss: 3.0561776161193848, acc: 0.25752002000808716, test loss: 3.193617105484009, test acc: 0.08144000172615051\n",
      "epoch: 521, loss: 3.0556519508361815, acc: 0.25727999210357666, test loss: 3.1934009313583376, test acc: 0.08231999725103378\n",
      "epoch: 522, loss: 3.0551241874694823, acc: 0.2590400278568268, test loss: 3.1941139936447143, test acc: 0.0820000022649765\n",
      "epoch: 523, loss: 3.0550102949142457, acc: 0.25967997312545776, test loss: 3.1928921222686766, test acc: 0.08239999413490295\n",
      "epoch: 524, loss: 3.0556249141693117, acc: 0.2574400305747986, test loss: 3.193759799003601, test acc: 0.08247999846935272\n",
      "epoch: 525, loss: 3.0561471223831176, acc: 0.2569600045681, test loss: 3.1941219091415407, test acc: 0.0820000022649765\n",
      "epoch: 526, loss: 3.0567046642303466, acc: 0.25760000944137573, test loss: 3.1930662393569946, test acc: 0.08119998872280121\n",
      "epoch: 527, loss: 3.0554365634918215, acc: 0.2584800124168396, test loss: 3.1940464973449707, test acc: 0.08327999711036682\n",
      "epoch: 528, loss: 3.0552985668182373, acc: 0.2584800124168396, test loss: 3.1943670511245728, test acc: 0.0820000022649765\n",
      "epoch: 529, loss: 3.0556322574615478, acc: 0.2585600018501282, test loss: 3.1929601430892944, test acc: 0.08263999223709106\n",
      "epoch: 530, loss: 3.0561967372894285, acc: 0.2582400441169739, test loss: 3.193616580963135, test acc: 0.08232000470161438\n",
      "epoch: 531, loss: 3.0553073406219484, acc: 0.25944000482559204, test loss: 3.1936789035797117, test acc: 0.08184000104665756\n",
      "epoch: 532, loss: 3.0555538654327394, acc: 0.2574400305747986, test loss: 3.193817448616028, test acc: 0.08159999549388885\n",
      "epoch: 533, loss: 3.0547580242156984, acc: 0.2597599923610687, test loss: 3.193236780166626, test acc: 0.08256000280380249\n",
      "epoch: 534, loss: 3.054000473022461, acc: 0.2613600194454193, test loss: 3.1931782722473145, test acc: 0.0828000009059906\n",
      "epoch: 535, loss: 3.054245352745056, acc: 0.2600800395011902, test loss: 3.193657875061035, test acc: 0.0819999948143959\n",
      "epoch: 536, loss: 3.055045962333679, acc: 0.258400022983551, test loss: 3.193854546546936, test acc: 0.08320000022649765\n",
      "epoch: 537, loss: 3.0566814661026003, acc: 0.2575199604034424, test loss: 3.193607521057129, test acc: 0.08271999657154083\n",
      "epoch: 538, loss: 3.0548874616622923, acc: 0.2589600384235382, test loss: 3.1936023473739623, test acc: 0.08144000172615051\n",
      "epoch: 539, loss: 3.0561842203140257, acc: 0.2576799988746643, test loss: 3.193938159942627, test acc: 0.08256000280380249\n",
      "epoch: 540, loss: 3.054664897918701, acc: 0.25944000482559204, test loss: 3.193156933784485, test acc: 0.08247999846935272\n",
      "epoch: 541, loss: 3.0551926612854006, acc: 0.25936001539230347, test loss: 3.193831729888916, test acc: 0.08288000524044037\n",
      "epoch: 542, loss: 3.0547666788101195, acc: 0.2587199807167053, test loss: 3.19305214881897, test acc: 0.08399999886751175\n",
      "epoch: 543, loss: 3.0541581869125367, acc: 0.2608799934387207, test loss: 3.1937875032424925, test acc: 0.08384000509977341\n",
      "epoch: 544, loss: 3.0552878856658934, acc: 0.2581599950790405, test loss: 3.1934088468551636, test acc: 0.08256000280380249\n",
      "epoch: 545, loss: 3.0567140340805055, acc: 0.2560800015926361, test loss: 3.1932182788848875, test acc: 0.0820000022649765\n",
      "epoch: 546, loss: 3.056771755218506, acc: 0.2559199929237366, test loss: 3.1934937238693237, test acc: 0.08344000577926636\n",
      "epoch: 547, loss: 3.0552946805953978, acc: 0.2581599950790405, test loss: 3.1939523696899412, test acc: 0.08272000402212143\n",
      "epoch: 548, loss: 3.055878257751465, acc: 0.2577599883079529, test loss: 3.193562698364258, test acc: 0.08176000416278839\n",
      "epoch: 549, loss: 3.0552660465240478, acc: 0.2582400143146515, test loss: 3.193738055229187, test acc: 0.08288000524044037\n",
      "epoch: 550, loss: 3.0560383081436155, acc: 0.2573600113391876, test loss: 3.194133687019348, test acc: 0.0828000083565712\n",
      "epoch: 551, loss: 3.0558298587799073, acc: 0.2572000026702881, test loss: 3.193111848831177, test acc: 0.08176000416278839\n",
      "epoch: 552, loss: 3.0559319972991945, acc: 0.25647997856140137, test loss: 3.1942310333251953, test acc: 0.08096000552177429\n",
      "epoch: 553, loss: 3.054367208480835, acc: 0.2603999972343445, test loss: 3.1931650400161744, test acc: 0.08247999846935272\n",
      "epoch: 554, loss: 3.055095148086548, acc: 0.2593599855899811, test loss: 3.1932151556015014, test acc: 0.08264000713825226\n",
      "epoch: 555, loss: 3.055431914329529, acc: 0.2600000202655792, test loss: 3.193934512138367, test acc: 0.08288000524044037\n",
      "epoch: 556, loss: 3.054189133644104, acc: 0.2608800530433655, test loss: 3.193712258338928, test acc: 0.08311999589204788\n",
      "epoch: 557, loss: 3.055457329750061, acc: 0.2596000134944916, test loss: 3.1934309005737305, test acc: 0.08343999832868576\n",
      "epoch: 558, loss: 3.0552581548690796, acc: 0.25808000564575195, test loss: 3.19472815990448, test acc: 0.08207999914884567\n",
      "epoch: 559, loss: 3.0571191549301147, acc: 0.25703999400138855, test loss: 3.194146490097046, test acc: 0.08184000104665756\n",
      "epoch: 560, loss: 3.0541521310806274, acc: 0.25936001539230347, test loss: 3.1930452585220337, test acc: 0.08328000456094742\n",
      "epoch: 561, loss: 3.0558399677276613, acc: 0.2590400278568268, test loss: 3.19342622756958, test acc: 0.08288000524044037\n",
      "epoch: 562, loss: 3.054726243019104, acc: 0.25936001539230347, test loss: 3.1937050342559816, test acc: 0.08207999914884567\n",
      "epoch: 563, loss: 3.054745888710022, acc: 0.25887998938560486, test loss: 3.1935982704162598, test acc: 0.08240000158548355\n",
      "epoch: 564, loss: 3.0541107177734377, acc: 0.2592799961566925, test loss: 3.193131756782532, test acc: 0.08263999223709106\n",
      "epoch: 565, loss: 3.0540871620178223, acc: 0.2603200078010559, test loss: 3.1935175895690917, test acc: 0.08231998980045319\n",
      "epoch: 566, loss: 3.0542274951934814, acc: 0.260560005903244, test loss: 3.1935569524765013, test acc: 0.08247999846935272\n",
      "epoch: 567, loss: 3.054044270515442, acc: 0.2619199752807617, test loss: 3.193650507926941, test acc: 0.0820000022649765\n",
      "epoch: 568, loss: 3.054488444328308, acc: 0.2589600086212158, test loss: 3.193201518058777, test acc: 0.08023999631404877\n",
      "epoch: 569, loss: 3.0565260648727417, acc: 0.2555199861526489, test loss: 3.1939661264419557, test acc: 0.0828000009059906\n",
      "epoch: 570, loss: 3.0566385269165037, acc: 0.25624001026153564, test loss: 3.1946294784545897, test acc: 0.08287999778985977\n",
      "epoch: 571, loss: 3.0554259061813354, acc: 0.25759997963905334, test loss: 3.1936686754226686, test acc: 0.08256000280380249\n",
      "epoch: 572, loss: 3.054410982131958, acc: 0.2592799961566925, test loss: 3.1934794187545776, test acc: 0.0828000009059906\n",
      "epoch: 573, loss: 3.0538483619689942, acc: 0.26016002893447876, test loss: 3.1936995506286623, test acc: 0.08240000158548355\n",
      "epoch: 574, loss: 3.05437548160553, acc: 0.26023998856544495, test loss: 3.193408155441284, test acc: 0.08183999359607697\n",
      "epoch: 575, loss: 3.0546747922897337, acc: 0.2582399845123291, test loss: 3.1931308031082155, test acc: 0.08335999399423599\n",
      "epoch: 576, loss: 3.054837536811829, acc: 0.25887998938560486, test loss: 3.1938074350357057, test acc: 0.08143999427556992\n",
      "epoch: 577, loss: 3.0540868520736693, acc: 0.2608799934387207, test loss: 3.194359040260315, test acc: 0.08216001093387604\n",
      "epoch: 578, loss: 3.0549108743667603, acc: 0.258400022983551, test loss: 3.193248987197876, test acc: 0.0820000022649765\n",
      "epoch: 579, loss: 3.054960584640503, acc: 0.25911998748779297, test loss: 3.192959356307983, test acc: 0.08135999739170074\n",
      "epoch: 580, loss: 3.0554604291915894, acc: 0.25784003734588623, test loss: 3.1940173387527464, test acc: 0.08311999589204788\n",
      "epoch: 581, loss: 3.054270887374878, acc: 0.26016002893447876, test loss: 3.1937931776046753, test acc: 0.08207999914884567\n",
      "epoch: 582, loss: 3.054412007331848, acc: 0.2595199942588806, test loss: 3.1936389923095705, test acc: 0.0803999975323677\n",
      "epoch: 583, loss: 3.0544621467590334, acc: 0.2611200213432312, test loss: 3.1934878826141357, test acc: 0.08392000198364258\n",
      "epoch: 584, loss: 3.054239368438721, acc: 0.2597599923610687, test loss: 3.193762493133545, test acc: 0.0817599967122078\n",
      "epoch: 585, loss: 3.054798626899719, acc: 0.2587199807167053, test loss: 3.1942370176315307, test acc: 0.08087999373674393\n",
      "epoch: 586, loss: 3.0540026426315308, acc: 0.26159998774528503, test loss: 3.1939504861831667, test acc: 0.08231999725103378\n",
      "epoch: 587, loss: 3.0550216913223265, acc: 0.2587200105190277, test loss: 3.1935348749160766, test acc: 0.08312000334262848\n",
      "epoch: 588, loss: 3.055355167388916, acc: 0.2576799988746643, test loss: 3.193437600135803, test acc: 0.08303999900817871\n",
      "epoch: 589, loss: 3.054424524307251, acc: 0.2600799798965454, test loss: 3.193188786506653, test acc: 0.08399999886751175\n",
      "epoch: 590, loss: 3.053889274597168, acc: 0.260560005903244, test loss: 3.1936980962753294, test acc: 0.08128000050783157\n",
      "epoch: 591, loss: 3.0542769908905028, acc: 0.2597600221633911, test loss: 3.193959856033325, test acc: 0.08152000606060028\n",
      "epoch: 592, loss: 3.0557101488113405, acc: 0.2565600275993347, test loss: 3.1935789346694947, test acc: 0.08240000158548355\n",
      "epoch: 593, loss: 3.055181360244751, acc: 0.2569600045681, test loss: 3.1935999155044557, test acc: 0.08151999861001968\n",
      "epoch: 594, loss: 3.0546688795089723, acc: 0.25967997312545776, test loss: 3.1937026739120484, test acc: 0.08167999982833862\n",
      "epoch: 595, loss: 3.054330015182495, acc: 0.25920000672340393, test loss: 3.1933131217956543, test acc: 0.08176000416278839\n",
      "epoch: 596, loss: 3.0544986486434937, acc: 0.25944000482559204, test loss: 3.1932737827301025, test acc: 0.08240000158548355\n",
      "epoch: 597, loss: 3.0546388626098633, acc: 0.2612000107765198, test loss: 3.1939239263534547, test acc: 0.08064000308513641\n",
      "epoch: 598, loss: 3.0539838314056396, acc: 0.2608800232410431, test loss: 3.193391036987305, test acc: 0.08303999900817871\n",
      "epoch: 599, loss: 3.054527187347412, acc: 0.25936001539230347, test loss: 3.1938607692718506, test acc: 0.08231999725103378\n",
      "epoch: 600, loss: 3.0536802768707276, acc: 0.2603200078010559, test loss: 3.192867159843445, test acc: 0.08320000022649765\n",
      "epoch: 601, loss: 3.054141974449158, acc: 0.2595999836921692, test loss: 3.193225646018982, test acc: 0.08176000416278839\n",
      "epoch: 602, loss: 3.0547760009765623, acc: 0.2592800259590149, test loss: 3.1940301656723022, test acc: 0.08192000538110733\n",
      "epoch: 603, loss: 3.053921437263489, acc: 0.2611199915409088, test loss: 3.1935615062713625, test acc: 0.08136000484228134\n",
      "epoch: 604, loss: 3.0532199859619142, acc: 0.2608799934387207, test loss: 3.193477201461792, test acc: 0.08135999739170074\n",
      "epoch: 605, loss: 3.0541512727737428, acc: 0.26072001457214355, test loss: 3.193820762634277, test acc: 0.08080000430345535\n",
      "epoch: 606, loss: 3.055340027809143, acc: 0.2580000162124634, test loss: 3.192254590988159, test acc: 0.08351999521255493\n",
      "epoch: 607, loss: 3.0555378437042235, acc: 0.2579200267791748, test loss: 3.194382667541504, test acc: 0.08159999549388885\n",
      "epoch: 608, loss: 3.054087281227112, acc: 0.2595199942588806, test loss: 3.193519687652588, test acc: 0.08216000348329544\n",
      "epoch: 609, loss: 3.0532601118087768, acc: 0.26071998476982117, test loss: 3.193499708175659, test acc: 0.08296000212430954\n",
      "epoch: 610, loss: 3.0538408041000364, acc: 0.2597599923610687, test loss: 3.1937727451324465, test acc: 0.0828000009059906\n",
      "epoch: 611, loss: 3.0560248851776124, acc: 0.25735998153686523, test loss: 3.1933761835098267, test acc: 0.08303999900817871\n",
      "epoch: 612, loss: 3.053448939323425, acc: 0.2627200186252594, test loss: 3.193885922431946, test acc: 0.08079999685287476\n",
      "epoch: 613, loss: 3.05350399017334, acc: 0.2608799636363983, test loss: 3.1929025173187258, test acc: 0.08367999643087387\n",
      "epoch: 614, loss: 3.053435206413269, acc: 0.2619200050830841, test loss: 3.1932293653488157, test acc: 0.08263999968767166\n",
      "epoch: 615, loss: 3.0541274547576904, acc: 0.260560005903244, test loss: 3.1942715883255004, test acc: 0.08239999413490295\n",
      "epoch: 616, loss: 3.054953908920288, acc: 0.26024001836776733, test loss: 3.193774938583374, test acc: 0.08111999928951263\n",
      "epoch: 617, loss: 3.055285358428955, acc: 0.2587200105190277, test loss: 3.1943875789642333, test acc: 0.08144000172615051\n",
      "epoch: 618, loss: 3.0562363862991333, acc: 0.25751999020576477, test loss: 3.1931708812713624, test acc: 0.08295999467372894\n",
      "epoch: 619, loss: 3.0543848991394045, acc: 0.26047998666763306, test loss: 3.192724680900574, test acc: 0.0846400037407875\n",
      "epoch: 620, loss: 3.053718161582947, acc: 0.2609599828720093, test loss: 3.1935366868972777, test acc: 0.0825599953532219\n",
      "epoch: 621, loss: 3.053029704093933, acc: 0.2619200050830841, test loss: 3.1932530641555785, test acc: 0.08367999643087387\n",
      "epoch: 622, loss: 3.0528373956680297, acc: 0.2613599896430969, test loss: 3.193413186073303, test acc: 0.08167999982833862\n",
      "epoch: 623, loss: 3.053300714492798, acc: 0.2609599828720093, test loss: 3.1930029153823853, test acc: 0.08368000388145447\n",
      "epoch: 624, loss: 3.053450417518616, acc: 0.2622399926185608, test loss: 3.193180727958679, test acc: 0.08328000456094742\n",
      "epoch: 625, loss: 3.053122115135193, acc: 0.26047998666763306, test loss: 3.193301773071289, test acc: 0.0820000022649765\n",
      "epoch: 626, loss: 3.0532646417617797, acc: 0.2608799934387207, test loss: 3.19315619468689, test acc: 0.08287999778985977\n",
      "epoch: 627, loss: 3.0540630340576174, acc: 0.2600800096988678, test loss: 3.193772053718567, test acc: 0.08336000144481659\n",
      "epoch: 628, loss: 3.054932141304016, acc: 0.25936001539230347, test loss: 3.192914438247681, test acc: 0.08400000631809235\n",
      "epoch: 629, loss: 3.053639364242554, acc: 0.2603999972343445, test loss: 3.193310809135437, test acc: 0.08152000606060028\n",
      "epoch: 630, loss: 3.053448486328125, acc: 0.26151999831199646, test loss: 3.1928393125534056, test acc: 0.08400000631809235\n",
      "epoch: 631, loss: 3.053212547302246, acc: 0.26072001457214355, test loss: 3.1930788278579714, test acc: 0.08240000903606415\n",
      "epoch: 632, loss: 3.0531066179275514, acc: 0.2619999945163727, test loss: 3.1935473918914794, test acc: 0.08271999657154083\n",
      "epoch: 633, loss: 3.052957224845886, acc: 0.2619200348854065, test loss: 3.193184232711792, test acc: 0.08231999725103378\n",
      "epoch: 634, loss: 3.0531661987304686, acc: 0.26128000020980835, test loss: 3.1929197549819945, test acc: 0.08271999657154083\n",
      "epoch: 635, loss: 3.0532429456710815, acc: 0.2619999945163727, test loss: 3.1937232971191407, test acc: 0.08152000606060028\n",
      "epoch: 636, loss: 3.053020787239075, acc: 0.261680006980896, test loss: 3.1931337833404543, test acc: 0.08231999725103378\n",
      "epoch: 637, loss: 3.0526863813400267, acc: 0.2619200348854065, test loss: 3.193100023269653, test acc: 0.08104000240564346\n",
      "epoch: 638, loss: 3.052726316452026, acc: 0.26360005140304565, test loss: 3.1933177947998046, test acc: 0.08104000240564346\n",
      "epoch: 639, loss: 3.05220627784729, acc: 0.26263996958732605, test loss: 3.193085265159607, test acc: 0.08232000470161438\n",
      "epoch: 640, loss: 3.054081583023071, acc: 0.260560005903244, test loss: 3.193270134925842, test acc: 0.08224000036716461\n",
      "epoch: 641, loss: 3.0543272256851197, acc: 0.2587200105190277, test loss: 3.193644571304321, test acc: 0.08080000430345535\n",
      "epoch: 642, loss: 3.0539074897766114, acc: 0.2616000175476074, test loss: 3.1931937456130983, test acc: 0.08271999657154083\n",
      "epoch: 643, loss: 3.054745817184448, acc: 0.2590399980545044, test loss: 3.1934327125549316, test acc: 0.0828000009059906\n",
      "epoch: 644, loss: 3.05390350818634, acc: 0.261680006980896, test loss: 3.1947070837020872, test acc: 0.08031999319791794\n",
      "epoch: 645, loss: 3.05410578250885, acc: 0.2598399817943573, test loss: 3.193575620651245, test acc: 0.08136000484228134\n",
      "epoch: 646, loss: 3.052975082397461, acc: 0.2624800205230713, test loss: 3.193176794052124, test acc: 0.08151999861001968\n",
      "epoch: 647, loss: 3.0525277137756346, acc: 0.262719988822937, test loss: 3.1928362607955934, test acc: 0.0835999995470047\n",
      "epoch: 648, loss: 3.052482771873474, acc: 0.2619200050830841, test loss: 3.193868041038513, test acc: 0.08071999996900558\n",
      "epoch: 649, loss: 3.053549337387085, acc: 0.2611200213432312, test loss: 3.194053387641907, test acc: 0.08135999739170074\n",
      "epoch: 650, loss: 3.053279900550842, acc: 0.2614400088787079, test loss: 3.1926321268081663, test acc: 0.08271999657154083\n",
      "epoch: 651, loss: 3.05330069065094, acc: 0.2612000107765198, test loss: 3.1931654691696165, test acc: 0.08167999982833862\n",
      "epoch: 652, loss: 3.0557960987091066, acc: 0.25672000646591187, test loss: 3.193050241470337, test acc: 0.08288000524044037\n",
      "epoch: 653, loss: 3.054126811027527, acc: 0.26016002893447876, test loss: 3.1933000564575194, test acc: 0.0835999995470047\n",
      "epoch: 654, loss: 3.0523661375045776, acc: 0.2626400291919708, test loss: 3.19288170337677, test acc: 0.08352000266313553\n",
      "epoch: 655, loss: 3.052699112892151, acc: 0.2625599801540375, test loss: 3.192875623703003, test acc: 0.08135999739170074\n",
      "epoch: 656, loss: 3.0534643650054933, acc: 0.2622399926185608, test loss: 3.1937160968780516, test acc: 0.08207999169826508\n",
      "epoch: 657, loss: 3.0528494358062743, acc: 0.2624800205230713, test loss: 3.1935835123062133, test acc: 0.08351999521255493\n",
      "epoch: 658, loss: 3.0532750368118284, acc: 0.26231998205184937, test loss: 3.192996287345886, test acc: 0.0846400037407875\n",
      "epoch: 659, loss: 3.053131031990051, acc: 0.2616800367832184, test loss: 3.192818784713745, test acc: 0.08144000172615051\n",
      "epoch: 660, loss: 3.0526453971862795, acc: 0.261680006980896, test loss: 3.193394732475281, test acc: 0.08151999861001968\n",
      "epoch: 661, loss: 3.053700566291809, acc: 0.26055997610092163, test loss: 3.1937453746795654, test acc: 0.08256000280380249\n",
      "epoch: 662, loss: 3.053904891014099, acc: 0.261680006980896, test loss: 3.193254828453064, test acc: 0.08239999413490295\n",
      "epoch: 663, loss: 3.0542980194091798, acc: 0.2603999972343445, test loss: 3.1929687023162843, test acc: 0.08376000821590424\n",
      "epoch: 664, loss: 3.0528493881225587, acc: 0.26183998584747314, test loss: 3.193409490585327, test acc: 0.08407999575138092\n",
      "epoch: 665, loss: 3.053208351135254, acc: 0.26071998476982117, test loss: 3.1944013118743895, test acc: 0.08176000416278839\n",
      "epoch: 666, loss: 3.053983998298645, acc: 0.2611200213432312, test loss: 3.1926482915878296, test acc: 0.08063999563455582\n",
      "epoch: 667, loss: 3.0536377906799315, acc: 0.2600000202655792, test loss: 3.1927420139312743, test acc: 0.08327999711036682\n",
      "epoch: 668, loss: 3.0531525373458863, acc: 0.26208001375198364, test loss: 3.194625663757324, test acc: 0.08055999875068665\n",
      "epoch: 669, loss: 3.0553589820861817, acc: 0.2577599883079529, test loss: 3.1933961391448973, test acc: 0.0828000083565712\n",
      "epoch: 670, loss: 3.054265522956848, acc: 0.2600000202655792, test loss: 3.193618655204773, test acc: 0.0809599980711937\n",
      "epoch: 671, loss: 3.053229308128357, acc: 0.2622399926185608, test loss: 3.1927579402923585, test acc: 0.08399999886751175\n",
      "epoch: 672, loss: 3.05260055065155, acc: 0.2632800042629242, test loss: 3.193293046951294, test acc: 0.08383999764919281\n",
      "epoch: 673, loss: 3.052874779701233, acc: 0.2609599828720093, test loss: 3.1930835247039795, test acc: 0.08183999359607697\n",
      "epoch: 674, loss: 3.0532340526580812, acc: 0.26263999938964844, test loss: 3.193138074874878, test acc: 0.08232000470161438\n",
      "epoch: 675, loss: 3.0547152042388914, acc: 0.2608799934387207, test loss: 3.1947181701660154, test acc: 0.0804000049829483\n",
      "epoch: 676, loss: 3.0540950775146483, acc: 0.2597599923610687, test loss: 3.1936431884765626, test acc: 0.08288000524044037\n",
      "epoch: 677, loss: 3.053550052642822, acc: 0.26104000210762024, test loss: 3.1932945013046266, test acc: 0.0836000069975853\n",
      "epoch: 678, loss: 3.0544620037078856, acc: 0.25944000482559204, test loss: 3.1923988342285154, test acc: 0.08231999725103378\n",
      "epoch: 679, loss: 3.0548789739608764, acc: 0.25975996255874634, test loss: 3.194442105293274, test acc: 0.08304000645875931\n",
      "epoch: 680, loss: 3.055108141899109, acc: 0.2590400278568268, test loss: 3.193790340423584, test acc: 0.08160000294446945\n",
      "epoch: 681, loss: 3.0540213108062746, acc: 0.2603999972343445, test loss: 3.1936147689819334, test acc: 0.08336000144481659\n",
      "epoch: 682, loss: 3.053074502944946, acc: 0.2619199752807617, test loss: 3.1928967237472534, test acc: 0.08423999696969986\n",
      "epoch: 683, loss: 3.0528183221817016, acc: 0.2613599896430969, test loss: 3.192871069908142, test acc: 0.08184000104665756\n",
      "epoch: 684, loss: 3.052607536315918, acc: 0.2624799907207489, test loss: 3.1930089235305785, test acc: 0.08367999643087387\n",
      "epoch: 685, loss: 3.0523406744003294, acc: 0.2637600004673004, test loss: 3.1927984237670897, test acc: 0.08231999725103378\n",
      "epoch: 686, loss: 3.0527981996536253, acc: 0.26159998774528503, test loss: 3.193276357650757, test acc: 0.0843999981880188\n",
      "epoch: 687, loss: 3.0522146463394164, acc: 0.2651200294494629, test loss: 3.1930418491363524, test acc: 0.08231999725103378\n",
      "epoch: 688, loss: 3.052077794075012, acc: 0.26287999749183655, test loss: 3.192807340621948, test acc: 0.08512000739574432\n",
      "epoch: 689, loss: 3.0526177883148193, acc: 0.2635200321674347, test loss: 3.19298734664917, test acc: 0.08335999399423599\n",
      "epoch: 690, loss: 3.0529805183410645, acc: 0.2610400319099426, test loss: 3.1937145948410035, test acc: 0.08263999968767166\n",
      "epoch: 691, loss: 3.0536065816879274, acc: 0.26047998666763306, test loss: 3.1931221008300783, test acc: 0.08416000008583069\n",
      "epoch: 692, loss: 3.0532704830169677, acc: 0.2608799934387207, test loss: 3.1933433294296263, test acc: 0.08271999657154083\n",
      "epoch: 693, loss: 3.052681565284729, acc: 0.26287999749183655, test loss: 3.193385910987854, test acc: 0.08399999141693115\n",
      "epoch: 694, loss: 3.054350996017456, acc: 0.25968000292778015, test loss: 3.1928510904312133, test acc: 0.08407999575138092\n",
      "epoch: 695, loss: 3.052486610412598, acc: 0.2624000310897827, test loss: 3.19301381111145, test acc: 0.08319999277591705\n",
      "epoch: 696, loss: 3.0527689695358275, acc: 0.2619200348854065, test loss: 3.1931091070175173, test acc: 0.08160000294446945\n",
      "epoch: 697, loss: 3.0522991180419923, acc: 0.26287999749183655, test loss: 3.1936936140060426, test acc: 0.08240000158548355\n",
      "epoch: 698, loss: 3.05295045375824, acc: 0.26080000400543213, test loss: 3.1926578521728515, test acc: 0.08535999804735184\n",
      "epoch: 699, loss: 3.053241729736328, acc: 0.26096001267433167, test loss: 3.1931522607803347, test acc: 0.08304000645875931\n",
      "epoch: 700, loss: 3.0525856971740724, acc: 0.2637600302696228, test loss: 3.192816424369812, test acc: 0.08367999643087387\n",
      "epoch: 701, loss: 3.0520620822906492, acc: 0.26368001103401184, test loss: 3.1925720453262327, test acc: 0.08336000144481659\n",
      "epoch: 702, loss: 3.0522674322128296, acc: 0.26288002729415894, test loss: 3.1928130626678466, test acc: 0.0846400037407875\n",
      "epoch: 703, loss: 3.0521599292755126, acc: 0.2639999985694885, test loss: 3.192826843261719, test acc: 0.08176000416278839\n",
      "epoch: 704, loss: 3.0525794506072996, acc: 0.2622400224208832, test loss: 3.1925923109054564, test acc: 0.08336000144481659\n",
      "epoch: 705, loss: 3.0517557144165037, acc: 0.26336002349853516, test loss: 3.192762565612793, test acc: 0.0843999981880188\n",
      "epoch: 706, loss: 3.0521114349365233, acc: 0.2648000121116638, test loss: 3.1937067031860353, test acc: 0.0820000022649765\n",
      "epoch: 707, loss: 3.052684783935547, acc: 0.2622400224208832, test loss: 3.1931866884231566, test acc: 0.08240000158548355\n",
      "epoch: 708, loss: 3.052574944496155, acc: 0.2630400061607361, test loss: 3.1926945209503175, test acc: 0.08167999237775803\n",
      "epoch: 709, loss: 3.0520185470581054, acc: 0.2622399926185608, test loss: 3.1933616399765015, test acc: 0.08216000348329544\n",
      "epoch: 710, loss: 3.0528735399246214, acc: 0.2619200050830841, test loss: 3.1931081295013426, test acc: 0.08376000076532364\n",
      "epoch: 711, loss: 3.0527907848358153, acc: 0.26175999641418457, test loss: 3.193905568122864, test acc: 0.08192000538110733\n",
      "epoch: 712, loss: 3.052684783935547, acc: 0.2619200348854065, test loss: 3.1932251930236815, test acc: 0.08279999345541\n",
      "epoch: 713, loss: 3.052767610549927, acc: 0.26239997148513794, test loss: 3.1928900241851808, test acc: 0.08312000334262848\n",
      "epoch: 714, loss: 3.0521520614624023, acc: 0.26312002539634705, test loss: 3.193132424354553, test acc: 0.08247999846935272\n",
      "epoch: 715, loss: 3.0522042989730833, acc: 0.26319998502731323, test loss: 3.1929033041000365, test acc: 0.08271999657154083\n",
      "epoch: 716, loss: 3.051655077934265, acc: 0.2630400061607361, test loss: 3.1926529884338377, test acc: 0.08543999493122101\n",
      "epoch: 717, loss: 3.051928973197937, acc: 0.2632000148296356, test loss: 3.193659257888794, test acc: 0.0812000036239624\n",
      "epoch: 718, loss: 3.052519345283508, acc: 0.261680006980896, test loss: 3.1928601026535035, test acc: 0.08367999643087387\n",
      "epoch: 719, loss: 3.051787805557251, acc: 0.2637600004673004, test loss: 3.193120312690735, test acc: 0.08320000022649765\n",
      "epoch: 720, loss: 3.0532694816589356, acc: 0.2619200348854065, test loss: 3.1925265073776243, test acc: 0.08424000442028046\n",
      "epoch: 721, loss: 3.0530388593673705, acc: 0.26128000020980835, test loss: 3.1929407358169555, test acc: 0.08303999900817871\n",
      "epoch: 722, loss: 3.0528467178344725, acc: 0.26175999641418457, test loss: 3.192735028266907, test acc: 0.08416000008583069\n",
      "epoch: 723, loss: 3.0522478103637694, acc: 0.2641599774360657, test loss: 3.1935800075531007, test acc: 0.08191999793052673\n",
      "epoch: 724, loss: 3.051821732521057, acc: 0.2635999917984009, test loss: 3.1933945655822753, test acc: 0.08184000104665756\n",
      "epoch: 725, loss: 3.0522025346755983, acc: 0.2635200023651123, test loss: 3.193316912651062, test acc: 0.08320000767707825\n",
      "epoch: 726, loss: 3.0522762060165407, acc: 0.2635200321674347, test loss: 3.192531180381775, test acc: 0.08336000144481659\n",
      "epoch: 727, loss: 3.0526508331298827, acc: 0.26232001185417175, test loss: 3.1935226202011107, test acc: 0.08167999237775803\n",
      "epoch: 728, loss: 3.051956582069397, acc: 0.26368001103401184, test loss: 3.1928046464920046, test acc: 0.08312000334262848\n",
      "epoch: 729, loss: 3.0519727230072022, acc: 0.26231998205184937, test loss: 3.192290258407593, test acc: 0.08416000008583069\n",
      "epoch: 730, loss: 3.0521663188934327, acc: 0.26319998502731323, test loss: 3.1929661512374876, test acc: 0.08183999359607697\n",
      "epoch: 731, loss: 3.052312231063843, acc: 0.26200002431869507, test loss: 3.1929643154144287, test acc: 0.08368000388145447\n",
      "epoch: 732, loss: 3.0529728174209594, acc: 0.26183995604515076, test loss: 3.1936081409454347, test acc: 0.08391999453306198\n",
      "epoch: 733, loss: 3.0548043966293337, acc: 0.25887995958328247, test loss: 3.192607855796814, test acc: 0.08431999385356903\n",
      "epoch: 734, loss: 3.054466700553894, acc: 0.25863999128341675, test loss: 3.193286657333374, test acc: 0.08207999914884567\n",
      "epoch: 735, loss: 3.0526180982589723, acc: 0.2624000012874603, test loss: 3.193882703781128, test acc: 0.08111999928951263\n",
      "epoch: 736, loss: 3.0523523569107054, acc: 0.2632800042629242, test loss: 3.192720651626587, test acc: 0.08215999603271484\n",
      "epoch: 737, loss: 3.0528857469558717, acc: 0.2624799907207489, test loss: 3.1929444789886476, test acc: 0.08392000943422318\n",
      "epoch: 738, loss: 3.052642345428467, acc: 0.2612000107765198, test loss: 3.192744994163513, test acc: 0.08407999575138092\n",
      "epoch: 739, loss: 3.051957607269287, acc: 0.262719988822937, test loss: 3.192744278907776, test acc: 0.08400000631809235\n",
      "epoch: 740, loss: 3.052040195465088, acc: 0.26319998502731323, test loss: 3.192713212966919, test acc: 0.0835999995470047\n",
      "epoch: 741, loss: 3.05328369140625, acc: 0.26200002431869507, test loss: 3.1934100866317747, test acc: 0.08088000118732452\n",
      "epoch: 742, loss: 3.0543128490447997, acc: 0.2592799663543701, test loss: 3.1942567586898805, test acc: 0.08231999725103378\n",
      "epoch: 743, loss: 3.0541160821914675, acc: 0.2600799798965454, test loss: 3.19293475151062, test acc: 0.0835999995470047\n",
      "epoch: 744, loss: 3.0529099702835083, acc: 0.26319998502731323, test loss: 3.1927075386047363, test acc: 0.08247999846935272\n",
      "epoch: 745, loss: 3.051824116706848, acc: 0.26367998123168945, test loss: 3.1936800479888916, test acc: 0.08167999982833862\n",
      "epoch: 746, loss: 3.0517250537872314, acc: 0.2637600004673004, test loss: 3.193453335762024, test acc: 0.08296000212430954\n",
      "epoch: 747, loss: 3.0525019645690916, acc: 0.262800008058548, test loss: 3.193623924255371, test acc: 0.08216000348329544\n",
      "epoch: 748, loss: 3.0521788120269777, acc: 0.26343998312950134, test loss: 3.193309998512268, test acc: 0.0828000009059906\n",
      "epoch: 749, loss: 3.052163314819336, acc: 0.26311999559402466, test loss: 3.1925215482711793, test acc: 0.08351999521255493\n",
      "epoch: 750, loss: 3.0520524978637695, acc: 0.26392000913619995, test loss: 3.1934290409088133, test acc: 0.08192000538110733\n",
      "epoch: 751, loss: 3.0528300523757936, acc: 0.2619200050830841, test loss: 3.1926217555999754, test acc: 0.08231999725103378\n",
      "epoch: 752, loss: 3.05262553691864, acc: 0.2624000012874603, test loss: 3.1932586669921874, test acc: 0.0809599980711937\n",
      "epoch: 753, loss: 3.0514846324920653, acc: 0.2635999917984009, test loss: 3.19309606552124, test acc: 0.08296000212430954\n",
      "epoch: 754, loss: 3.0517602920532227, acc: 0.26368004083633423, test loss: 3.193032670021057, test acc: 0.08207999914884567\n",
      "epoch: 755, loss: 3.051017737388611, acc: 0.26471999287605286, test loss: 3.1925155878067017, test acc: 0.08151999861001968\n",
      "epoch: 756, loss: 3.0511322259902953, acc: 0.2648800015449524, test loss: 3.1932857036590576, test acc: 0.08375999331474304\n",
      "epoch: 757, loss: 3.0510916709899902, acc: 0.26392000913619995, test loss: 3.1926027059555055, test acc: 0.08312000334262848\n",
      "epoch: 758, loss: 3.0513560295104982, acc: 0.2639999985694885, test loss: 3.192599868774414, test acc: 0.08343999087810516\n",
      "epoch: 759, loss: 3.0510759115219117, acc: 0.2651199996471405, test loss: 3.1932416439056395, test acc: 0.08336000144481659\n",
      "epoch: 760, loss: 3.0516820192337035, acc: 0.2630400061607361, test loss: 3.193176102638245, test acc: 0.08239999413490295\n",
      "epoch: 761, loss: 3.0524301528930664, acc: 0.2632000148296356, test loss: 3.193022608757019, test acc: 0.08176000416278839\n",
      "epoch: 762, loss: 3.052521014213562, acc: 0.2616000175476074, test loss: 3.1930782794952393, test acc: 0.08247999846935272\n",
      "epoch: 763, loss: 3.0546390771865846, acc: 0.2589600086212158, test loss: 3.193947196006775, test acc: 0.0820000022649765\n",
      "epoch: 764, loss: 3.0545567512512206, acc: 0.25968000292778015, test loss: 3.192900061607361, test acc: 0.0835999995470047\n",
      "epoch: 765, loss: 3.053739047050476, acc: 0.26208001375198364, test loss: 3.193819522857666, test acc: 0.08088000118732452\n",
      "epoch: 766, loss: 3.0527967691421507, acc: 0.261680006980896, test loss: 3.193043565750122, test acc: 0.08152000606060028\n",
      "epoch: 767, loss: 3.0525455713272094, acc: 0.26208001375198364, test loss: 3.1932231903076174, test acc: 0.08287999778985977\n",
      "epoch: 768, loss: 3.0517020225524902, acc: 0.2637600004673004, test loss: 3.193302297592163, test acc: 0.08208000659942627\n",
      "epoch: 769, loss: 3.0530580043792725, acc: 0.2612000107765198, test loss: 3.1935335397720337, test acc: 0.08184000104665756\n",
      "epoch: 770, loss: 3.0536254167556764, acc: 0.26072001457214355, test loss: 3.193053102493286, test acc: 0.08256001025438309\n",
      "epoch: 771, loss: 3.0537116289138795, acc: 0.2619999945163727, test loss: 3.19346170425415, test acc: 0.08231998980045319\n",
      "epoch: 772, loss: 3.053337740898132, acc: 0.26232001185417175, test loss: 3.193676257133484, test acc: 0.08104000240564346\n",
      "epoch: 773, loss: 3.0527127504348757, acc: 0.26287999749183655, test loss: 3.19332640171051, test acc: 0.08191999793052673\n",
      "epoch: 774, loss: 3.0528161764144897, acc: 0.26104000210762024, test loss: 3.1926342010498048, test acc: 0.08207999914884567\n",
      "epoch: 775, loss: 3.051895356178284, acc: 0.2643200159072876, test loss: 3.19357693195343, test acc: 0.08472000062465668\n",
      "epoch: 776, loss: 3.053161287307739, acc: 0.26208001375198364, test loss: 3.192638063430786, test acc: 0.08224000781774521\n",
      "epoch: 777, loss: 3.0537446260452272, acc: 0.2608799934387207, test loss: 3.192913222312927, test acc: 0.0811999961733818\n",
      "epoch: 778, loss: 3.052103543281555, acc: 0.26423996686935425, test loss: 3.1932758331298827, test acc: 0.08128000050783157\n",
      "epoch: 779, loss: 3.0509898900985717, acc: 0.2648000121116638, test loss: 3.193139410018921, test acc: 0.0820000022649765\n",
      "epoch: 780, loss: 3.0513607978820803, acc: 0.2646400034427643, test loss: 3.193188738822937, test acc: 0.08271999657154083\n",
      "epoch: 781, loss: 3.0516642808914183, acc: 0.2624800205230713, test loss: 3.1938119888305665, test acc: 0.08176000416278839\n",
      "epoch: 782, loss: 3.051762580871582, acc: 0.26416000723838806, test loss: 3.1923717737197874, test acc: 0.0835999995470047\n",
      "epoch: 783, loss: 3.052105975151062, acc: 0.26311999559402466, test loss: 3.193647289276123, test acc: 0.0825599953532219\n",
      "epoch: 784, loss: 3.0517722368240356, acc: 0.2627200186252594, test loss: 3.1927231311798097, test acc: 0.08352000266313553\n",
      "epoch: 785, loss: 3.05203115940094, acc: 0.26416000723838806, test loss: 3.193433928489685, test acc: 0.0803999975323677\n",
      "epoch: 786, loss: 3.0523536920547487, acc: 0.26263999938964844, test loss: 3.1927586078643797, test acc: 0.08319999277591705\n",
      "epoch: 787, loss: 3.0518521308898925, acc: 0.2637600004673004, test loss: 3.1934041023254394, test acc: 0.08207999914884567\n",
      "epoch: 788, loss: 3.051625967025757, acc: 0.2637600302696228, test loss: 3.1933626174926757, test acc: 0.08168000727891922\n",
      "epoch: 789, loss: 3.051313281059265, acc: 0.265999972820282, test loss: 3.1927894353866577, test acc: 0.08375999331474304\n",
      "epoch: 790, loss: 3.051242733001709, acc: 0.26423996686935425, test loss: 3.1932000160217284, test acc: 0.08328000456094742\n",
      "epoch: 791, loss: 3.051256275177002, acc: 0.2655999958515167, test loss: 3.1931628704071047, test acc: 0.0828000009059906\n",
      "epoch: 792, loss: 3.05125207901001, acc: 0.2651999890804291, test loss: 3.193537640571594, test acc: 0.08288000524044037\n",
      "epoch: 793, loss: 3.051627683639526, acc: 0.2640799880027771, test loss: 3.193008637428284, test acc: 0.0835999995470047\n",
      "epoch: 794, loss: 3.052711343765259, acc: 0.26183998584747314, test loss: 3.1928354263305665, test acc: 0.08351999521255493\n",
      "epoch: 795, loss: 3.052775502204895, acc: 0.26287999749183655, test loss: 3.1936063289642336, test acc: 0.08207999169826508\n",
      "epoch: 796, loss: 3.0521618127822876, acc: 0.26280003786087036, test loss: 3.1930066108703614, test acc: 0.08271999657154083\n",
      "epoch: 797, loss: 3.0510677099227905, acc: 0.2643200159072876, test loss: 3.1928455352783205, test acc: 0.08344000577926636\n",
      "epoch: 798, loss: 3.050472140312195, acc: 0.2669599950313568, test loss: 3.1930437088012695, test acc: 0.08271999657154083\n",
      "epoch: 799, loss: 3.050096130371094, acc: 0.2651999890804291, test loss: 3.193081283569336, test acc: 0.08231999725103378\n",
      "epoch: 800, loss: 3.05036404132843, acc: 0.26527997851371765, test loss: 3.193247127532959, test acc: 0.0811999961733818\n",
      "epoch: 801, loss: 3.0508448600769045, acc: 0.2656800150871277, test loss: 3.192978358268738, test acc: 0.08368000388145447\n",
      "epoch: 802, loss: 3.051107716560364, acc: 0.2637600004673004, test loss: 3.1931517124176025, test acc: 0.08231999725103378\n",
      "epoch: 803, loss: 3.0506975173950197, acc: 0.26471999287605286, test loss: 3.1929143905639648, test acc: 0.08304000645875931\n",
      "epoch: 804, loss: 3.050738573074341, acc: 0.2648000121116638, test loss: 3.1931973457336427, test acc: 0.08207999914884567\n",
      "epoch: 805, loss: 3.051299047470093, acc: 0.265360027551651, test loss: 3.1930933475494383, test acc: 0.08424000442028046\n",
      "epoch: 806, loss: 3.050639271736145, acc: 0.26504001021385193, test loss: 3.193015432357788, test acc: 0.08448000252246857\n",
      "epoch: 807, loss: 3.051596760749817, acc: 0.26335999369621277, test loss: 3.1942002534866334, test acc: 0.08128000795841217\n",
      "epoch: 808, loss: 3.051747751235962, acc: 0.2624799907207489, test loss: 3.1929064750671388, test acc: 0.08111999928951263\n",
      "epoch: 809, loss: 3.0514498949050903, acc: 0.2656799852848053, test loss: 3.1929356336593626, test acc: 0.08447998762130737\n",
      "epoch: 810, loss: 3.0508025884628296, acc: 0.26503998041152954, test loss: 3.193095588684082, test acc: 0.08271999657154083\n",
      "epoch: 811, loss: 3.0510077714920043, acc: 0.26448002457618713, test loss: 3.1932219505310058, test acc: 0.08336000144481659\n",
      "epoch: 812, loss: 3.0515732049942015, acc: 0.26528000831604004, test loss: 3.193615221977234, test acc: 0.08184000104665756\n",
      "epoch: 813, loss: 3.051556181907654, acc: 0.2630400061607361, test loss: 3.193236827850342, test acc: 0.08272000402212143\n",
      "epoch: 814, loss: 3.051595616340637, acc: 0.2635999917984009, test loss: 3.1930608987808227, test acc: 0.0843999981880188\n",
      "epoch: 815, loss: 3.050930953025818, acc: 0.2651999890804291, test loss: 3.1930405855178834, test acc: 0.08183999359607697\n",
      "epoch: 816, loss: 3.051135945320129, acc: 0.2645600140094757, test loss: 3.193490219116211, test acc: 0.08207999169826508\n",
      "epoch: 817, loss: 3.05125207901001, acc: 0.26472002267837524, test loss: 3.193126082420349, test acc: 0.08336000144481659\n",
      "epoch: 818, loss: 3.051327276229858, acc: 0.26440000534057617, test loss: 3.192888283729553, test acc: 0.08344000577926636\n",
      "epoch: 819, loss: 3.0504206895828245, acc: 0.2667199969291687, test loss: 3.1934240818023683, test acc: 0.08312000334262848\n",
      "epoch: 820, loss: 3.050430083274841, acc: 0.2645600140094757, test loss: 3.1937533617019653, test acc: 0.08239999413490295\n",
      "epoch: 821, loss: 3.050435018539429, acc: 0.2651999890804291, test loss: 3.1930583238601686, test acc: 0.0828000083565712\n",
      "epoch: 822, loss: 3.0511194705963134, acc: 0.26423996686935425, test loss: 3.1938141107559206, test acc: 0.0812000036239624\n",
      "epoch: 823, loss: 3.049897050857544, acc: 0.2659199833869934, test loss: 3.1934154987335206, test acc: 0.08336000144481659\n",
      "epoch: 824, loss: 3.0508710145950317, acc: 0.2653599977493286, test loss: 3.1935730934143067, test acc: 0.08159999549388885\n",
      "epoch: 825, loss: 3.0508474588394163, acc: 0.2641599774360657, test loss: 3.1932250022888184, test acc: 0.08336000144481659\n",
      "epoch: 826, loss: 3.04989013671875, acc: 0.26736000180244446, test loss: 3.1928590297698975, test acc: 0.08248000591993332\n",
      "epoch: 827, loss: 3.050230383872986, acc: 0.2645600438117981, test loss: 3.193550729751587, test acc: 0.08064000308513641\n",
      "epoch: 828, loss: 3.050132465362549, acc: 0.2667199969291687, test loss: 3.1936094045639036, test acc: 0.0809599980711937\n",
      "epoch: 829, loss: 3.0502974510192873, acc: 0.26607999205589294, test loss: 3.1933204412460325, test acc: 0.08288000524044037\n",
      "epoch: 830, loss: 3.050563907623291, acc: 0.2651199996471405, test loss: 3.1929142236709596, test acc: 0.0828000083565712\n",
      "epoch: 831, loss: 3.0507622241973875, acc: 0.2637600302696228, test loss: 3.192897653579712, test acc: 0.08191999793052673\n",
      "epoch: 832, loss: 3.051093864440918, acc: 0.26447999477386475, test loss: 3.1931461572647093, test acc: 0.08407999575138092\n",
      "epoch: 833, loss: 3.051518702507019, acc: 0.2645600140094757, test loss: 3.1931838989257812, test acc: 0.08104000240564346\n",
      "epoch: 834, loss: 3.0506766557693483, acc: 0.2646400034427643, test loss: 3.1937804937362673, test acc: 0.08128000050783157\n",
      "epoch: 835, loss: 3.050678515434265, acc: 0.26552003622055054, test loss: 3.1935319900512695, test acc: 0.08151999861001968\n",
      "epoch: 836, loss: 3.049864172935486, acc: 0.266400009393692, test loss: 3.1927338600158692, test acc: 0.08319999277591705\n",
      "epoch: 837, loss: 3.0504019260406494, acc: 0.2654400169849396, test loss: 3.193164348602295, test acc: 0.08376000076532364\n",
      "epoch: 838, loss: 3.0500828504562376, acc: 0.2656800150871277, test loss: 3.193784785270691, test acc: 0.07951999455690384\n",
      "epoch: 839, loss: 3.0506803512573244, acc: 0.2651199698448181, test loss: 3.193556547164917, test acc: 0.0828000083565712\n",
      "epoch: 840, loss: 3.051143217086792, acc: 0.2651999890804291, test loss: 3.193284249305725, test acc: 0.0820000022649765\n",
      "epoch: 841, loss: 3.050387239456177, acc: 0.2665599584579468, test loss: 3.1939316749572755, test acc: 0.08183999359607697\n",
      "epoch: 842, loss: 3.050081992149353, acc: 0.2662399709224701, test loss: 3.1930809020996094, test acc: 0.08263999968767166\n",
      "epoch: 843, loss: 3.050593852996826, acc: 0.2651200294494629, test loss: 3.1942653894424438, test acc: 0.08160000294446945\n",
      "epoch: 844, loss: 3.0525740146636964, acc: 0.26232001185417175, test loss: 3.1932324171066284, test acc: 0.08167999982833862\n",
      "epoch: 845, loss: 3.0507925271987917, acc: 0.2639999985694885, test loss: 3.193458390235901, test acc: 0.08328000456094742\n",
      "epoch: 846, loss: 3.0504334688186647, acc: 0.26520001888275146, test loss: 3.193321108818054, test acc: 0.08191999793052673\n",
      "epoch: 847, loss: 3.0513453006744387, acc: 0.26495999097824097, test loss: 3.1935379981994627, test acc: 0.08112000674009323\n",
      "epoch: 848, loss: 3.0506375312805174, acc: 0.26504001021385193, test loss: 3.1934322118759155, test acc: 0.08247999846935272\n",
      "epoch: 849, loss: 3.050259900093079, acc: 0.26688000559806824, test loss: 3.193383479118347, test acc: 0.08215999603271484\n",
      "epoch: 850, loss: 3.0497325897216796, acc: 0.2670400142669678, test loss: 3.193107509613037, test acc: 0.08343999832868576\n",
      "epoch: 851, loss: 3.0501997470855713, acc: 0.26631999015808105, test loss: 3.193023347854614, test acc: 0.08247999101877213\n",
      "epoch: 852, loss: 3.050311875343323, acc: 0.26576000452041626, test loss: 3.1940011501312258, test acc: 0.08191999793052673\n",
      "epoch: 853, loss: 3.051077723503113, acc: 0.266400009393692, test loss: 3.193064785003662, test acc: 0.08136000484228134\n",
      "epoch: 854, loss: 3.0506253004074098, acc: 0.26495999097824097, test loss: 3.193371868133545, test acc: 0.08320000022649765\n",
      "epoch: 855, loss: 3.0498939037322996, acc: 0.266400009393692, test loss: 3.1934914112091066, test acc: 0.08167999982833862\n",
      "epoch: 856, loss: 3.050163245201111, acc: 0.26607999205589294, test loss: 3.193062496185303, test acc: 0.08352000266313553\n",
      "epoch: 857, loss: 3.0504242420196532, acc: 0.26552000641822815, test loss: 3.1940460443496703, test acc: 0.08159998804330826\n",
      "epoch: 858, loss: 3.050539016723633, acc: 0.2648800015449524, test loss: 3.1938557863235473, test acc: 0.08224000036716461\n",
      "epoch: 859, loss: 3.0505248308181763, acc: 0.2672799825668335, test loss: 3.192881965637207, test acc: 0.08247999846935272\n",
      "epoch: 860, loss: 3.0512709856033324, acc: 0.2635999917984009, test loss: 3.1950488090515137, test acc: 0.0809599980711937\n",
      "epoch: 861, loss: 3.0515076160430907, acc: 0.2641599774360657, test loss: 3.1934994220733643, test acc: 0.08367999643087387\n",
      "epoch: 862, loss: 3.0517818689346314, acc: 0.26344001293182373, test loss: 3.1931476831436156, test acc: 0.08127999305725098\n",
      "epoch: 863, loss: 3.0515645265579225, acc: 0.263839989900589, test loss: 3.1931156873703004, test acc: 0.08288000524044037\n",
      "epoch: 864, loss: 3.050999331474304, acc: 0.26423999667167664, test loss: 3.194864273071289, test acc: 0.07871999591588974\n",
      "epoch: 865, loss: 3.0515987157821653, acc: 0.2633599638938904, test loss: 3.192916655540466, test acc: 0.08295999467372894\n",
      "epoch: 866, loss: 3.051897740364075, acc: 0.2625599801540375, test loss: 3.1946928977966307, test acc: 0.08096000552177429\n",
      "epoch: 867, loss: 3.052113652229309, acc: 0.2637600004673004, test loss: 3.1934650421142576, test acc: 0.08176000416278839\n",
      "epoch: 868, loss: 3.051103949546814, acc: 0.26528000831604004, test loss: 3.1933916091918944, test acc: 0.0820000022649765\n",
      "epoch: 869, loss: 3.0526927709579468, acc: 0.2624000012874603, test loss: 3.1944400310516357, test acc: 0.08023999631404877\n",
      "epoch: 870, loss: 3.052655553817749, acc: 0.26263999938964844, test loss: 3.193763184547424, test acc: 0.08064000308513641\n",
      "epoch: 871, loss: 3.051313638687134, acc: 0.26392000913619995, test loss: 3.1943082571029664, test acc: 0.07992000877857208\n",
      "epoch: 872, loss: 3.05105082988739, acc: 0.2646400034427643, test loss: 3.192579507827759, test acc: 0.08504000306129456\n",
      "epoch: 873, loss: 3.0513972520828245, acc: 0.26288002729415894, test loss: 3.1935378313064575, test acc: 0.08240000158548355\n",
      "epoch: 874, loss: 3.050808477401733, acc: 0.26495999097824097, test loss: 3.193140435218811, test acc: 0.08263999968767166\n",
      "epoch: 875, loss: 3.0512610197067263, acc: 0.263839989900589, test loss: 3.1945141315460206, test acc: 0.08104000240564346\n",
      "epoch: 876, loss: 3.0520646810531615, acc: 0.2643199861049652, test loss: 3.1942121744155885, test acc: 0.08023999631404877\n",
      "epoch: 877, loss: 3.0506857872009276, acc: 0.2643999755382538, test loss: 3.193519878387451, test acc: 0.08383999764919281\n",
      "epoch: 878, loss: 3.050989842414856, acc: 0.2654400169849396, test loss: 3.1927652597427367, test acc: 0.08167999237775803\n",
      "epoch: 879, loss: 3.0497766971588134, acc: 0.26711997389793396, test loss: 3.1941121101379393, test acc: 0.08056000620126724\n",
      "epoch: 880, loss: 3.0492997646331785, acc: 0.2670399844646454, test loss: 3.1935198307037354, test acc: 0.08128000050783157\n",
      "epoch: 881, loss: 3.0500357389450072, acc: 0.266400009393692, test loss: 3.1932690858840944, test acc: 0.08056001365184784\n",
      "epoch: 882, loss: 3.049703359603882, acc: 0.2667999863624573, test loss: 3.193183183670044, test acc: 0.08272001147270203\n",
      "epoch: 883, loss: 3.050865626335144, acc: 0.26472002267837524, test loss: 3.1939001798629763, test acc: 0.08128000795841217\n",
      "epoch: 884, loss: 3.050793480873108, acc: 0.26607999205589294, test loss: 3.193701410293579, test acc: 0.08288000524044037\n",
      "epoch: 885, loss: 3.051405835151672, acc: 0.2643199861049652, test loss: 3.1941367387771606, test acc: 0.08247999846935272\n",
      "epoch: 886, loss: 3.0511238813400268, acc: 0.2632000148296356, test loss: 3.1934685707092285, test acc: 0.08424000442028046\n",
      "epoch: 887, loss: 3.0490378379821776, acc: 0.2667199969291687, test loss: 3.193170166015625, test acc: 0.08135999739170074\n",
      "epoch: 888, loss: 3.0498995780944824, acc: 0.2656800150871277, test loss: 3.193531322479248, test acc: 0.08256000280380249\n",
      "epoch: 889, loss: 3.05015709400177, acc: 0.26552000641822815, test loss: 3.1930870532989504, test acc: 0.08304000645875931\n",
      "epoch: 890, loss: 3.0501851081848144, acc: 0.26576000452041626, test loss: 3.1932762622833253, test acc: 0.0817599967122078\n",
      "epoch: 891, loss: 3.049839901924133, acc: 0.26656001806259155, test loss: 3.193284440040588, test acc: 0.08152000606060028\n",
      "epoch: 892, loss: 3.0520902633666993, acc: 0.26528000831604004, test loss: 3.194470191001892, test acc: 0.08176000416278839\n",
      "epoch: 893, loss: 3.0514147996902468, acc: 0.2639999985694885, test loss: 3.1941967248916625, test acc: 0.08080000430345535\n",
      "epoch: 894, loss: 3.0508402824401855, acc: 0.2643199861049652, test loss: 3.1933350563049316, test acc: 0.08207999914884567\n",
      "epoch: 895, loss: 3.049467587471008, acc: 0.2672799825668335, test loss: 3.1936293601989747, test acc: 0.08247999846935272\n",
      "epoch: 896, loss: 3.049689030647278, acc: 0.2669600248336792, test loss: 3.193471312522888, test acc: 0.0812000036239624\n",
      "epoch: 897, loss: 3.0491682052612306, acc: 0.26656001806259155, test loss: 3.1937201261520385, test acc: 0.08135999739170074\n",
      "epoch: 898, loss: 3.049018621444702, acc: 0.2678399980068207, test loss: 3.193731260299683, test acc: 0.08111999928951263\n",
      "epoch: 899, loss: 3.049926733970642, acc: 0.26552000641822815, test loss: 3.193350052833557, test acc: 0.08240000903606415\n",
      "epoch: 900, loss: 3.05052535533905, acc: 0.2654400169849396, test loss: 3.1932254791259767, test acc: 0.0836000069975853\n",
      "epoch: 901, loss: 3.050970721244812, acc: 0.26583999395370483, test loss: 3.1942376375198362, test acc: 0.08071999996900558\n",
      "epoch: 902, loss: 3.0506884336471556, acc: 0.26600000262260437, test loss: 3.1947811126708983, test acc: 0.07928000390529633\n",
      "epoch: 903, loss: 3.050986886024475, acc: 0.26367998123168945, test loss: 3.1936546564102173, test acc: 0.08247999846935272\n",
      "epoch: 904, loss: 3.050404095649719, acc: 0.2639999985694885, test loss: 3.193731665611267, test acc: 0.08167999982833862\n",
      "epoch: 905, loss: 3.050409531593323, acc: 0.2659199833869934, test loss: 3.193631911277771, test acc: 0.08271999657154083\n",
      "epoch: 906, loss: 3.0500259160995484, acc: 0.2648000121116638, test loss: 3.193686103820801, test acc: 0.08032000064849854\n",
      "epoch: 907, loss: 3.051379418373108, acc: 0.26440000534057617, test loss: 3.194511294364929, test acc: 0.07983998954296112\n",
      "epoch: 908, loss: 3.050085735321045, acc: 0.26528000831604004, test loss: 3.193412184715271, test acc: 0.08312000334262848\n",
      "epoch: 909, loss: 3.04927716255188, acc: 0.2671999931335449, test loss: 3.193932294845581, test acc: 0.08032000064849854\n",
      "epoch: 910, loss: 3.0494216203689577, acc: 0.26767998933792114, test loss: 3.193734622001648, test acc: 0.08167999982833862\n",
      "epoch: 911, loss: 3.050207996368408, acc: 0.26552000641822815, test loss: 3.193851041793823, test acc: 0.0809599906206131\n",
      "epoch: 912, loss: 3.0506242513656616, acc: 0.2651999890804291, test loss: 3.195105767250061, test acc: 0.07895998656749725\n",
      "epoch: 913, loss: 3.050614261627197, acc: 0.26600003242492676, test loss: 3.1938244342803954, test acc: 0.08063999563455582\n",
      "epoch: 914, loss: 3.0496472835540773, acc: 0.26687997579574585, test loss: 3.193688726425171, test acc: 0.08240000903606415\n",
      "epoch: 915, loss: 3.049465227127075, acc: 0.26792001724243164, test loss: 3.193419933319092, test acc: 0.08088000118732452\n",
      "epoch: 916, loss: 3.049470829963684, acc: 0.26656001806259155, test loss: 3.1946250438690185, test acc: 0.08144000172615051\n",
      "epoch: 917, loss: 3.052289581298828, acc: 0.2634400427341461, test loss: 3.193858599662781, test acc: 0.08160000294446945\n",
      "epoch: 918, loss: 3.0512297630310057, acc: 0.26287999749183655, test loss: 3.1940379619598387, test acc: 0.08160000294446945\n",
      "epoch: 919, loss: 3.0525859117507936, acc: 0.26319998502731323, test loss: 3.1936822652816774, test acc: 0.08312000334262848\n",
      "epoch: 920, loss: 3.049731135368347, acc: 0.2667199969291687, test loss: 3.1942547082901003, test acc: 0.08191999793052673\n",
      "epoch: 921, loss: 3.050513172149658, acc: 0.2661600112915039, test loss: 3.1942140102386474, test acc: 0.0809599906206131\n",
      "epoch: 922, loss: 3.0513426065444946, acc: 0.26423999667167664, test loss: 3.1936422109603884, test acc: 0.08160000294446945\n",
      "epoch: 923, loss: 3.049478054046631, acc: 0.267520010471344, test loss: 3.1933770179748535, test acc: 0.08320000022649765\n",
      "epoch: 924, loss: 3.0494155883789062, acc: 0.26687997579574585, test loss: 3.194025254249573, test acc: 0.0809599980711937\n",
      "epoch: 925, loss: 3.050144100189209, acc: 0.26576000452041626, test loss: 3.19415442943573, test acc: 0.08064000308513641\n",
      "epoch: 926, loss: 3.0507303714752196, acc: 0.2672799825668335, test loss: 3.193634581565857, test acc: 0.08224000036716461\n",
      "epoch: 927, loss: 3.0500258684158323, acc: 0.26656001806259155, test loss: 3.193076968193054, test acc: 0.08376000821590424\n",
      "epoch: 928, loss: 3.0506473541259767, acc: 0.26624003052711487, test loss: 3.1953575134277346, test acc: 0.08159999549388885\n",
      "epoch: 929, loss: 3.051444888114929, acc: 0.2639999985694885, test loss: 3.193615126609802, test acc: 0.08224000036716461\n",
      "epoch: 930, loss: 3.050593447685242, acc: 0.26552000641822815, test loss: 3.1939733743667604, test acc: 0.0820000022649765\n",
      "epoch: 931, loss: 3.0502251863479612, acc: 0.2651199698448181, test loss: 3.193610596656799, test acc: 0.08176000416278839\n",
      "epoch: 932, loss: 3.0493335247039797, acc: 0.2671999931335449, test loss: 3.194826579093933, test acc: 0.08048000186681747\n",
      "epoch: 933, loss: 3.050408720970154, acc: 0.265360027551651, test loss: 3.1936097860336305, test acc: 0.08167999982833862\n",
      "epoch: 934, loss: 3.0502713918685913, acc: 0.2659199833869934, test loss: 3.1936535835266113, test acc: 0.08247999846935272\n",
      "epoch: 935, loss: 3.0492626190185548, acc: 0.2668800354003906, test loss: 3.193928861618042, test acc: 0.08160001039505005\n",
      "epoch: 936, loss: 3.0498618841171266, acc: 0.2670400142669678, test loss: 3.1937780141830445, test acc: 0.08056000620126724\n",
      "epoch: 937, loss: 3.0489516496658324, acc: 0.2667199969291687, test loss: 3.1937832832336426, test acc: 0.08135999739170074\n",
      "epoch: 938, loss: 3.0489082813262938, acc: 0.26848000288009644, test loss: 3.193680691719055, test acc: 0.08311999589204788\n",
      "epoch: 939, loss: 3.0490070104599, acc: 0.2683199942111969, test loss: 3.194437098503113, test acc: 0.07879999279975891\n",
      "epoch: 940, loss: 3.050656247138977, acc: 0.26472002267837524, test loss: 3.193263125419617, test acc: 0.08312000334262848\n",
      "epoch: 941, loss: 3.04915714263916, acc: 0.2677600085735321, test loss: 3.193924975395203, test acc: 0.08231999725103378\n",
      "epoch: 942, loss: 3.049470901489258, acc: 0.26791995763778687, test loss: 3.194080638885498, test acc: 0.0809599980711937\n",
      "epoch: 943, loss: 3.0497788429260253, acc: 0.26688000559806824, test loss: 3.1938513278961183, test acc: 0.08104000240564346\n",
      "epoch: 944, loss: 3.0496339082717894, acc: 0.2672000229358673, test loss: 3.1934701442718505, test acc: 0.08135999739170074\n",
      "epoch: 945, loss: 3.0502187490463255, acc: 0.2648000121116638, test loss: 3.194416308403015, test acc: 0.08111999928951263\n",
      "epoch: 946, loss: 3.0492481708526613, acc: 0.26576000452041626, test loss: 3.1940836191177366, test acc: 0.0809599980711937\n",
      "epoch: 947, loss: 3.0507147312164307, acc: 0.2653599977493286, test loss: 3.194230890274048, test acc: 0.07903999835252762\n",
      "epoch: 948, loss: 3.0517507076263426, acc: 0.26344001293182373, test loss: 3.193948435783386, test acc: 0.08135999739170074\n",
      "epoch: 949, loss: 3.050702667236328, acc: 0.26423999667167664, test loss: 3.1941404819488524, test acc: 0.08263999968767166\n",
      "epoch: 950, loss: 3.051055836677551, acc: 0.2653599977493286, test loss: 3.1933908462524414, test acc: 0.08159999549388885\n",
      "epoch: 951, loss: 3.050440812110901, acc: 0.2648000121116638, test loss: 3.1938787937164306, test acc: 0.08136000484228134\n",
      "epoch: 952, loss: 3.0489882230758667, acc: 0.2677599787712097, test loss: 3.193248152732849, test acc: 0.08159999549388885\n",
      "epoch: 953, loss: 3.048665761947632, acc: 0.2678399682044983, test loss: 3.193664026260376, test acc: 0.08152000606060028\n",
      "epoch: 954, loss: 3.04896559715271, acc: 0.2682400047779083, test loss: 3.1935928106307983, test acc: 0.08144000172615051\n",
      "epoch: 955, loss: 3.048871946334839, acc: 0.2686399817466736, test loss: 3.1932565927505494, test acc: 0.08231999725103378\n",
      "epoch: 956, loss: 3.0487246036529543, acc: 0.2677599787712097, test loss: 3.194119763374329, test acc: 0.08104000985622406\n",
      "epoch: 957, loss: 3.0487108707427977, acc: 0.2678399682044983, test loss: 3.193882155418396, test acc: 0.08047999441623688\n",
      "epoch: 958, loss: 3.049108362197876, acc: 0.2672799825668335, test loss: 3.1930861949920653, test acc: 0.08448000252246857\n",
      "epoch: 959, loss: 3.049538516998291, acc: 0.2672800123691559, test loss: 3.1943803071975707, test acc: 0.08176000416278839\n",
      "epoch: 960, loss: 3.050442409515381, acc: 0.2656800150871277, test loss: 3.194118547439575, test acc: 0.07983999699354172\n",
      "epoch: 961, loss: 3.050253415107727, acc: 0.26559996604919434, test loss: 3.1941203117370605, test acc: 0.0809599906206131\n",
      "epoch: 962, loss: 3.0496448040008546, acc: 0.2653599679470062, test loss: 3.1939319610595702, test acc: 0.08143999427556992\n",
      "epoch: 963, loss: 3.049327039718628, acc: 0.267520010471344, test loss: 3.1937878131866455, test acc: 0.08104000240564346\n",
      "epoch: 964, loss: 3.0492450475692747, acc: 0.26632001996040344, test loss: 3.1938411712646486, test acc: 0.08192001283168793\n",
      "epoch: 965, loss: 3.0501373529434206, acc: 0.266400009393692, test loss: 3.193620276451111, test acc: 0.08064000308513641\n",
      "epoch: 966, loss: 3.0490789651870727, acc: 0.2680799663066864, test loss: 3.1936100721359253, test acc: 0.0828000009059906\n",
      "epoch: 967, loss: 3.048791193962097, acc: 0.2674400210380554, test loss: 3.1941694259643554, test acc: 0.08183999359607697\n",
      "epoch: 968, loss: 3.0499704122543334, acc: 0.26600000262260437, test loss: 3.1940727710723875, test acc: 0.08159999549388885\n",
      "epoch: 969, loss: 3.0500312089920043, acc: 0.2656800150871277, test loss: 3.1938331604003904, test acc: 0.08263999968767166\n",
      "epoch: 970, loss: 3.0484925746917724, acc: 0.26840001344680786, test loss: 3.193852734565735, test acc: 0.08047999441623688\n",
      "epoch: 971, loss: 3.0489561557769775, acc: 0.26631999015808105, test loss: 3.193587589263916, test acc: 0.0828000009059906\n",
      "epoch: 972, loss: 3.049042057991028, acc: 0.26736000180244446, test loss: 3.1944882392883303, test acc: 0.08103999495506287\n",
      "epoch: 973, loss: 3.0505304098129273, acc: 0.2654399871826172, test loss: 3.193295216560364, test acc: 0.08176000416278839\n",
      "epoch: 974, loss: 3.0497934341430666, acc: 0.26712000370025635, test loss: 3.193426823616028, test acc: 0.08336000144481659\n",
      "epoch: 975, loss: 3.049800682067871, acc: 0.26552000641822815, test loss: 3.1931277990341185, test acc: 0.08192001283168793\n",
      "epoch: 976, loss: 3.0491003513336183, acc: 0.26656001806259155, test loss: 3.1937180519104005, test acc: 0.08184000104665756\n",
      "epoch: 977, loss: 3.048441219329834, acc: 0.26976001262664795, test loss: 3.1932323932647706, test acc: 0.08167999982833862\n",
      "epoch: 978, loss: 3.048471736907959, acc: 0.2680000066757202, test loss: 3.1937921762466432, test acc: 0.0811999961733818\n",
      "epoch: 979, loss: 3.0487212419509886, acc: 0.2680799961090088, test loss: 3.194188618659973, test acc: 0.08111999928951263\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m output \u001b[39m=\u001b[39m model(inputs)\n\u001b[0;32m     13\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, targets)\n\u001b[1;32m---> 14\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     15\u001b[0m running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     16\u001b[0m pred \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(output, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)      \u001b[39m# outputの一番値が大きい成分\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sugay\\Anaconda3\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\sugay\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 学習の実行\n",
    "num_epochs = 7500\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "test_losses = []\n",
    "test_accs = []\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(inputs)\n",
    "        loss = criterion(output, targets)\n",
    "        loss.backward()\n",
    "        running_loss += loss.item()\n",
    "        pred = torch.argmax(output, dim=1)      # outputの一番値が大きい成分\n",
    "        targets = torch.argmax(targets, dim=1)  # targetの一番値が大きい成分\n",
    "        running_acc += torch.mean(pred.eq(targets).float()) # predとtargetが同じになった数の平均\n",
    "        optimizer.step()\n",
    "    running_loss /= len(train_loader)   # 12500個の訓練データ全体での損失関数の平均\n",
    "    running_acc /= len(train_loader)    # 12500個の訓練データ全体での正解率\n",
    "    train_losses.append(running_loss)\n",
    "    train_accs.append(running_acc)\n",
    "    #\n",
    "    #   test loop\n",
    "    #\n",
    "    test_running_loss = 0.0\n",
    "    test_running_acc = 0.0\n",
    "    for test_inputs, test_targets in test_loader:\n",
    "        test_output = model(test_inputs)\n",
    "        test_loss = criterion(test_output, test_targets)\n",
    "        test_running_loss += test_loss.item()\n",
    "        test_pred = torch.argmax(test_output, dim=1)      # outputの一番値が大きい成分\n",
    "        test_targets = torch.argmax(test_targets, dim=1)  # targetの一番値が大きい成分\n",
    "        test_running_acc += torch.mean(test_pred.eq(test_targets).float()) # predとtargetが同じになった数の平均\n",
    "    test_running_loss /= len(test_loader)   # 12500個の訓練データ全体での損失関数の平均\n",
    "    test_running_acc /= len(test_loader)    # 12500個の訓練データ全体での正解率\n",
    "    test_losses.append(test_running_loss)\n",
    "    test_accs.append(test_running_acc)\n",
    "        \n",
    "    print(\"epoch: {}, loss: {}, acc: {}, test loss: {}, test acc: {}\".format(epoch, running_loss, running_acc, test_running_loss, test_running_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "損失関数と正解率のグラフの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 損失関数のグラフ\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(num_epochs), train_losses, label='Training Loss', color='blue')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.show()\n",
    "\n",
    "# 正解率のグラフ\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(num_epochs), train_accs, label='Training Accuracy', color='green')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training Accuracy Over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際に予測値と正解がどうなっているか見てみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 7,  1, 11, 21, 22,  1, 10, 20,  5,  5,  0, 10,  0, 22, 24,  4, 16,  9,\n",
      "         1, 18])\n"
     ]
    }
   ],
   "source": [
    "print(pred[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6,  3, 11, 21, 24,  4, 10, 18,  5,  4,  1, 19, 10, 19, 16,  8, 21,  9,\n",
      "         4, 17])\n"
     ]
    }
   ],
   "source": [
    "print(targets[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(params, \"model.prm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
