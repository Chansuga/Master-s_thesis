{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "data = pd.read_csv('dataframe.csv')\n",
    "X = data.iloc[:, :-1].values  # 入力データ (スピン配位)\n",
    "y = data.iloc[:, -1].values   # 教師データ (温度)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 100), (25000,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データのサイズを確認\n",
    "X.shape , y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01, 0.01, 0.01, ..., 6.  , 6.  , 6.  ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy配列からPyTorchのテンソルに変換\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)  # (25000,) -> (25000, 1)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)    # (6250,) -> (6250, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.0000],\n",
       "        [0.5000],\n",
       "        [2.2500],\n",
       "        ...,\n",
       "        [0.0100],\n",
       "        [3.7500],\n",
       "        [5.7500]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正解データはone-hot表現にする必要がある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# y_trainテンソルを新しいテンソルに変換する関数を定義\n",
    "def to_one_hot(y_train, num_classes=25):\n",
    "    # one-hotベクトルの初期化\n",
    "    one_hot = torch.zeros(len(y_train), num_classes)\n",
    "    \n",
    "    # 各要素を25次元のone-hotベクトルに変換\n",
    "    for i, val in enumerate(y_train):\n",
    "        index = int((val - 0.01) / 0.24)  # 正しいインデックスの計算\n",
    "        one_hot[i, index] = 1.0\n",
    "    \n",
    "    return one_hot\n",
    "\n",
    "# y_train,y_testをone-hotベクトルに変換\n",
    "one_hot_y_train = to_one_hot(y_train, num_classes=25)\n",
    "one_hot_y_test = to_one_hot(y_test, num_classes=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.5000])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_y_train[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの作成\n",
    "train_dataset = TensorDataset(X_train, one_hot_y_train)\n",
    "test_dataset = TensorDataset(X_test, one_hot_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.,  1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "          1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1.,  1., -1.,\n",
       "         -1., -1., -1., -1., -1., -1., -1., -1.,  1.,  1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1.,  1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1.,  1., -1., -1., -1.,  1.,  1., -1., -1., -1., -1., -1., -1.,\n",
       "         -1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1.,\n",
       "          1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaderの設定（バッチサイズ250）\n",
    "train_loader = DataLoader(train_dataset, batch_size=250, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ニューラルネットワークモデルの定義\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = F.softmax(self.fc2(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの初期化\n",
    "input_size = 100\n",
    "hidden_size = 64\n",
    "output_size = 25\n",
    "model = NeuralNetwork(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (fc1): Linear(in_features=100, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=25, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KLダイバージェンス損失関数の定義\n",
    "class KLDivergenceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KLDivergenceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        loss = nn.KLDivLoss(reduction='sum')(torch.log(output), target)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失関数と最適化アルゴリズムの設定\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sugay\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m output \u001b[39m=\u001b[39m model(inputs)\n\u001b[0;32m     13\u001b[0m loss \u001b[39m=\u001b[39m criterion(targets, targets)\n\u001b[1;32m---> 14\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     15\u001b[0m running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     16\u001b[0m pred \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(output, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sugay\\Anaconda3\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\sugay\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "# 学習の実行\n",
    "num_epochs = 7500\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "test_losses = []\n",
    "test_accs = []\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(inputs)\n",
    "        loss = criterion(targets, targets)\n",
    "        loss.backward()\n",
    "        running_loss += loss.item()\n",
    "        pred = torch.argmax(output, dim=1)\n",
    "        running_acc += torch.mean(pred.eq(targets).float())\n",
    "        optimizer.step()\n",
    "    running_loss /= len(train_loader)\n",
    "    running_acc /= len(train_loader)\n",
    "    train_losses.append(running_loss)\n",
    "    train_accs.append(running_acc)\n",
    "    #\n",
    "    # testidation loop\n",
    "    #\n",
    "    test_running_loss = 0.0\n",
    "    test_running_acc = 0.0\n",
    "    for test_inputs, test_targets in test_loader:\n",
    "        test_outputs = model(test_inputs)\n",
    "        test_loss = criterion(test_outputs, test_targets)\n",
    "        test_running_loss += test_loss.item()\n",
    "        test_pred = torch.argmax(test_outputs, dim=1)\n",
    "        test_running_acc += torch.mean(test_pred.eq(test_targets).float())\n",
    "    test_running_loss /= len(test_loader)\n",
    "    test_running_acc /= len(test_loader)\n",
    "    test_loss.append(test_running_loss)\n",
    "    test_accs.append(test_running_acc)\n",
    "    print(\"epoch: {}, loss: {}, acc: {}, \\\n",
    "        test loss: {}, test acc: {}\".format(epoch, running_loss, running_acc, test_running_loss, test_running_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sugay\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/7500],  Test Loss: 3.1998\n",
      "Epoch [2/7500],  Test Loss: 3.1977\n",
      "Epoch [3/7500],  Test Loss: 3.1980\n",
      "Epoch [4/7500],  Test Loss: 3.1973\n",
      "Epoch [5/7500],  Test Loss: 3.1984\n",
      "Epoch [6/7500],  Test Loss: 3.1982\n",
      "Epoch [7/7500],  Test Loss: 3.1994\n",
      "Epoch [8/7500],  Test Loss: 3.1978\n",
      "Epoch [9/7500],  Test Loss: 3.2004\n",
      "Epoch [10/7500],  Test Loss: 3.1984\n",
      "Epoch [11/7500],  Test Loss: 3.1991\n",
      "Epoch [12/7500],  Test Loss: 3.1999\n",
      "Epoch [13/7500],  Test Loss: 3.2017\n",
      "Epoch [14/7500],  Test Loss: 3.2001\n",
      "Epoch [15/7500],  Test Loss: 3.1988\n",
      "Epoch [16/7500],  Test Loss: 3.2004\n",
      "Epoch [17/7500],  Test Loss: 3.1999\n",
      "Epoch [18/7500],  Test Loss: 3.2009\n",
      "Epoch [19/7500],  Test Loss: 3.1996\n",
      "Epoch [20/7500],  Test Loss: 3.2000\n",
      "Epoch [21/7500],  Test Loss: 3.2004\n",
      "Epoch [22/7500],  Test Loss: 3.1995\n",
      "Epoch [23/7500],  Test Loss: 3.2016\n",
      "Epoch [24/7500],  Test Loss: 3.2003\n",
      "Epoch [25/7500],  Test Loss: 3.2004\n",
      "Epoch [26/7500],  Test Loss: 3.2004\n",
      "Epoch [27/7500],  Test Loss: 3.1996\n",
      "Epoch [28/7500],  Test Loss: 3.2002\n",
      "Epoch [29/7500],  Test Loss: 3.2001\n",
      "Epoch [30/7500],  Test Loss: 3.2007\n",
      "Epoch [31/7500],  Test Loss: 3.2004\n",
      "Epoch [32/7500],  Test Loss: 3.2021\n",
      "Epoch [33/7500],  Test Loss: 3.2002\n",
      "Epoch [34/7500],  Test Loss: 3.1998\n",
      "Epoch [35/7500],  Test Loss: 3.2014\n",
      "Epoch [36/7500],  Test Loss: 3.2016\n",
      "Epoch [37/7500],  Test Loss: 3.2026\n",
      "Epoch [38/7500],  Test Loss: 3.2015\n",
      "Epoch [39/7500],  Test Loss: 3.2040\n",
      "Epoch [40/7500],  Test Loss: 3.2021\n",
      "Epoch [41/7500],  Test Loss: 3.2025\n",
      "Epoch [42/7500],  Test Loss: 3.2024\n",
      "Epoch [43/7500],  Test Loss: 3.2014\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m     17\u001b[0m     test_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m---> 18\u001b[0m     \u001b[39mfor\u001b[39;00m inputs, targets \u001b[39min\u001b[39;00m test_loader:\n\u001b[0;32m     19\u001b[0m         outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[0;32m     20\u001b[0m         loss \u001b[39m=\u001b[39m criterion(outputs, targets)\n",
      "File \u001b[1;32mc:\\Users\\sugay\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\sugay\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\sugay\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 52\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32mc:\\Users\\sugay\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:175\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    172\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 175\u001b[0m     \u001b[39mreturn\u001b[39;00m [default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\sugay\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:175\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    172\u001b[0m transposed \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch))  \u001b[39m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m--> 175\u001b[0m     \u001b[39mreturn\u001b[39;00m [default_collate(samples) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]  \u001b[39m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\sugay\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:141\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    139\u001b[0m         storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mstorage()\u001b[39m.\u001b[39m_new_shared(numel, device\u001b[39m=\u001b[39melem\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    140\u001b[0m         out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\u001b[39m.\u001b[39mresize_(\u001b[39mlen\u001b[39m(batch), \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(elem\u001b[39m.\u001b[39msize()))\n\u001b[1;32m--> 141\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n\u001b[0;32m    142\u001b[0m \u001b[39melif\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstr_\u001b[39m\u001b[39m'\u001b[39m \\\n\u001b[0;32m    143\u001b[0m         \u001b[39mand\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstring_\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    144\u001b[0m     \u001b[39mif\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mndarray\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmemmap\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    145\u001b[0m         \u001b[39m# array of string classes and object\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 学習の実行\n",
    "num_epochs = 7500\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # モデルを学習モードに設定\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()       # 勾配を初期化\n",
    "        outputs = model(inputs)     # フォワードパス\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()            # バックプロパゲーション\n",
    "        optimizer.step()           # パラメータの更新\n",
    "\n",
    "    model.eval()   # モデルを評価モードに設定\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        for inputs, targets in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    train_losses.append(loss.item())\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}],  Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Loss: 48858.8125\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAGwCAYAAABPSaTdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA4H0lEQVR4nO3de3RU5b3/8c+QZIYQMkMSIJdmQGgkGEjSCoLBOwnBKOWmBa3FcMyBAoKi4E/BclFrk5YioB5iXUVuWodajbUK0VANSnOwBIiGi+hqkYJMiBeYBAiTkOzfHyzmOCKIIWGH3fdrrb1WsveeZ3+fBxbz4dk3m2EYhgAAACyqndkFAAAAtCbCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsDTCDgAAsLRQswtoC5qamnTgwAFFRkbKZrOZXQ4AADgHhmGotrZWCQkJatfuzPM3hB1JBw4ckNvtNrsMAADQDPv27VNiYuIZtxN2JEVGRko6OVhOp9PkagAAwLmoqamR2+0OfI+fCWFHCpy6cjqdhB0AAC4y33UJChcoAwAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAASyPsAAAAS+NFoK3FMKSGY2ZXAQBA2xDWQfqOF3a2FsJOa2k4Jv06wewqAABoG2YfkOwRphya01gAAMDSTJ3ZKSwsVGFhoT799FNJUp8+fTR37lzl5ORIkg4ePKgHH3xQb731lg4fPqxrr71WTz31lC699NJAG36/XzNnztSLL76ouro6ZWZmaunSpUpMTDSjS/8nrMPJFAsAAE5+L5rE1LCTmJiogoICJSUlSZJWrlypESNGaNu2bUpJSdHIkSMVFhamv/zlL3I6nXriiSeUlZWlnTt3KiLi5FTY9OnT9de//lUej0cxMTGaMWOGhg0bpi1btigkJMS8ztlspk3XAQCA/2MzDMMwu4ivi46O1oIFC3TNNdcoOTlZ27dvV58+fSRJjY2N6tq1q37zm9/ov//7v+Xz+dSlSxetXr1aY8eOlSQdOHBAbrdba9eu1dChQ7/1GH6/X36/P/B7TU2N3G63fD6fnE5n63cSAACct5qaGrlcru/8/m4z1+w0NjbK4/Ho6NGjysjICISR9u3bB/YJCQmR3W7Xxo0bJUlbtmxRQ0ODsrOzA/skJCSob9++KisrO+Ox8vPz5XK5Aovb7W6lXgEAALOZHnYqKyvVsWNHORwOTZo0SUVFRUpJSVHv3r3VvXt3zZo1S4cOHVJ9fb0KCgpUVVUlr9crSaqqqpLdbldUVFRQm7GxsaqqqjrjMWfNmiWfzxdY9u3b16p9BAAA5jE97CQnJ6uiokKbNm3S5MmTlZubq507dyosLEwvv/yyPv74Y0VHR6tDhw4qLS1VTk7Od16LYxiGbGe5l9/hcMjpdAYtAADAmkwPO3a7XUlJSerfv7/y8/OVnp6uJUuWSJL69euniooKHT58WF6vV8XFxfryyy/Vo0cPSVJcXJzq6+t16NChoDarq6sVGxt7wfsCAADaHtPDzjcZhhF08bAkuVwudenSRZ988onKy8s1YsQISSfDUFhYmEpKSgL7er1ebd++XYMGDbqgdQMAgLbJ1FvPZ8+erZycHLndbtXW1srj8ai0tFTFxcWSpJdeekldunRRt27dVFlZqXvvvVcjR44MXJDscrmUl5enGTNmKCYmRtHR0Zo5c6ZSU1OVlZVlZtcAAEAbYWrYOXjwoMaNGyev1yuXy6W0tDQVFxdryJAhkk7O0tx///06ePCg4uPjdeedd2rOnDlBbSxatEihoaEaM2ZM4KGCK1asMPcZOwAAoM1oc8/ZMcO53qcPAADajovuOTsAAACtgbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAszdSwU1hYqLS0NDmdTjmdTmVkZGjdunWB7UeOHNHUqVOVmJio8PBwXXbZZSosLAxqw+/3a9q0aercubMiIiI0fPhw7d+//0J3BQAAtFGmhp3ExEQVFBSovLxc5eXlGjx4sEaMGKEdO3ZIku677z4VFxfr+eef165du3Tfffdp2rRp+stf/hJoY/r06SoqKpLH49HGjRt15MgRDRs2TI2NjWZ1CwAAtCE2wzAMs4v4uujoaC1YsEB5eXnq27evxo4dqzlz5gS29+vXTzfddJMee+wx+Xw+denSRatXr9bYsWMlSQcOHJDb7dbatWs1dOjQczpmTU2NXC6XfD6fnE5nq/QLAAC0rHP9/m4z1+w0NjbK4/Ho6NGjysjIkCRdffXVeu211/TZZ5/JMAy98847+vjjjwMhZsuWLWpoaFB2dnagnYSEBPXt21dlZWVnPJbf71dNTU3QAgAArCnU7AIqKyuVkZGh48ePq2PHjioqKlJKSook6cknn9SECROUmJio0NBQtWvXTn/4wx909dVXS5Kqqqpkt9sVFRUV1GZsbKyqqqrOeMz8/Hw98sgjrdcpAADQZpg+s5OcnKyKigpt2rRJkydPVm5urnbu3CnpZNjZtGmTXnvtNW3ZskULFy7UlClTtH79+rO2aRiGbDbbGbfPmjVLPp8vsOzbt69F+wQAANoO02d27Ha7kpKSJEn9+/fX5s2btWTJEi1evFizZ89WUVGRbr75ZklSWlqaKioq9Lvf/U5ZWVmKi4tTfX29Dh06FDS7U11drUGDBp3xmA6HQw6Ho3U7BgAA2gTTZ3a+yTAM+f1+NTQ0qKGhQe3aBZcYEhKipqYmSScvVg4LC1NJSUlgu9fr1fbt288adgAAwH8OU2d2Zs+erZycHLndbtXW1srj8ai0tFTFxcVyOp267rrr9MADDyg8PFzdu3fXhg0btGrVKj3xxBOSJJfLpby8PM2YMUMxMTGKjo7WzJkzlZqaqqysLDO7BgAA2ghTw87Bgwc1btw4eb1euVwupaWlqbi4WEOGDJEkeTwezZo1S3fccYe++uorde/eXY8//rgmTZoUaGPRokUKDQ3VmDFjVFdXp8zMTK1YsUIhISFmdQsAALQhbe45O2bgOTsAAFx8Lrrn7AAAALQGwg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0U8NOYWGh0tLS5HQ65XQ6lZGRoXXr1gW222y2b10WLFgQ2Mfv92vatGnq3LmzIiIiNHz4cO3fv9+M7gAAgDbI1LCTmJiogoIClZeXq7y8XIMHD9aIESO0Y8cOSZLX6w1annvuOdlsNt1yyy2BNqZPn66ioiJ5PB5t3LhRR44c0bBhw9TY2GhWtwAAQBtiMwzDMLuIr4uOjtaCBQuUl5d32raRI0eqtrZWf/vb3yRJPp9PXbp00erVqzV27FhJ0oEDB+R2u7V27VoNHTr0nI5ZU1Mjl8sln88np9PZcp0BAACt5ly/v9vMNTuNjY3yeDw6evSoMjIyTtt+8OBBvfHGG0EhaMuWLWpoaFB2dnZgXUJCgvr27auysrIzHsvv96umpiZoAQAA1mR62KmsrFTHjh3lcDg0adIkFRUVKSUl5bT9Vq5cqcjISI0ePTqwrqqqSna7XVFRUUH7xsbGqqqq6ozHzM/Pl8vlCixut7vlOgQAANoU08NOcnKyKioqtGnTJk2ePFm5ubnauXPnafs999xzuuOOO9S+ffvvbNMwDNlstjNunzVrlnw+X2DZt2/fefUBAAC0XaFmF2C325WUlCRJ6t+/vzZv3qwlS5bo97//fWCf9957T7t379aaNWuCPhsXF6f6+nodOnQoaHanurpagwYNOuMxHQ6HHA5HC/cEAAC0RabP7HyTYRjy+/1B65YtW6Z+/fopPT09aH2/fv0UFhamkpKSwDqv16vt27efNewAAID/HKbO7MyePVs5OTlyu92qra2Vx+NRaWmpiouLA/vU1NTopZde0sKFC0/7vMvlUl5enmbMmKGYmBhFR0dr5syZSk1NVVZW1oXsCgAAaKNMDTsHDx7UuHHj5PV65XK5lJaWpuLiYg0ZMiSwj8fjkWEYuv3227+1jUWLFik0NFRjxoxRXV2dMjMztWLFCoWEhFyobgAAgDaszT1nxww8ZwcAgIvPRfecHQAAgNZA2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJYWanYBAAC0pKamJtXX15tdBlpAWFiYQkJCzrsdwg4AwDLq6+u1Z88eNTU1mV0KWkinTp0UFxcnm83W7DYIOwAASzAMQ16vVyEhIXK73WrXjis1LmaGYejYsWOqrq6WJMXHxze7LVPDTmFhoQoLC/Xpp59Kkvr06aO5c+cqJycnsM+uXbv04IMPasOGDWpqalKfPn30pz/9Sd26dZMk+f1+zZw5Uy+++KLq6uqUmZmppUuXKjEx0YwuAQBMcuLECR07dkwJCQnq0KGD2eWgBYSHh0uSqqur1bVr12af0jI19iYmJqqgoEDl5eUqLy/X4MGDNWLECO3YsUOS9M9//lNXX321evfurdLSUn3wwQeaM2eO2rdvH2hj+vTpKioqksfj0caNG3XkyBENGzZMjY2NZnULAGCCU//u2+12kytBSzoVXBsaGprdhs0wDKOlCmoJ0dHRWrBggfLy8nTbbbcpLCxMq1ev/tZ9fT6funTpotWrV2vs2LGSpAMHDsjtdmvt2rUaOnToOR2zpqZGLpdLPp9PTqezxfoCALhwjh8/rj179qhHjx5B/ynGxe1sf67n+v3dZk5oNjY2yuPx6OjRo8rIyFBTU5PeeOMN9erVS0OHDlXXrl01cOBAvfrqq4HPbNmyRQ0NDcrOzg6sS0hIUN++fVVWVnbGY/n9ftXU1AQtAADAmkwPO5WVlerYsaMcDocmTZqkoqIipaSkqLq6WkeOHFFBQYFuvPFGvfXWWxo1apRGjx6tDRs2SJKqqqpkt9sVFRUV1GZsbKyqqqrOeMz8/Hy5XK7A4na7W7WPAABcSNdff72mT59udhlthul3YyUnJ6uiokKHDx/Wyy+/rNzcXG3YsEGdOnWSJI0YMUL33XefJOlHP/qRysrK9Mwzz+i66647Y5uGYZz1FrVZs2bp/vvvD/xeU1ND4AEAXHDfdTt1bm6uVqxY8b3bfeWVVxQWFtbMqk4aP368Dh8+HHRG5WJletix2+1KSkqSJPXv31+bN2/WkiVL9NRTTyk0NFQpKSlB+1922WXauHGjJCkuLk719fU6dOhQ0OxOdXW1Bg0adMZjOhwOORyOVugNAADnzuv1Bn5es2aN5s6dq927dwfWnbob6ZSGhoZzCjHR0dEtV6QFmH4a65sMw5Df75fdbtcVV1wR9IcuSR9//LG6d+8uSerXr5/CwsJUUlIS2O71erV9+/azhh0AANqCuLi4wOJyuWSz2QK/Hz9+XJ06ddKf/vQnXX/99Wrfvr2ef/55ffnll7r99tuVmJioDh06KDU1VS+++GJQu988jXXJJZfo17/+te666y5FRkaqW7duevbZZ8+r9g0bNmjAgAFyOByKj4/XQw89pBMnTgS2//nPf1ZqaqrCw8MVExOjrKwsHT16VJJUWlqqAQMGKCIiQp06ddJVV12lvXv3nlc9Z2PqzM7s2bOVk5Mjt9ut2tpaeTwelZaWqri4WJL0wAMPaOzYsbr22mt1ww03qLi4WH/9619VWloqSXK5XMrLy9OMGTMUExOj6OhozZw5U6mpqcrKyjKxZwAAsxmGoboGcx5DEh4Wcl5P/P26Bx98UAsXLtTy5cvlcDh0/Phx9evXTw8++KCcTqfeeOMNjRs3Tj179tTAgQPP2M7ChQv12GOPafbs2frzn/+syZMn69prr1Xv3r2/d02fffaZbrrpJo0fP16rVq3SRx99pAkTJqh9+/aaP3++vF6vbr/9dv32t7/VqFGjVFtbq/fee0+GYejEiRMaOXKkJkyYoBdffFH19fX6xz/+0WLj9W1MDTsHDx7UuHHj5PV65XK5lJaWpuLiYg0ZMkSSNGrUKD3zzDPKz8/XPffco+TkZL388su6+uqrA20sWrRIoaGhGjNmTOChgitWrGiRd2kAAC5edQ2NSpn7pinH3vnoUHWwt8xX7PTp0zV69OigdTNnzgz8PG3aNBUXF+ull146a9i56aabNGXKFEknA9SiRYtUWlrarLCzdOlSud1uPf3007LZbOrdu7cOHDigBx98UHPnzpXX69WJEyc0evTowNmY1NRUSdJXX30ln8+nYcOG6Yc//KGkk5eotKZm/Uns27dPNpst8JTif/zjH/rjH/+olJQUTZw48ZzbWbZs2Xfuc9ddd+muu+464/b27dvrqaee0lNPPXXOxwUA4GLRv3//oN8bGxtVUFCgNWvW6LPPPpPf75ff71dERMRZ20lLSwv8fOp02alXMXxfu3btUkZGRtBszFVXXaUjR45o//79Sk9PV2ZmplJTUzV06FBlZ2fr1ltvVVRUlKKjozV+/HgNHTpUQ4YMUVZWlsaMGXNer4P4Ls0KOz/72c80ceJEjRs3TlVVVRoyZIj69Omj559/XlVVVZo7d25L1wkAwPcSHhainY+e28NlW+PYLeWbIWbhwoVatGiRFi9erNTUVEVERGj69Onf+ab3b17YbLPZmv3C1G+76/nUM4ptNptCQkJUUlKisrIyvfXWW3rqqaf08MMP6/3331ePHj20fPly3XPPPSouLtaaNWv0y1/+UiUlJbryyiubVc93adYFytu3b9eAAQMkSX/6058CD/H74x//2Kxb5AAAaGk2m00d7KGmLK15/cl7772nESNG6Oc//7nS09PVs2dPffLJJ612vG+TkpKisrIyff0lDGVlZYqMjNQPfvADSSfH/6qrrtIjjzyibdu2yW63q6ioKLD/j3/8Y82aNUtlZWXq27ev/vjHP7Zavc2a2WloaAjcur1+/XoNHz5cktS7d++g2+gAAEDLSkpK0ssvv6yysjJFRUXpiSeeUFVVVatc9+Lz+VRRURG0Ljo6WlOmTNHixYs1bdo0TZ06Vbt379a8efN0//33q127dnr//ff1t7/9TdnZ2eratavef/99ff7557rsssu0Z88ePfvssxo+fLgSEhK0e/duffzxx7rzzjtbvP5TmhV2+vTpo2eeeUY333yzSkpK9Nhjj0k6+V6qmJiYFi0QAAD8nzlz5mjPnj0aOnSoOnTooIkTJ2rkyJHy+XwtfqzS0lL9+Mc/Dlp36kGHa9eu1QMPPKD09HRFR0crLy9Pv/zlLyVJTqdT7777rhYvXqyamhp1795dCxcuVE5Ojg4ePKiPPvpIK1eu1Jdffqn4+HhNnTpVv/jFL1q8/lOa9SLQ0tJSjRo1SjU1NcrNzdVzzz0n6eSt5B999JFeeeWVFi+0NfEiUAC4+PEiUGtqiReBNmtm5/rrr9cXX3yhmpqaoCcXT5w4MfAqdgAAgLagWRco19XVye/3B4LO3r17tXjxYu3evVtdu3Zt0QIBAADOR7PCzogRI7Rq1SpJ0uHDhzVw4EAtXLhQI0eOVGFhYYsWCAAAcD6aFXa2bt2qa665RtLJd1/ExsZq7969WrVqlZ588skWLRAAAOB8NCvsHDt2TJGRkZKkt956S6NHj1a7du105ZVXtuqLvAAAAL6vZoWdpKQkvfrqq9q3b5/efPNNZWdnS5Kqq6u5mwkAALQpzQo7c+fO1cyZM3XJJZdowIABysjIkHRylueb9+MDAACYqVm3nt966626+uqr5fV6lZ6eHlifmZmpUaNGtVhxAAAA56vZ75+Pi4tTXFyc9u/fL5vNph/84AeB92UBAAC0Fc06jdXU1KRHH31ULpdL3bt3V7du3dSpUyc99thjzX6DKgAAQGtoVth5+OGH9fTTT6ugoEDbtm3T1q1b9etf/1pPPfWU5syZ09I1AgBgSTab7azL+PHjm932JZdcosWLF7fYfhezZp3GWrlypf7whz8E3nYuSenp6frBD36gKVOm6PHHH2+xAgEAsCqv1xv4ec2aNZo7d652794dWBceHm5GWZbTrJmdr776Sr179z5tfe/evfXVV1+dd1EAAPwnOHX9a1xcnFwul2w2W9C6d999V/369VP79u3Vs2dPPfLIIzpx4kTg8/Pnz1e3bt3kcDiUkJCge+65R9LJd1ju3btX9913X2CWqLkKCwv1wx/+UHa7XcnJyVq9enXQ9jPVIElLly7VpZdeqvbt2ys2Nla33nprs+s4H82a2UlPT9fTTz992tOSn376aaWlpbVIYQAAnBfDkBqOmXPssA7SeQQMSXrzzTf185//XE8++aSuueYa/fOf/9TEiRMlSfPmzdOf//xnLVq0SB6PR3369FFVVZU++OADSdIrr7yi9PR0TZw4URMmTGh2DUVFRbr33nu1ePFiZWVl6fXXX9d//dd/KTExUTfccMNZaygvL9c999yj1atXa9CgQfrqq6/03nvvndeYNFezws5vf/tb3XzzzVq/fr0yMjJks9lUVlamffv2ae3atS1dIwAA31/DMenXCeYce/YByR5xXk08/vjjeuihh5SbmytJ6tmzpx577DH9v//3/zRv3jz9+9//VlxcnLKyshQWFqZu3boF7oqOjo5WSEiIIiMjFRcX1+wafve732n8+PGaMmWKJOn+++/Xpk2b9Lvf/U433HDDWWv497//rYiICA0bNkyRkZHq3r27ac/ia9ZprOuuu04ff/yxRo0apcOHD+urr77S6NGjtWPHDi1fvrylawQA4D/Oli1b9Oijj6pjx46BZcKECfJ6vTp27Jh++tOfqq6uTj179tSECRNUVFQUdIqrJezatUtXXXVV0LqrrrpKu3btkqSz1jBkyBB1795dPXv21Lhx4/TCCy/o2DFzZtqa/ZydhISE0y5E/uCDD7Ry5Uo999xz510YAADnJazDyRkWs459npqamvTII49o9OjRp21r37693G63du/erZKSEq1fv15TpkzRggULtGHDBoWFhZ338U/55vU+hmEE1p2thsjISG3dulWlpaV66623NHfuXM2fP1+bN29Wp06dWqy+c9HssAMAQJtms533qSQzXX755dq9e7eSkpLOuE94eLiGDx+u4cOH6+6771bv3r1VWVmpyy+/XHa7XY2NjedVw2WXXaaNGzfqzjvvDKwrKyvTZZdddk41hIaGKisrS1lZWZo3b546deqkt99++1sDXGsi7AAA0AbNnTtXw4YNk9vt1k9/+lO1a9dOH374oSorK/WrX/1KK1asUGNjowYOHKgOHTpo9erVCg8PV/fu3SWdfH7Ou+++q9tuu00Oh0OdO3c+47E+++wzVVRUBK3r1q2bHnjgAY0ZM0aXX365MjMz9de//lWvvPKK1q9fL0lnreH111/Xv/71L1177bWKiorS2rVr1dTUpOTk5FYbszMyWlBFRYXRrl27lmzygvD5fIYkw+fzmV0KAKCZ6urqjJ07dxp1dXVml9Isy5cvN1wuV9C64uJiY9CgQUZ4eLjhdDqNAQMGGM8++6xhGIZRVFRkDBw40HA6nUZERIRx5ZVXGuvXrw989n//93+NtLQ0w+FwGGf7uu/evbsh6bRl+fLlhmEYxtKlS42ePXsaYWFhRq9evYxVq1YFPnu2Gt577z3juuuuM6Kioozw8HAjLS3NWLNmzfcel7P9uZ7r97fNMAzjXIPRd007HT58WBs2bDjvabMLraamRi6XSz6fT06n0+xyAADNcPz4ce3Zs0c9evRQ+/btzS4HLeRsf67n+v39vU5juVyu79z+9fN6AAAAZvteYYfbygEAwMWmWc/ZAQAAuFgQdgAAgKURdgAAlvI97rvBRaAl/jwJOwAASwgJCZEk1dfXm1wJWtKpV0ycz1OheaggAMASQkND1aFDB33++ecKCwtTu3b8f/5iZhiGjh07purqanXq1CkQZpuDsAMAsASbzab4+Hjt2bNHe/fuNbsctJBOnTqd15vbJcIOAMBC7Ha7Lr30Uk5lWURYWNh5zeicQtgBAFhKu3bteIIygnBCEwAAWBphBwAAWJqpYaewsFBpaWlyOp1yOp3KyMjQunXrAtvHjx8vm80WtFx55ZVBbfj9fk2bNk2dO3dWRESEhg8frv3791/orgAAgDbK1LCTmJiogoIClZeXq7y8XIMHD9aIESO0Y8eOwD433nijvF5vYFm7dm1QG9OnT1dRUZE8Ho82btyoI0eOaNiwYRfdm9cBAEDrsBlt7FGT0dHRWrBggfLy8jR+/HgdPnxYr7766rfu6/P51KVLF61evVpjx46VJB04cEBut1tr167V0KFDv/Vzfr9ffr8/8HtNTY3cbvd3viIeAAC0HTU1NXK5XN/5/d1mrtlpbGyUx+PR0aNHlZGREVhfWlqqrl27qlevXpowYYKqq6sD27Zs2aKGhgZlZ2cH1iUkJKhv374qKys747Hy8/PlcrkCi9vtbp1OAQAA05kediorK9WxY0c5HA5NmjRJRUVFSklJkSTl5OTohRde0Ntvv62FCxdq8+bNGjx4cGBWpqqqSna7XVFRUUFtxsbGqqqq6ozHnDVrlnw+X2DZt29f63UQAACYyvTn7CQnJ6uiokKHDx/Wyy+/rNzcXG3YsEEpKSmBU1OS1LdvX/Xv31/du3fXG2+8odGjR5+xTcMwZLPZzrjd4XDI4XC0aD8AAEDbZPrMjt1uV1JSkvr376/8/Hylp6dryZIl37pvfHy8unfvrk8++USSFBcXp/r6eh06dChov+rqasXGxrZ67QAAoO0zPex8k2EYQRcPf92XX36pffv2KT4+XpLUr18/hYWFqaSkJLCP1+vV9u3bNWjQoAtSLwAAaNtMPY01e/Zs5eTkyO12q7a2Vh6PR6WlpSouLtaRI0c0f/583XLLLYqPj9enn36q2bNnq3Pnzho1apQkyeVyKS8vTzNmzFBMTIyio6M1c+ZMpaamKisry8yuAQCANsLUsHPw4EGNGzdOXq9XLpdLaWlpKi4u1pAhQ1RXV6fKykqtWrVKhw8fVnx8vG644QatWbNGkZGRgTYWLVqk0NBQjRkzRnV1dcrMzNSKFSta5MVhAADg4tfmnrNjhnO9Tx8AALQdF91zdgAAAFoDYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFiaqWGnsLBQaWlpcjqdcjqdysjI0Lp1675131/84hey2WxavHhx0Hq/369p06apc+fOioiI0PDhw7V///4LUD0AALgYmBp2EhMTVVBQoPLycpWXl2vw4MEaMWKEduzYEbTfq6++qvfff18JCQmntTF9+nQVFRXJ4/Fo48aNOnLkiIYNG6bGxsYL1Q0AANCGmRp2fvKTn+imm25Sr1691KtXLz3++OPq2LGjNm3aFNjns88+09SpU/XCCy8oLCws6PM+n0/Lli3TwoULlZWVpR//+Md6/vnnVVlZqfXr11/o7gAAgDaozVyz09jYKI/Ho6NHjyojI0OS1NTUpHHjxumBBx5Qnz59TvvMli1b1NDQoOzs7MC6hIQE9e3bV2VlZWc8lt/vV01NTdACAACsyfSwU1lZqY4dO8rhcGjSpEkqKipSSkqKJOk3v/mNQkNDdc8993zrZ6uqqmS32xUVFRW0PjY2VlVVVWc8Zn5+vlwuV2Bxu90t1yEAANCmhJpdQHJysioqKnT48GG9/PLLys3N1YYNG1RXV6clS5Zo69atstls36tNwzDO+plZs2bp/vvvD/xeU1ND4AEAwKJMDzt2u11JSUmSpP79+2vz5s1asmSJLrvsMlVXV6tbt26BfRsbGzVjxgwtXrxYn376qeLi4lRfX69Dhw4Fze5UV1dr0KBBZzymw+GQw+FovU4BAIA2w/TTWN9kGIb8fr/GjRunDz/8UBUVFYElISFBDzzwgN58801JUr9+/RQWFqaSkpLA571er7Zv337WsAMAAP5zmDqzM3v2bOXk5Mjtdqu2tlYej0elpaUqLi5WTEyMYmJigvYPCwtTXFyckpOTJUkul0t5eXmaMWOGYmJiFB0drZkzZyo1NVVZWVlmdAkAALQxpoadgwcPaty4cfJ6vXK5XEpLS1NxcbGGDBlyzm0sWrRIoaGhGjNmjOrq6pSZmakVK1YoJCSkFSsHAAAXC5thGIbZRZitpqZGLpdLPp9PTqfT7HIAAMA5ONfv7zZ3zQ4AAEBLIuwAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLMzXsFBYWKi0tTU6nU06nUxkZGVq3bl1g+/z589W7d29FREQoKipKWVlZev/994Pa8Pv9mjZtmjp37qyIiAgNHz5c+/fvv9BdAQAAbZSpYScxMVEFBQUqLy9XeXm5Bg8erBEjRmjHjh2SpF69eunpp59WZWWlNm7cqEsuuUTZ2dn6/PPPA21Mnz5dRUVF8ng82rhxo44cOaJhw4apsbHRrG4BAIA2xGYYhmF2EV8XHR2tBQsWKC8v77RtNTU1crlcWr9+vTIzM+Xz+dSlSxetXr1aY8eOlSQdOHBAbrdba9eu1dChQ8/pmKfa9fl8cjqdLdofAADQOs71+7vNXLPT2Ngoj8ejo0ePKiMj47Tt9fX1evbZZ+VyuZSeni5J2rJlixoaGpSdnR3YLyEhQX379lVZWdkZj+X3+1VTUxO0AAAAawo1u4DKykplZGTo+PHj6tixo4qKipSSkhLY/vrrr+u2227TsWPHFB8fr5KSEnXu3FmSVFVVJbvdrqioqKA2Y2NjVVVVdcZj5ufn65FHHmmdDgEAgDbF9Jmd5ORkVVRUaNOmTZo8ebJyc3O1c+fOwPYbbrhBFRUVKisr04033qgxY8aourr6rG0ahiGbzXbG7bNmzZLP5wss+/bta7H+AACAtsX0sGO325WUlKT+/fsrPz9f6enpWrJkSWB7RESEkpKSdOWVV2rZsmUKDQ3VsmXLJElxcXGqr6/XoUOHgtqsrq5WbGzsGY/pcDgCd4CdWgAAgDWZHna+yTAM+f3+c9rer18/hYWFqaSkJLDd6/Vq+/btGjRoUKvXCgAA2j5Tr9mZPXu2cnJy5Ha7VVtbK4/Ho9LSUhUXF+vo0aN6/PHHNXz4cMXHx+vLL7/U0qVLtX//fv30pz+VJLlcLuXl5WnGjBmKiYlRdHS0Zs6cqdTUVGVlZZnZNQAA0EaYGnYOHjyocePGyev1yuVyKS0tTcXFxRoyZIiOHz+ujz76SCtXrtQXX3yhmJgYXXHFFXrvvffUp0+fQBuLFi1SaGioxowZo7q6OmVmZmrFihUKCQkxsWcAAKCtaHPP2TEDz9kBAODic9E9ZwcAAKA1EHYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClhZpdgFUZhqG6hkazywAAoE0IDwuRzWYz5diEnVZS19ColLlvml0GAABtws5Hh6qD3ZzYwWksAABgaczstJLwsBDtfHSo2WUAANAmhIeFmHZswk4rsdlspk3XAQCA/8NpLAAAYGmEHQAAYGmEHQAAYGmmhp3CwkKlpaXJ6XTK6XQqIyND69atkyQ1NDTowQcfVGpqqiIiIpSQkKA777xTBw4cCGrD7/dr2rRp6ty5syIiIjR8+HDt37/fjO4AAIA2yNSwk5iYqIKCApWXl6u8vFyDBw/WiBEjtGPHDh07dkxbt27VnDlztHXrVr3yyiv6+OOPNXz48KA2pk+frqKiInk8Hm3cuFFHjhzRsGHD1NjIA/0AAIBkMwzDMLuIr4uOjtaCBQuUl5d32rbNmzdrwIAB2rt3r7p16yafz6cuXbpo9erVGjt2rCTpwIEDcrvdWrt2rYYOPbdbv2tqauRyueTz+eR0Olu0PwAAoHWc6/d3m7lmp7GxUR6PR0ePHlVGRsa37uPz+WSz2dSpUydJ0pYtW9TQ0KDs7OzAPgkJCerbt6/KysrOeCy/36+ampqgBQAAWJPpYaeyslIdO3aUw+HQpEmTVFRUpJSUlNP2O378uB566CH97Gc/C6S3qqoq2e12RUVFBe0bGxurqqqqMx4zPz9fLpcrsLjd7pbtFAAAaDNMDzvJycmqqKjQpk2bNHnyZOXm5mrnzp1B+zQ0NOi2225TU1OTli5d+p1tGoZx1peNzZo1Sz6fL7Ds27fvvPsBAADaJtMf8Wu325WUlCRJ6t+/vzZv3qwlS5bo97//vaSTQWfMmDHas2eP3n777aBzcnFxcaqvr9ehQ4eCZneqq6s1aNCgMx7T4XDI4XC0Uo8AAEBbYvrMzjcZhiG/3y/p/4LOJ598ovXr1ysmJiZo3379+iksLEwlJSWBdV6vV9u3bz9r2AEAAP85TJ3ZmT17tnJycuR2u1VbWyuPx6PS0lIVFxfrxIkTuvXWW7V161a9/vrramxsDFyHEx0dLbvdLpfLpby8PM2YMUMxMTGKjo7WzJkzlZqaqqysLDO7BgAA2ghTw87Bgwc1btw4eb1euVwupaWlqbi4WEOGDNGnn36q1157TZL0ox/9KOhz77zzjq6//npJ0qJFixQaGqoxY8aorq5OmZmZWrFihUJCzHu7KgAAaDva3HN2zODz+dSpUyft27eP5+wAAHCRqKmpkdvt1uHDh+Vyuc64n+kXKLcFtbW1ksQt6AAAXIRqa2vPGnaY2ZHU1NSkAwcOKDIy8qy3rH/dqTTJbNCFwXhfWIz3hcV4X1iM94XVmuNtGIZqa2uVkJCgdu3OfM8VMzuS2rVrp8TExGZ99tRLTHFhMN4XFuN9YTHeFxbjfWG11nifbUbnlDZ36zkAAEBLIuwAAABLI+w0k8Ph0Lx583gS8wXCeF9YjPeFxXhfWIz3hdUWxpsLlAEAgKUxswMAACyNsAMAACyNsAMAACyNsAMAACyNsNNMS5cuVY8ePdS+fXv169dP7733ntklWcK7776rn/zkJ0pISJDNZtOrr74atN0wDM2fP18JCQkKDw/X9ddfrx07dphT7EUuPz9fV1xxhSIjI9W1a1eNHDlSu3fvDtqH8W5ZhYWFSktLCzxcLSMjQ+vWrQtsZ7xbT35+vmw2m6ZPnx5Yx3i3rPnz58tmswUtcXFxge1mjjdhpxnWrFmj6dOn6+GHH9a2bdt0zTXXKCcnR//+97/NLu2id/ToUaWnp+vpp5/+1u2//e1v9cQTT+jpp5/W5s2bFRcXpyFDhgTeb4Zzt2HDBt19993atGmTSkpKdOLECWVnZ+vo0aOBfRjvlpWYmKiCggKVl5ervLxcgwcP1ogRIwL/4DPerWPz5s169tlnlZaWFrSe8W55ffr0kdfrDSyVlZWBbaaOt4HvbcCAAcakSZOC1vXu3dt46KGHTKrImiQZRUVFgd+bmpqMuLg4o6CgILDu+PHjhsvlMp555hkTKrSW6upqQ5KxYcMGwzAY7wslKirK+MMf/sB4t5La2lrj0ksvNUpKSozrrrvOuPfeew3D4O93a5g3b56Rnp7+rdvMHm9mdr6n+vp6bdmyRdnZ2UHrs7OzVVZWZlJV/xn27NmjqqqqoLF3OBy67rrrGPsW4PP5JEnR0dGSGO/W1tjYKI/Ho6NHjyojI4PxbiV33323br75ZmVlZQWtZ7xbxyeffKKEhAT16NFDt912m/71r39JMn+8eRHo9/TFF1+osbFRsbGxQetjY2NVVVVlUlX/GU6N77eN/d69e80oyTIMw9D999+vq6++Wn379pXEeLeWyspKZWRk6Pjx4+rYsaOKioqUkpIS+Aef8W45Ho9HW7du1ebNm0/bxt/vljdw4ECtWrVKvXr10sGDB/WrX/1KgwYN0o4dO0wfb8JOM9lstqDfDcM4bR1aB2Pf8qZOnaoPP/xQGzduPG0b492ykpOTVVFRocOHD+vll19Wbm6uNmzYENjOeLeMffv26d5779Vbb72l9u3bn3E/xrvl5OTkBH5OTU1VRkaGfvjDH2rlypW68sorJZk33pzG+p46d+6skJCQ02ZxqqurT0usaFmnrupn7FvWtGnT9Nprr+mdd95RYmJiYD3j3TrsdruSkpLUv39/5efnKz09XUuWLGG8W9iWLVtUXV2tfv36KTQ0VKGhodqwYYOefPJJhYaGBsaU8W49ERERSk1N1SeffGL632/Czvdkt9vVr18/lZSUBK0vKSnRoEGDTKrqP0OPHj0UFxcXNPb19fXasGEDY98MhmFo6tSpeuWVV/T222+rR48eQdsZ7wvDMAz5/X7Gu4VlZmaqsrJSFRUVgaV///664447VFFRoZ49ezLerczv92vXrl2Kj483/+93q18CbUEej8cICwszli1bZuzcudOYPn26ERERYXz66adml3bRq62tNbZt22Zs27bNkGQ88cQTxrZt24y9e/cahmEYBQUFhsvlMl555RWjsrLSuP322434+HijpqbG5MovPpMnTzZcLpdRWlpqeL3ewHLs2LHAPox3y5o1a5bx7rvvGnv27DE+/PBDY/bs2Ua7du2Mt956yzAMxru1ff1uLMNgvFvajBkzjNLSUuNf//qXsWnTJmPYsGFGZGRk4LvRzPEm7DTT//zP/xjdu3c37Ha7cfnllwdu18X5eeeddwxJpy25ubmGYZy8fXHevHlGXFyc4XA4jGuvvdaorKw0t+iL1LeNsyRj+fLlgX0Y75Z11113Bf7d6NKli5GZmRkIOobBeLe2b4YdxrtljR071oiPjzfCwsKMhIQEY/To0caOHTsC280cb5thGEbrzx8BAACYg2t2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AACApRF2AOBb2Gw2vfrqq2aXAaAFEHYAtDnjx4+XzWY7bbnxxhvNLg3ARSjU7AIA4NvceOONWr58edA6h8NhUjUALmbM7ABokxwOh+Li4oKWqKgoSSdPMRUWFionJ0fh4eHq0aOHXnrppaDPV1ZWavDgwQoPD1dMTIwmTpyoI0eOBO3z3HPPqU+fPnI4HIqPj9fUqVODtn/xxRcaNWqUOnTooEsvvVSvvfZa63YaQKsg7AC4KM2ZM0e33HKLPvjgA/385z/X7bffrl27dkmSjh07phtvvFFRUVHavHmzXnrpJa1fvz4ozBQWFuruu+/WxIkTVVlZqddee01JSUlBx3jkkUc0ZswYffjhh7rpppt0xx136Kuvvrqg/QTQAi7Iu9UB4HvIzc01QkJCjIiIiKDl0UcfNQzDMCQZkyZNCvrMwIEDjcmTJxuGYRjPPvusERUVZRw5ciSw/Y033jDatWtnVFVVGYZhGAkJCcbDDz98xhokGb/85S8Dvx85csSw2WzGunXrWqyfAC4MrtkB0CbdcMMNKiwsDFoXHR0d+DkjIyNoW0ZGhioqKiRJu3btUnp6uiIiIgLbr7rqKjU1NWn37t2y2Ww6cOCAMjMzz1pDWlpa4OeIiAhFRkaqurq6uV0CYBLCDoA2KSIi4rTTSt/FZrNJkgzDCPz8bfuEh4efU3thYWGnfbapqel71QTAfFyzA+CitGnTptN+7927tyQpJSVFFRUVOnr0aGD73//+d7Vr1069evVSZGSkLrnkEv3tb3+7oDUDMAczOwDaJL/fr6qqqqB1oaGh6ty5syTppZdeUv/+/XX11VfrhRde0D/+8Q8tW7ZMknTHHXdo3rx5ys3N1fz58/X5559r2rRpGjdunGJjYyVJ8+fP16RJk9S1a1fl5OSotrZWf//73zVt2rQL21EArY6wA6BNKi4uVnx8fNC65ORkffTRR5JO3inl8Xg0ZcoUxcXF6YUXXlBKSookqUOHDnrzzTd177336oorrlCHDh10yy236Iknngi0lZubq+PHj2vRokWaOXOmOnfurFtvvfXCdRDABWMzDMMwuwgA+D5sNpuKioo0cuRIs0sBcBHgmh0AAGBphB0AAGBpXLMD4KLD2XcA3wczOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNL+Pz03ygE9yVp1AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# モデルの評価\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    test_loss = criterion(y_pred, y_test)\n",
    "    print(f'Final Test Loss: {test_loss:.4f}')\n",
    "\n",
    "# 損失の可視化\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, num_epochs + 1), test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
