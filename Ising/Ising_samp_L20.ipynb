{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 関数を定義\n",
    "def metropolis_ising(L, T, num_steps, J=1, device=\"cpu\"):\n",
    "    lattice = np.random.choice([-1, 1], size=(L, L))\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        i = np.random.randint(L)\n",
    "        j = np.random.randint(L)\n",
    "        \n",
    "        \n",
    "        # 近傍のスピンの総和を計算（周期境界条件を適用）\n",
    "        total = lattice[(i + 1) % L, j] + lattice[(i - 1) % L, j] + \\\n",
    "                lattice[i, (j + 1) % L] + lattice[i, (j - 1) % L]\n",
    "        \n",
    "        # エネルギー差を計算\n",
    "        delta_energy = 2 * J * lattice[i, j] * total\n",
    "        \n",
    "        if delta_energy < 0 or np.random.rand() < np.exp(-delta_energy / T):\n",
    "            \n",
    "            lattice[i, j] *= -1     # スピンを反転させる\n",
    "            \n",
    "    # 状況に応じてスピン変数全体を反転\n",
    "    if np.sum(lattice==1) >= L*L/2:\n",
    "        lattice = lattice*-1\n",
    "    else:\n",
    "        lattice = lattice\n",
    "\n",
    "    # NumPy配列をPyTorchテンソルに変換し、デバイスに移動\n",
    "    lattice = torch.tensor(lattice, dtype=torch.float32, device=device)\n",
    "    \n",
    "    return lattice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T=1からT=6まで，0.25刻みで配位データを取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]C:\\Users\\soken\\AppData\\Local\\Temp\\ipykernel_12052\\1404279372.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spin_data.append(torch.tensor(lattice, dtype=torch.float32, device=device))\n",
      "100%|██████████| 1000/1000 [08:09<00:00,  2.04it/s]\n",
      "100%|██████████| 1000/1000 [08:09<00:00,  2.04it/s]\n",
      "100%|██████████| 1000/1000 [08:13<00:00,  2.03it/s]\n",
      "100%|██████████| 1000/1000 [08:12<00:00,  2.03it/s]\n",
      "100%|██████████| 1000/1000 [08:07<00:00,  2.05it/s]\n",
      "100%|██████████| 1000/1000 [08:13<00:00,  2.03it/s]\n",
      "100%|██████████| 1000/1000 [08:09<00:00,  2.04it/s]\n",
      "100%|██████████| 1000/1000 [08:05<00:00,  2.06it/s]\n",
      "100%|██████████| 1000/1000 [07:59<00:00,  2.09it/s]\n",
      "100%|██████████| 1000/1000 [08:00<00:00,  2.08it/s]\n",
      "100%|██████████| 1000/1000 [07:54<00:00,  2.11it/s]]\n",
      "100%|██████████| 1000/1000 [07:52<00:00,  2.11it/s]]\n",
      "100%|██████████| 1000/1000 [07:51<00:00,  2.12it/s]]\n",
      "100%|██████████| 1000/1000 [07:55<00:00,  2.10it/s]]\n",
      "100%|██████████| 1000/1000 [07:52<00:00,  2.12it/s]]\n",
      "100%|██████████| 1000/1000 [07:46<00:00,  2.14it/s]]\n",
      "100%|██████████| 1000/1000 [07:43<00:00,  2.16it/s]]\n",
      "100%|██████████| 1000/1000 [07:44<00:00,  2.15it/s]]\n",
      "100%|██████████| 1000/1000 [07:43<00:00,  2.16it/s] \n",
      "100%|██████████| 1000/1000 [07:43<00:00,  2.16it/s]\n",
      "100%|██████████| 1000/1000 [07:46<00:00,  2.14it/s]\n",
      "100%|██████████| 1000/1000 [07:40<00:00,  2.17it/s]\n",
      "100%|██████████| 1000/1000 [07:39<00:00,  2.18it/s]\n",
      "100%|██████████| 1000/1000 [07:39<00:00,  2.18it/s]\n",
      "100%|██████████| 1000/1000 [07:37<00:00,  2.18it/s]\n",
      "100%|██████████| 25/25 [3:17:53<00:00, 474.95s/it]\n"
     ]
    }
   ],
   "source": [
    "L = 20\n",
    "num_steps = 100000\n",
    "\n",
    "# GPUが利用可能であれば、CUDAデバイスを使用\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "spin_data = []\n",
    "temp_data = []\n",
    "\n",
    "# 一次元データを得る\n",
    "for T in tqdm(np.arange(0.0, 6.01, 0.25)):\n",
    "    # T=0はmetropolis_isingには定義されていないのでT=0.01をT=0のデータとする\n",
    "    if T==0:\n",
    "        T = 0.01     \n",
    "    # 各温度で1000個ずつ配位を作成   \n",
    "    for i in tqdm(range(1000)):\n",
    "        lattice = metropolis_ising(L, T, num_steps)\n",
    "        # latticeをGPUに移動してからspin_dataに追加\n",
    "        spin_data.append(torch.tensor(lattice, dtype=torch.float32, device=device))\n",
    "        temp_data.append(T)\n",
    "        \n",
    "spin_data = torch.stack(spin_data)  # GPU上でテンソルスタック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# 型を確認\n",
    "print(type(spin_data))\n",
    "print(type(temp_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25000, 20, 20])\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "# データサイズの確認\n",
    "print(torch.Tensor.size(spin_data))\n",
    "print(len(temp_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1., -1., -1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "          1., -1., -1., -1., -1., -1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "          1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "          1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "          1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "          1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "          1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "          1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "          1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "          1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,\n",
      "         -1., -1.,  1.,  1.,  1.,  1.],\n",
      "        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "         -1., -1., -1., -1., -1., -1.],\n",
      "        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "         -1., -1., -1., -1., -1., -1.],\n",
      "        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "         -1., -1., -1., -1., -1., -1.],\n",
      "        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "         -1., -1., -1., -1., -1., -1.],\n",
      "        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "         -1., -1., -1., -1., -1., -1.],\n",
      "        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "         -1., -1., -1., -1., -1., -1.],\n",
      "        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "         -1., -1., -1., -1., -1., -1.],\n",
      "        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "         -1., -1., -1., -1., -1., -1.],\n",
      "        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "         -1., -1., -1., -1., -1., -1.],\n",
      "        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "         -1., -1., -1., -1., -1., -1.]], device='cuda:0')\n",
      "0.5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 2000\n",
    "print(spin_data[i])\n",
    "print(temp_data[i])\n",
    "\n",
    "# CUDAデバイス上のテンソルをCPU上のNumPy配列に変換\n",
    "spin_data_cpu = spin_data[i].cpu().numpy()\n",
    "\n",
    "# CUDAデバイス上のテンソルをCPU上のNumPy配列に変換\n",
    "plt.imshow(spin_data_cpu, cmap='gray', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存するデータをtupleにまとめる\n",
    "data_to_save = (spin_data, temp_data)\n",
    "\n",
    "# データをバイナリ形式で保存\n",
    "with open('data_L20.pkl', 'wb') as file:\n",
    "    pickle.dump(data_to_save, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        ...,\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "        [-1., -1., -1.,  ..., -1., -1., -1.]], device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spin_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
