{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sugay\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] 指定されたプロシージャが見つかりません。'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cudaが使えるか確認\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPUで作ったPickleのファイルは，CPUではそのままでは使えないため，工夫が必要．\n",
    "\n",
    "https://www.kunita-gamefactory.com/post/%E3%80%90pytorch%E3%80%91gpu%E3%81%A7%E8%A8%93%E7%B7%B4%E3%81%95%E3%81%9B%E3%81%9F%E3%83%A2%E3%83%87%E3%83%AB%E3%82%92cpu%E3%81%A7%E8%AA%AD%E3%81%BF%E8%BE%BC%E3%82%82%E3%81%86%E3%81%A8%E3%81%97%E3%81%9F%E3%81%8A%E8%A9%B1\n",
    "\n",
    "を真似したらうまくCPU上でもファイルを読み込むことができるようになった．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "        \n",
    "class CPU_Unpickler(pickle.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
    "            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
    "        else: return super().find_class(module, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ファイルの相対パスを指定\n",
    "file_path = '../data storage/Ising_data_L16.pkl'\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    with open(file_path, 'rb') as file:\n",
    "        loaded_data = pickle.load(file)\n",
    "else:\n",
    "    with open(file_path, 'rb') as file:\n",
    "        loaded_data = CPU_Unpickler(file).load()\n",
    "        \n",
    "# 読み込んだデータを個々の変数に分割\n",
    "spin_data, label_data = loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データのリストをNumPy配列に変換\n",
    "spin_data_np = np.array(spin_data)\n",
    "label_data_np = np.array(label_data)\n",
    "\n",
    "# NumPy配列をPyTorchテンソルに変換\n",
    "spin_data_tensor = torch.from_numpy(spin_data_np)\n",
    "label_data_tensor = torch.from_numpy(label_data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spin_data_tensor = spin_data_tensor.unsqueeze(1)\n",
    "# spin_data_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# サンプルデータを訓練用とテスト用に分割(5:5)\n",
    "spin_train, spin_test, label_train, label_test = train_test_split(spin_data_tensor, label_data_tensor, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sugay\\AppData\\Local\\Temp\\ipykernel_26892\\168836570.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spin_train = torch.tensor(spin_train, dtype=torch.float32)\n",
      "C:\\Users\\sugay\\AppData\\Local\\Temp\\ipykernel_26892\\168836570.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  spin_test = torch.tensor(spin_test, dtype=torch.float32)\n",
      "C:\\Users\\sugay\\AppData\\Local\\Temp\\ipykernel_26892\\168836570.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label_train = torch.tensor(label_train, dtype=torch.float32)\n",
      "C:\\Users\\sugay\\AppData\\Local\\Temp\\ipykernel_26892\\168836570.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label_test = torch.tensor(label_test, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# PyTorchのテンソルに変換\n",
    "spin_train = torch.tensor(spin_train, dtype=torch.float32)\n",
    "spin_test = torch.tensor(spin_test, dtype=torch.float32)\n",
    "label_train = torch.tensor(label_train, dtype=torch.float32)  \n",
    "label_test = torch.tensor(label_test, dtype=torch.float32)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正解データはone-hot表現にする必要がある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テンソルを新しいテンソルに変換する関数を定義\n",
    "def to_one_hot(data, num_classes=100):\n",
    "    # one-hotベクトルの初期化\n",
    "    one_hot = torch.zeros(len(data), num_classes)\n",
    "    \n",
    "    # 各要素を25次元のone-hotベクトルに変換\n",
    "    for i, val in enumerate(data):\n",
    "        index = int(torch.round((val - 0.2) / 0.0080808080808081))  # 正しいインデックスの計算\n",
    "        one_hot[i, index] = 1.0\n",
    "    \n",
    "    return one_hot\n",
    "\n",
    "# label_train,temp_testをone-hotベクトルに変換\n",
    "one_hot_label_train = to_one_hot(label_train, num_classes=100)\n",
    "one_hot_label_test = to_one_hot(label_test, num_classes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの作成\n",
    "train_dataset = TensorDataset(spin_train, one_hot_label_train)\n",
    "test_dataset = TensorDataset(spin_test, one_hot_label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理を定義\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "])\n",
    "\n",
    "# データセットに前処理を適用\n",
    "transformed_train_dataset = [(transform(tensor_sample), label) for tensor_sample, label in train_dataset]\n",
    "transformed_test_dataset = [(transform(tensor_sample), label) for tensor_sample, label in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaderの設定（バッチサイズ50）\n",
    "train_loader = DataLoader(transformed_train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(transformed_test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 前処理なしver\n",
    "# # DataLoaderの設定（バッチサイズ50）\n",
    "# train_loader = DataLoader(train_dataset, batch_size=50, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルを定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(FCNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size, bias=False)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size, bias=False)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.softmax(self.fc2(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルのインスタンス化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCNN(\n",
      "  (fc1): Linear(in_features=256, out_features=320, bias=False)\n",
      "  (fc2): Linear(in_features=320, out_features=100, bias=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = 16*16\n",
    "hidden_size = 320\n",
    "output_size = 100\n",
    "model = FCNN(input_size, hidden_size, output_size)\n",
    "model.to(device)\n",
    "# モデルの概要表示\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "損失関数と最適化アルゴリズムの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()   # クロスエントロピー誤差\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)     # Adam,L2正則化{, weight_decay=5e-4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 4.600599125528335, train acc: 0.016599999740719795, test loss: 4.598330234050751, test acc: 0.016200000420212746\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "running_loss = 0.0\n",
    "running_acc = 0.0\n",
    "\n",
    "for inputs, targets in train_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(inputs)\n",
    "    loss = criterion(output, targets)\n",
    "    loss.backward()\n",
    "    running_loss += loss.item()\n",
    "    pred = torch.argmax(output, dim=1)   \n",
    "    targets = torch.argmax(targets, dim=1)  \n",
    "    running_acc += torch.mean(pred.eq(targets).float().cpu()) \n",
    "    optimizer.step()\n",
    "running_loss /= len(train_loader)\n",
    "running_acc /= len(train_loader)  \n",
    "#\n",
    "#   test loop\n",
    "#\n",
    "test_running_loss = 0.0\n",
    "test_running_acc = 0.0\n",
    "for test_inputs, test_targets in test_loader:\n",
    "    test_inputs = test_inputs.to(device)\n",
    "    test_targets = test_targets.to(device)\n",
    "    test_output = model(test_inputs)\n",
    "    test_loss = criterion(test_output, test_targets)\n",
    "    test_running_loss += test_loss.item()\n",
    "    test_pred = torch.argmax(test_output, dim=1)   \n",
    "    test_targets = torch.argmax(test_targets, dim=1) \n",
    "    test_running_acc += torch.mean(test_pred.eq(test_targets).float().cpu()) \n",
    "test_running_loss /= len(test_loader)  \n",
    "test_running_acc /= len(test_loader) \n",
    "    \n",
    "print(\"train loss: {}, train acc: {}, test loss: {}, test acc: {}\".format(running_loss, running_acc, test_running_loss, test_running_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../data storage/prm_data_L16_FCNN.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
